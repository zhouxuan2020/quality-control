[["index.html", "Quality control 1 General Info 1.1 Topic 1.2 Frequently used commands", " Quality control updated on 2022-01-24 1 General Info 1.1 Topic We propose a new method to detect the inflation of GWAS test statistics caused by population stratification (&amp; relatedness). Here we document all analyses and results. [insert details about the method here] 1.2 Frequently used commands ssh -l zhoux login.genome.au.dk sftp zhoux@login.genome.au.dk lcd /home/zhoux/Dropbox/github/quality-control/main-files cd /home/zhoux/dsmwpred/xuan/quality-control/qc-10oct srun --mem=15g -c 2 -t 5:0:0 --constraint \"s04|s05\" -A snpher --pty /bin/bash "],["summaries.html", "2 Summaries 2.1 Good GWAS 2.2 Bad GWAS 2.3 UKBB recommended 2.4 Control GWAS", " 2 Summaries To compare the proposed method against existing ones, we performed good and bad GWASs for 14 traits using N = 100k. While both sets of GWASs were based on quality-controlled genotype data, bad GWASs used individuals of different ethnicity and hence were confounded by population stratification, which is known to cause inflation in test statistics. As expected, for the good GWASs, no inflation was detected by the methods, though with some exceptions ( Tables 2.1 ). In contrast, for the bad GWASs significant inflation was evident based on all methods ( see Tables 2.3 &amp; 2.4 ). The detected inflation for the GWASs is not due to random errors because no inflation was observed for the control GWASs ( see Tables 2.7 &amp; 2.8 ) 2.1 Good GWAS Code for the good GWAS can be found in section 4. Basically, we used 100k unrelated white British with quality-controlled genotype data for the GWASs. We tested the GWAS test statistics for inflation using ldsc, sumher and the proposed method (based on individual level data using Haseman Elston regression) 2.1.1 ldsc &amp; sumher Table 2.1: Good GWAS: LDSC regression line intercept estimates (SE) using ldsc and sumher ldsc sumher-gcta sumher-ldak-thin trait est se wald_p est se wald_p est se wald_p awake 1.002 0.007 7.8e-01 0.997 0.008 6.8e-01 0.995 0.009 5.8e-01 bmi 1.017 0.009 6.2e-02 0.994 0.010 5.3e-01 0.997 0.010 7.3e-01 chron 1.012 0.008 1.2e-01 1.011 0.009 2.0e-01 1.013 0.009 1.4e-01 ever 1.000 0.007 9.4e-01 0.996 0.009 6.1e-01 0.995 0.009 5.6e-01 fvc 1.032 0.010 1.4e-03 1.014 0.010 1.4e-01 1.007 0.010 4.6e-01 height 1.094 0.017 1.9e-08 1.018 0.012 1.4e-01 1.031 0.012 7.9e-03 hyper 1.018 0.009 5.6e-02 1.013 0.009 1.5e-01 1.002 0.009 8.6e-01 imp 1.016 0.011 1.3e-01 0.987 0.010 1.8e-01 0.991 0.010 3.4e-01 neur 1.004 0.009 6.8e-01 0.997 0.009 7.1e-01 0.996 0.009 6.5e-01 pulse 1.029 0.010 2.3e-03 1.016 0.009 8.5e-02 1.019 0.009 4.2e-02 quals 1.020 0.008 1.5e-02 1.014 0.009 1.3e-01 1.012 0.009 2.1e-01 reaction 1.010 0.007 1.6e-01 1.007 0.009 4.0e-01 1.003 0.009 7.0e-01 sbp 1.007 0.009 3.9e-01 0.999 0.009 8.8e-01 0.997 0.009 7.2e-01 snoring 1.008 0.007 2.6e-01 1.004 0.008 6.3e-01 1.004 0.009 6.4e-01 Note: p-values are based on the wald test that compares the ldsc regression line intercept against 1. p-values &lt;= Bonferroni corrected alpha (i.e., 0.05/14) are highlighted 2.1.2 Haseman Elston Regression Table 2.2: Good GWAS: Heritability estimates (SE) using Haseman Elston regression under assumed heritability models trait right_est right_sd left_est left_sd all_est all_sd p_inflation under gcta awake 0.040 0.004 0.034 0.004 0.073 0.005 4.9e-01 bmi 0.137 0.005 0.126 0.005 0.263 0.007 4.9e-01 chron 0.060 0.004 0.048 0.004 0.108 0.005 4.8e-01 ever 0.041 0.004 0.043 0.004 0.085 0.005 5.1e-01 fvc 0.110 0.005 0.100 0.004 0.210 0.006 4.9e-01 height 0.294 0.007 0.264 0.006 0.558 0.009 4.8e-01 imp 0.154 0.006 0.141 0.005 0.295 0.008 4.9e-01 neur 0.064 0.004 0.057 0.004 0.121 0.006 4.9e-01 pulse 0.081 0.004 0.076 0.004 0.156 0.006 5.0e-01 quals 0.088 0.004 0.089 0.004 0.177 0.006 5.1e-01 reaction 0.034 0.004 0.038 0.004 0.072 0.005 5.1e-01 sbp 0.086 0.005 0.076 0.004 0.162 0.007 4.9e-01 snoring 0.034 0.004 0.033 0.004 0.068 0.005 5.0e-01 hyper 0.065 0.005 0.049 0.004 0.114 0.006 4.8e-01 under ldak-thin awake 0.037 0.004 0.033 0.004 0.070 0.005 4.9e-01 bmi 0.134 0.005 0.122 0.005 0.256 0.007 5.0e-01 chron 0.056 0.004 0.048 0.004 0.104 0.005 5.0e-01 ever 0.039 0.004 0.041 0.004 0.080 0.005 5.0e-01 fvc 0.105 0.005 0.100 0.004 0.205 0.006 5.0e-01 height 0.269 0.006 0.253 0.006 0.522 0.009 4.9e-01 imp 0.149 0.006 0.135 0.005 0.284 0.008 4.9e-01 neur 0.064 0.005 0.056 0.004 0.120 0.006 5.0e-01 pulse 0.077 0.004 0.073 0.004 0.150 0.006 5.0e-01 quals 0.085 0.004 0.089 0.004 0.173 0.006 5.0e-01 reaction 0.034 0.004 0.038 0.004 0.072 0.005 5.0e-01 sbp 0.088 0.006 0.076 0.004 0.163 0.007 5.0e-01 snoring 0.033 0.004 0.033 0.004 0.065 0.005 5.0e-01 hyper 0.068 0.005 0.049 0.004 0.117 0.006 5.0e-01 Note: p-values are for testing whether the sum of ‘left’ and ‘right’ heritability estimates are greater than the heritability estimate based on the whole genome. p-values &lt;= Bonferroni corrected alpha (i.e., 0.05/14) are highlighted 2.2 Bad GWAS Code for the bad GWAS can be found in section 5. Basically, we used 100k unrelated individuals that consist of 93,528 whites and 6,472 blacks and Asians (i.e., mixed populations). Hence, the GWASs were confounded by population stratification. We performed the confounded GWASs and tested the test statistics for inflation using ldsc, sumher and the proposed method (based on individual level data using Haseman Elston regression) 2.2.1 ldsc &amp; sumher Table 2.3: Bad GWAS: LDSC regression line intercept estimates (SE) using ldsc and sumher ldsc sumher-gcta sumher-ldak-thin trait est se wald_p est se wald_p est se wald_p awake 3.441 0.027 0.0e+00 3.513 0.026 0.0e+00 3.758 0.018 0.0e+00 bmi 5.040 0.030 0.0e+00 8.893 0.066 0.0e+00 9.536 0.045 0.0e+00 chron 1.453 0.012 1.9e-311 1.402 0.011 2.4e-283 1.465 0.011 0.0e+00 ever 6.838 0.028 0.0e+00 15.830 0.114 0.0e+00 16.885 0.080 0.0e+00 fvc NA NA NA 78.325 0.564 0.0e+00 83.464 0.393 0.0e+00 height NA NA NA 14.197 0.107 0.0e+00 15.475 0.103 0.0e+00 hyper 4.673 0.029 0.0e+00 6.891 0.050 0.0e+00 7.320 0.034 0.0e+00 imp NA NA NA 8.930 0.064 0.0e+00 9.467 0.045 0.0e+00 neur 4.179 0.026 0.0e+00 5.349 0.038 0.0e+00 5.682 0.027 0.0e+00 pulse 1.444 0.013 7.8e-260 1.406 0.012 1.5e-269 1.452 0.012 2.5e-323 quals 2.082 0.018 0.0e+00 2.023 0.016 0.0e+00 2.147 0.017 0.0e+00 reaction 8.123 0.031 0.0e+00 33.822 0.241 0.0e+00 35.822 0.169 0.0e+00 sbp 3.028 0.026 0.0e+00 3.050 0.023 0.0e+00 3.313 0.016 0.0e+00 snoring 1.050 0.007 3.1e-11 1.052 0.008 5.2e-10 1.047 0.009 6.3e-08 Note: p-values are based on the wald test that compares the ldsc regression line intercept against 1. p-values &lt;= Bonferroni corrected alpha (i.e., 0.05/14) are highlighted 2.2.2 Haseman Elston Regression Table 2.4: Bad GWAS: Heritability estimates (SE) using Haseman Elston regression under assumed heritability models trait right_est right_sd left_est left_sd all_est all_sd p_inflation under gcta awake 0.075 0.012 0.075 0.012 0.080 0.012 1.8e-04 bmi 0.237 0.023 0.235 0.023 0.249 0.025 0.0e+00 chron 0.016 0.004 0.016 0.004 0.017 0.004 2.0e-02 ever 0.439 0.028 0.434 0.027 0.461 0.029 0.0e+00 fvc 2.280 0.063 2.237 0.062 2.384 0.067 0.0e+00 height 0.406 0.023 0.402 0.023 0.426 0.024 0.0e+00 imp 0.228 0.015 0.227 0.015 0.240 0.016 0.0e+00 neur 0.128 0.015 0.129 0.015 0.136 0.016 1.0e-05 pulse 0.018 0.004 0.019 0.004 0.020 0.004 2.6e-03 quals 0.037 0.006 0.038 0.006 0.040 0.006 2.9e-04 reaction 0.959 0.059 0.950 0.059 1.008 0.063 0.0e+00 sbp 0.064 0.011 0.064 0.010 0.068 0.011 4.6e-04 snoring 0.004 0.001 0.005 0.001 0.005 0.001 3.1e-03 hyper 0.175 0.020 0.172 0.020 0.183 0.021 0.0e+00 under ldak-thin awake 0.090 0.014 0.090 0.014 0.080 0.012 2.0e-05 bmi 0.278 0.027 0.273 0.027 0.249 0.025 0.0e+00 chron 0.021 0.005 0.021 0.005 0.017 0.004 1.8e-03 ever 0.533 0.033 0.525 0.032 0.461 0.029 0.0e+00 fvc 2.782 0.076 2.734 0.074 2.384 0.067 0.0e+00 height 0.527 0.029 0.526 0.029 0.426 0.024 0.0e+00 imp 0.283 0.018 0.281 0.017 0.240 0.016 0.0e+00 neur 0.150 0.018 0.150 0.018 0.136 0.016 0.0e+00 pulse 0.024 0.004 0.025 0.004 0.020 0.004 1.0e-05 quals 0.049 0.007 0.050 0.007 0.040 0.006 0.0e+00 reaction 1.146 0.070 1.135 0.069 1.008 0.063 0.0e+00 sbp 0.077 0.012 0.075 0.012 0.068 0.011 1.0e-05 snoring 0.006 0.001 0.007 0.001 0.005 0.001 5.0e-05 hyper 0.206 0.024 0.202 0.023 0.183 0.021 0.0e+00 Note: p-values are for testing whether the sum of ‘left’ and ‘right’ heritability estimates are greater than the heritability estimate based on the whole genome. p-values &lt;= Bonferroni corrected alpha (i.e., 0.05/14) are highlighted 2.3 UKBB recommended Code for this GWAS can be found in section 6. Basically, we randomly selected 100k white British from a total of 337k individuals that are recommended by the UKBB (i.e., QCed by the UKBB). We performed the GWASs and tested the test statistics for inflation using ldsc, sumher and the proposed method (based on individual level data using Haseman Elston regression). 2.3.1 ldsc &amp; sumher Table 2.5: UKBB recommended: LDSC regression line intercept estimates (SE) using ldsc and sumher ldsc sumher-gcta sumher-ldak-thin trait est se wald_p est se wald_p est se wald_p awake 1.017 0.007 9.8e-03 1.015 0.008 7.0e-02 1.012 0.009 1.7e-01 bmi 1.016 0.009 8.4e-02 0.995 0.010 6.1e-01 0.996 0.010 6.6e-01 chron 1.014 0.008 8.2e-02 1.008 0.009 3.4e-01 1.010 0.009 2.4e-01 ever 0.990 0.007 1.3e-01 0.986 0.008 1.1e-01 0.986 0.009 1.1e-01 fvc 1.036 0.009 2.8e-05 1.021 0.009 2.4e-02 1.018 0.009 6.4e-02 height 1.102 0.015 2.9e-11 1.030 0.012 1.1e-02 1.043 0.012 2.4e-04 hyper 1.010 0.007 1.7e-01 1.003 0.009 6.9e-01 1.003 0.009 7.3e-01 imp 1.029 0.009 1.2e-03 1.004 0.010 6.9e-01 1.005 0.010 5.8e-01 neur 1.010 0.009 2.9e-01 1.007 0.009 4.1e-01 1.001 0.009 8.7e-01 pulse 1.007 0.009 4.2e-01 0.992 0.009 4.0e-01 0.995 0.009 5.6e-01 quals 1.015 0.009 7.4e-02 1.004 0.009 6.9e-01 1.002 0.009 8.5e-01 reaction 1.016 0.007 2.1e-02 1.015 0.009 8.1e-02 1.016 0.009 7.1e-02 sbp 1.022 0.009 8.9e-03 1.016 0.009 8.0e-02 1.011 0.009 2.1e-01 snoring 1.005 0.008 5.6e-01 1.002 0.008 8.5e-01 1.001 0.009 8.9e-01 Note: p-values are based on the wald test that compares the ldsc regression line intercept against 1. p-values &lt;= Bonferroni corrected alpha (i.e., 0.05/14) are highlighted 2.3.2 Haseman Elston Regression Table 2.6: UKBB recommended: Heritability estimates (SE) using Haseman Elston regression under assumed heritability models trait right_est right_sd left_est left_sd all_est all_sd p_inflation under gcta awake 0.034 0.004 0.030 0.003 0.062 0.005 3.7e-01 bmi 0.135 0.005 0.124 0.005 0.251 0.007 1.9e-01 chron 0.061 0.005 0.048 0.004 0.104 0.006 3.0e-01 ever 0.034 0.004 0.040 0.004 0.071 0.005 3.9e-01 fvc 0.098 0.005 0.103 0.005 0.194 0.007 2.4e-01 height 0.274 0.007 0.264 0.006 0.522 0.009 8.7e-02 imp 0.142 0.005 0.142 0.005 0.276 0.007 1.9e-01 neur 0.064 0.006 0.055 0.005 0.115 0.007 3.3e-01 pulse 0.084 0.005 0.077 0.004 0.155 0.006 2.5e-01 quals 0.084 0.004 0.089 0.004 0.168 0.006 2.4e-01 reaction 0.037 0.004 0.040 0.004 0.075 0.005 3.7e-01 sbp 0.086 0.005 0.073 0.004 0.154 0.007 2.8e-01 snoring 0.038 0.004 0.032 0.004 0.067 0.005 3.7e-01 hyper 0.057 0.004 0.046 0.004 0.100 0.006 3.2e-01 under ldak-thin awake 0.033 0.004 0.031 0.003 0.062 0.005 4.2e-01 bmi 0.134 0.006 0.122 0.005 0.251 0.007 3.0e-01 chron 0.059 0.005 0.047 0.004 0.104 0.006 4.0e-01 ever 0.032 0.004 0.039 0.004 0.071 0.005 5.0e-01 fvc 0.094 0.005 0.101 0.005 0.194 0.007 4.3e-01 height 0.257 0.006 0.249 0.006 0.522 0.009 9.0e-01 imp 0.138 0.006 0.135 0.005 0.276 0.007 5.7e-01 neur 0.069 0.007 0.055 0.004 0.115 0.007 1.9e-01 pulse 0.081 0.005 0.074 0.004 0.155 0.006 4.6e-01 quals 0.083 0.004 0.088 0.004 0.168 0.006 3.8e-01 reaction 0.036 0.004 0.038 0.004 0.075 0.005 5.1e-01 sbp 0.085 0.005 0.072 0.004 0.154 0.007 3.7e-01 snoring 0.035 0.004 0.033 0.004 0.067 0.005 4.7e-01 hyper 0.055 0.004 0.045 0.004 0.100 0.006 5.0e-01 Note: p-values are for testing whether the sum of ‘left’ and ‘right’ heritability estimates are greater than the heritability estimate based on the whole genome. p-values &lt;= Bonferroni corrected alpha (i.e., 0.05/14) are highlighted 2.4 Control GWAS Code for this GWAS can be found in section 7. In short, we performed GWASs that serve as the control for the good versus bad GWASs comparison. This to ascertain that the observed inflation of bad GWAS test statistics is due to population stratification not random errors. We used a total of 100k that included 93,528 unrelated white British (also included in the bad and good GWAS) and 6,472 unrelated white British that were neither included in the good GWASs nor bad GWASs. 2.4.1 ldsc &amp; sumher Table 2.7: Control GWASs: LDSC regression line intercept estimates (SE) using ldsc and sumher ldsc sumher-gcta sumher-ldak-thin trait est se wald_p est se wald_p est se wald_p awake 0.996 0.006 5.4e-01 0.992 0.008 3.6e-01 0.994 0.008 4.5e-01 bmi 1.014 0.009 1.1e-01 0.991 0.010 3.9e-01 0.991 0.010 3.6e-01 chron 1.009 0.008 2.2e-01 1.008 0.009 3.4e-01 1.011 0.009 2.0e-01 ever 0.999 0.007 9.2e-01 0.996 0.009 6.4e-01 0.993 0.009 4.0e-01 fvc 1.034 0.010 5.1e-04 1.015 0.010 1.3e-01 1.007 0.010 4.6e-01 height 1.097 0.017 7.0e-09 1.019 0.012 1.1e-01 1.032 0.012 6.5e-03 hyper 1.017 0.010 7.9e-02 1.011 0.009 2.3e-01 1.000 0.009 9.6e-01 imp 1.012 0.011 2.8e-01 0.983 0.010 9.5e-02 0.988 0.010 2.1e-01 neur 1.001 0.009 9.4e-01 0.995 0.009 6.0e-01 0.997 0.009 6.9e-01 pulse 1.028 0.009 2.8e-03 1.012 0.009 1.8e-01 1.015 0.009 9.9e-02 quals 1.020 0.008 1.8e-02 1.014 0.009 1.5e-01 1.012 0.009 2.2e-01 reaction 1.013 0.007 7.4e-02 1.008 0.009 3.4e-01 1.006 0.009 4.7e-01 sbp 1.010 0.009 2.7e-01 1.000 0.009 9.8e-01 0.999 0.009 9.2e-01 snoring 1.010 0.007 1.7e-01 1.007 0.008 4.3e-01 1.008 0.009 3.8e-01 Note: p-values are based on the wald test that compares the ldsc regression line intercept against 1. p-values &lt;= Bonferroni corrected alpha (i.e., 0.05/14) are highlighted 2.4.2 Haseman Elston Regression Table 2.8: Control GWASs: Heritability estimates (SE) using Haseman Elston regression under assumed heritability models trait right_est right_sd left_est left_sd all_est all_sd p_inflation under gcta awake 0.034 0.004 0.030 0.003 0.062 0.005 3.7e-01 bmi 0.135 0.005 0.124 0.005 0.251 0.007 1.9e-01 chron 0.061 0.005 0.048 0.004 0.104 0.006 3.0e-01 ever 0.034 0.004 0.040 0.004 0.071 0.005 3.9e-01 fvc 0.098 0.005 0.103 0.005 0.194 0.007 2.4e-01 height 0.274 0.007 0.264 0.006 0.522 0.009 8.7e-02 imp 0.142 0.005 0.142 0.005 0.276 0.007 1.9e-01 neur 0.064 0.006 0.055 0.005 0.115 0.007 3.3e-01 pulse 0.084 0.005 0.077 0.004 0.155 0.006 2.5e-01 quals 0.084 0.004 0.089 0.004 0.168 0.006 2.4e-01 reaction 0.037 0.004 0.040 0.004 0.075 0.005 3.7e-01 sbp 0.086 0.005 0.073 0.004 0.154 0.007 2.8e-01 snoring 0.038 0.004 0.032 0.004 0.067 0.005 3.7e-01 hyper 0.057 0.004 0.046 0.004 0.100 0.006 3.2e-01 under ldak-thin awake 0.033 0.004 0.031 0.003 0.062 0.005 4.2e-01 bmi 0.134 0.006 0.122 0.005 0.251 0.007 3.0e-01 chron 0.059 0.005 0.047 0.004 0.104 0.006 4.0e-01 ever 0.032 0.004 0.039 0.004 0.071 0.005 5.0e-01 fvc 0.094 0.005 0.101 0.005 0.194 0.007 4.3e-01 height 0.257 0.006 0.249 0.006 0.522 0.009 9.0e-01 imp 0.138 0.006 0.135 0.005 0.276 0.007 5.7e-01 neur 0.069 0.007 0.055 0.004 0.115 0.007 1.9e-01 pulse 0.081 0.005 0.074 0.004 0.155 0.006 4.6e-01 quals 0.083 0.004 0.088 0.004 0.168 0.006 3.8e-01 reaction 0.036 0.004 0.038 0.004 0.075 0.005 5.1e-01 sbp 0.085 0.005 0.072 0.004 0.154 0.007 3.7e-01 snoring 0.035 0.004 0.033 0.004 0.067 0.005 4.7e-01 hyper 0.055 0.004 0.045 0.004 0.100 0.006 5.0e-01 Note: p-values are for testing whether the sum of ‘left’ and ‘right’ heritability estimates are greater than the heritability estimate based on the whole genome. p-values &lt;= Bonferroni corrected alpha (i.e., 0.05/14) are highlighted "],["good-vs-bad-gwas.html", "3 Good VS Bad GWAS 3.1 test statistics ~ LD score", " 3 Good VS Bad GWAS Here we investigate the inflation in test statistics from the bad GWASs. We want to find out 1) if the inflation is constant; 2) if it can be predicted in some way. 3.1 test statistics ~ LD score The inflation in GWAS test statistics due to confouding is not always constant, as assumed by LDSC. Below we plotted the chi-square test statistics from the bad (colored in red), good (orange), and control (gray) GWASs as a function of LD score ( Fig 3.1 ). The linear model assumed by LDSC is only appropriate for four traits, namely chron, pulse, quals, and snoring. For these traits, LDSC accounts for the inflation due to confouding (i.e., intercept) and the inflation due to polygenity (i.e., slope). However, LDSD is inadequate for other traits, where the inflation is non-linear. More specifically, for these traits, the test statistics for SNPs with a low LD score are much more inflated than would be expected by LDSC. Thus, it seems that ldsc can detect inflation in test statistics due to confouding but cannot be used to correct the inflation for some traits. Figure 3.1: Test statistics by LD score for good, bad and control GWASs. "],["good.html", "4 Good GWAS 4.1 QC of hp3 SNPs 4.2 extract covariates 4.3 GWAS 4.4 ldsc intercept 4.5 REML 4.6 HE", " 4 Good GWAS Here we do good GWASs. We will use 1.2M hapmap3 SNPs. But sill need to do some QC to these SNPs. 4.1 QC of hp3 SNPs # select 100k unrelated individuals with no missing covariates &amp; 14 phenotypes-- # individual with complete covariates R options(scipen = 100) library(vroom) dat=vroom(&quot;phen/covariates.use&quot;, col_names=F) out=dat[complete.cases(dat),c(1,2)] write.table(out,&quot;covariates-complete-cases.id&quot;, col.names=F, row.names=F, quote=F) # overlaping individuals across 14 traits cp icd10/unrelated.inds overlap.ind # unrelated white British dir=phen/continuous-traits/ for tt in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do mv overlap.ind temp awk &#39;(NR==FNR){a[$1];next}($1 in a){print $1, $2}&#39; temp $dir/$tt.raw.pheno &gt; overlap.ind wc -l overlap.ind echo $tt done rm temp # overlapping &amp; complete covariates awk &#39;NR==FNR{a[$1]; next} ($1 in a) {print $1, $1}&#39; overlap.ind covariates-complete-cases.id &gt; overlap-complete-cases.id #randomly pick 100k of these shuf overlap-complete-cases.id | head -n 100000 &gt; rand.100000 # QC SNPs----------------------------------------------------------------------- # stating number of SNPs= 1,184,423 for j in {1..22}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 20G #SBATCH -c 3 #SBATCH -t 1:0:0 ./plink2 --pfile ../gen/geno_plink/bhr$j \\ --keep ../unrelated/rand.100000 \\ --extract ../doug/ukbb.ldsc \\ --hwe 0.0001 \\ --hard-call-threshold .05 \\ --mach-r2-filter 0.8 2 \\ --make-bed \\ --memory 20000 \\ --out ../gen/tmp/bhr$j-unrel \\ --threads 3 &quot;&gt; sh_script/chr$j.sh done # submit jobs for j in {1..22}; do sbatch -A snpher ../sh_script/chr$j.sh done &gt; ../job-records/qc-unrel # merge files rm bfile-unrel.list for j in {1..22}; do echo &quot;../gen/tmp/bhr$j-unrel&quot; &gt;&gt;bfile-unrel.list done echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 20G #SBATCH -c 3 #SBATCH -t 40:0:0 ./ldak5.1 --make-bed ../gen/geno-unrel \\ --mbfile ../gen/bfile-unrel.list \\ --max-threads 3 \\ --exclude-dups YES &quot;&gt; sh_script/mbfile-unrel.sh # submit the script sbatch -A snpher ../sh_script/mbfile-unrel.sh &gt;../job-records/mbfiles-unrel # MAF &amp; call-rate awk &lt; geno-unrel.stats &#39;($5&gt;.01 &amp;&amp; $6&gt;=0.95 &amp;&amp; NR&gt;1){print $1}&#39; &gt; snps-unrel-inds.use # m = 1,103,209 SNPs 4.2 extract covariates head=read.table(&quot;phen/ukb45861.header&quot;, sep=&quot;,&quot;, header=F, stringsAsFactors = F) # function to get the variables get=function(nm){ colnum=grep(nm,head,fixed=TRUE) out=data.frame(t(rbind(colnum, head[,colnum]))) names(out)=c(&quot;column&quot;, &quot;field&quot;) return (out) } # get the variables out=rbind(get(&#39;21022-0&#39;), # age at recruitment: 21022 get(&#39;54-0&#39;), # assessment centre: 54 get(&#39;22000-0&#39;), # genotyping batch: 22000 get(&#39;22001-0&#39;), # genetic sex: 22001 get(&#39;189-0&#39;), # townsend get(&#39;22009-0&#39;), # genotype PC: 22009 get(&#39;21000-0&#39;)) # ethnic background row.names(out)=1:dim(out)[1] # remove unwanted out=out[-c(95:100),] write.table(out,&quot;phen/covariates.colnum&quot;, col.names=F, row.names=F, sep=&quot;\\t&quot;, quote=F) # extract dat from the full data set awk -F &#39;&quot;,&quot;&#39; &#39;(NR==FNR){a[$1];next}{printf &quot;%s\\&quot;&quot;, $1;for(i in a){printf &quot; \\&quot;%s\\&quot;&quot;, $i};printf &quot;\\n&quot;}&#39; phen/covariates.colnum phen/ukb45861.csv &gt; phen/covariates.dat #-------- # organize covariates #-------- options(scipen = 100) # all covariates var=read.table(&quot;phen/covariates.dat&quot;, header=T, stringsAsFactors = F) nm=names(var) # extract covariates var1=data.frame(eid=var$eid, age=var[,grep(&#39;21022&#39;, nm, fixed=T)], # age at recruitment sex_gen=var[,grep(&#39;22001&#39;, nm, fixed=T)], # genetic sex: 0 =F; 1 = M centre=var[,grep(&#39;X54&#39;, nm, fixed=T)], # assessment centre geno_batch=var[,grep(&#39;22000&#39;, nm, fixed=T)], # genotype batch townsend=var[,grep(&#39;189&#39;, nm, fixed=T)], # townsen var[,grep(&#39;22009&#39;, nm, fixed=T)], # genotype PC ethnicity=var[,grep(&#39;21000&#39;, nm, fixed=T)], # self-reported ethnicity stringsAsFactors = F) pcnm=strsplit(nm[grep(&#39;22009&#39;, nm, fixed=T)], &quot;[.]&quot;) pcnm=paste0(&quot;pc&quot;,unlist(lapply(pcnm,function(X) X[3]))) names(var1)[7:46]=pcnm # file that contains all covariates write.table(var1,&quot;phen/covariates.phen&quot;, col.names=T, row.names=F, quote=F) # create a file to use: no col.names &amp; continuous covariates only use=var1[,c(1,1:3,6:46)] write.table(names(use),&quot;phen/covariates.use-names&quot;, col.names=F, row.names=F, quote=F) write.table(use,&quot;phen/covariates.use&quot;, col.names=F, row.names=F, quote=F) 4.3 GWAS # linear regression------------------------------------------------------------- mkdir unrelated/gwas-good for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 10G #SBATCH -c 2 #SBATCH -t 10:0:0 ./ldak5.1 --linear ../unrelated/gwas-good/$i-linear \\ --pheno ../phen/continuous-traits/$i.raw.pheno \\ --bfile ../gen/geno-unrel \\ --keep ../unrelated/rand.100000 \\ --extract ../gen/snps-unrel-inds.use \\ --covar ../phen/covariates.use \\ --max-threads 2 \\ &quot;&gt; sh_script/$i-linear.sh done # submit files------------------------------------------------------------------ for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do sbatch -A snpher ../sh_script/$i-linear.sh done&gt;../job-records/gwas-good # check job completion---------------------------------------------------------- file=job-records/gwas-good jobs=`awk &#39;{print $4}&#39; $file` mkdir $file-tmp for i in $jobs; do jobinfo $i | awk -F &quot;:&quot; -v i=$i &#39;$1~/Name/ {print i, $2}&#39; &gt;&gt; $file-tmp/name.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/State/ {print$2}&#39; &gt;&gt; $file-tmp/state.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Cores/ {print$2}&#39; &gt;&gt; $file-tmp/cores.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Used walltime/ {print $2 &quot;:&quot; $3 &quot;:&quot; $4}&#39; &gt;&gt; $file-tmp/time.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Max Mem/ {split($2,a,/[(]/ ); print a[1]}&#39; &gt;&gt; $file-tmp/mem.tmp done paste $file-tmp/name.tmp \\ $file-tmp/state.tmp \\ $file-tmp/cores.tmp \\ $file-tmp/time.tmp \\ $file-tmp/mem.tmp \\ | awk &#39;BEGIN{print &quot;ID name state cores time mem&quot;}{print $0}&#39; &gt; $file.out rm -r $file-tmp # resubmit failed/incomplete jobs----------------------------------------------- for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do for j in {1..22}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 8G #SBATCH -c 2 #SBATCH -t 5:0:0 ./ldak5.1 --linear ../unrelated/gwas-good/$i-linear-chr-$j \\ --pheno ../phen/continuous-traits/$i.raw.pheno \\ --bfile ../gen/geno-unrel \\ --keep ../unrelated/rand.100000 \\ --extract ../gen/snps-unrel-inds.use \\ --covar ../phen/covariates.use \\ --max-threads 2 \\ --chr $j &quot;&gt; sh_script/$i-linear-chr-$j.sh done done # submit files------------------------------------------------------------------ for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do for j in {1..22}; do sbatch -A snpher ../sh_script/$i-linear-chr-$j.sh done done&gt;../job-records/gwas-good-resubmission # check job completion---------------------------------------------------------- file=job-records/gwas-good-resubmission jobs=`awk &#39;{print $4}&#39; $file` mkdir $file-tmp for i in $jobs; do jobinfo $i | awk -F &quot;:&quot; -v i=$i &#39;$1~/Name/ {print i, $2}&#39; &gt;&gt; $file-tmp/name.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/State/ {print$2}&#39; &gt;&gt; $file-tmp/state.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Cores/ {print$2}&#39; &gt;&gt; $file-tmp/cores.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Used walltime/ {print $2 &quot;:&quot; $3 &quot;:&quot; $4}&#39; &gt;&gt; $file-tmp/time.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Max Mem/ {split($2,a,/[(]/ ); print a[1]}&#39; &gt;&gt; $file-tmp/mem.tmp done paste $file-tmp/name.tmp \\ $file-tmp/state.tmp \\ $file-tmp/cores.tmp \\ $file-tmp/time.tmp \\ $file-tmp/mem.tmp \\ | awk &#39;BEGIN{print &quot;ID name state cores time mem&quot;}{print $0}&#39; &gt; $file.out rm -r $file-tmp # combine results # only need .summaries &amp; .pvalues #for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,reaction,sbp,snoring,hyper}; do i=quals for j in {1..22}; do if [ $j == 1 ]; then awk &#39;{print $0}&#39; $i-linear-chr-$j.summaries &gt; $i-linear.summaries awk &#39;{print $0}&#39; $i-linear-chr-$j.pvalues &gt; $i-linear.pvalues else awk &#39;NR&gt;1 {print $0}&#39; $i-linear-chr-$j.summaries &gt;&gt; $i-linear.summaries awk &#39;NR&gt;1 {print $0}&#39; $i-linear-chr-$j.pvalues &gt;&gt; $i-linear.pvalues fi done #done 4.4 ldsc intercept 4.4.1 under gcta #::::::::::::: # using original ldsc #::::::::::::: # format stats for ldsc--------------------------------------------------------- library(vroom) options(scipen = 100) rs=vroom(&quot;doug/ukbb.ldsc&quot;, col_names=F) phen=c(&quot;awake&quot;,&quot;bmi&quot;,&quot;chron&quot;,&quot;ever&quot;,&quot;fvc&quot;, &quot;height&quot;,&quot;imp&quot;,&quot;neur&quot;,&quot;pulse&quot;,&quot;quals&quot;, &quot;reaction&quot;,&quot;sbp&quot;,&quot;snoring&quot;,&quot;hyper&quot;, &quot;quals&quot;) for(i in phen){ stat=vroom(paste0(&quot;unrelated/gwas-good/&quot;,i,&quot;-linear.summaries&quot;), col_names=T) p=vroom(paste0(&quot;unrelated/gwas-good/&quot;,i,&quot;-linear.pvalues&quot;), col_names=T) m1=match(rs$X1, stat$Predictor) m2=match(rs$X1, p$Predictor) out=data.frame(SNP=rs$X2, N=stat$n[m1], Z=(sqrt(stat$Stat)*stat$Direction)[m1], A1=stat$A1[m1], A2=stat$A2[m1], pval=p$P[m2], stringsAsFactors=F) out=out[complete.cases(out),] write.table(out, paste0(&quot;unrelated/gwas-good/&quot;,i,&quot;-linear-rs.summaries&quot;), col.names=T, row.names=F, quote=F) } # perform ldsc------------------------------------------------------------------ mkdir out-good-gwas for i in {awake,bmi,chron,ever,fvc,height,quals,imp,neur,pulse,reaction,sbp,snoring,hyper}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 2G #SBATCH -c 3 #SBATCH -t 24:00:0 .././munge_sumstats.py \\ --sumstats ../../unrelated/gwas-good/$i-linear-rs.summaries \\ --out ../out-good-gwas/$i \\ --merge-alleles ../w_hm3.snplist .././ldsc.py \\ --h2 ../out-good-gwas/$i.sumstats.gz \\ --ref-ld-chr ../eur_w_ld_chr/ \\ --w-ld-chr ../eur_w_ld_chr/ \\ --out ../out-good-gwas/$i-ldsc &quot;&gt;sh_script/ldsc-$i-good-gwas.sh done # submit jobs------------------------------------------------------------------- for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,reaction,sbp,snoring,hyper,quals}; do sbatch -A snpher ../sh_script/ldsc-$i-good-gwas.sh done&gt;../../job-records/ldsc-good-gwas #::::::::::::: # using sumher #::::::::::::: # insert genetic distance into bim file----------------------------------------- head geno-unrel.fam &gt; small-unrel for j in {1..22}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --mem 8G #SBATCH -c 1 #SBATCH -t 3:00:0 #SBATCH --constraint \\&quot;s04|s05\\&quot; ./plink1.9 --bfile ../gen/geno-unrel \\ --chr $j \\ --cm-map /home/zhoux/snpher/faststorage/genetic_maps/genetic_map_chr@_combined_b37.txt \\ --make-bed \\ --out new$j \\ --keep ../gen/small-unrel &quot; &gt; sh_script/map$j done for j in {1..22}; do sbatch -A snpher ../sh_script/map$j done &gt; genetic-distance-hapmap3 cd /home/zhoux/dsmwpred/xuan/quality-control/qc-10oct/gen cat new{1..22}.bim | awk &#39;{print $2, $3}&#39; &gt; maps-hapmap3.txt rm new{1..22}.{bim,bed,fam,log} awk &#39;(NR==FNR){arr[$1]=$2;next}{print $1, $2, arr[$2], $4, $5, $6}&#39; &gt; geno-unrel.bim2 maps-hapmap3.txt geno-unrel.bim mv geno-unrel.bim geno-unrel.bim0 mv geno-unrel.bim2 geno-unrel.bim # compute tagging under gcta---------------------------------------------------- for j in {1..22}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 5G #SBATCH -c 1 #SBATCH -t 5:0:0 ./ldak5.1 --calc-tagging ../tagging/gcta-hapmap3-chr-$j \\ --bfile ../gen/geno-unrel \\ --ignore-weights YES \\ --power -1 \\ --window-cm 1 \\ --chr $j &quot;&gt; sh_script/tagging-gcta-hapmap3-chr$j done for j in {1..22}; do sbatch -A snpher ../sh_script/tagging-gcta-hapmap3-chr$j done &gt; ../job-records/tagging-gcta-hapmap3 # check job completion---------------------------------------------------------- file=job-records/tagging-gcta-hapmap3 jobs=`awk &#39;{print $4}&#39; $file` mkdir $file-tmp for i in $jobs; do jobinfo $i | awk -F &quot;:&quot; -v i=$i &#39;$1~/Name/ {print i, $2}&#39; &gt;&gt; $file-tmp/name.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/State/ {print$2}&#39; &gt;&gt; $file-tmp/state.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Cores/ {print$2}&#39; &gt;&gt; $file-tmp/cores.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Used walltime/ {print $2 &quot;:&quot; $3 &quot;:&quot; $4}&#39; &gt;&gt; $file-tmp/time.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Max Mem/ {split($2,a,/[(]/ ); print a[1]}&#39; &gt;&gt; $file-tmp/mem.tmp done paste $file-tmp/name.tmp \\ $file-tmp/state.tmp \\ $file-tmp/cores.tmp \\ $file-tmp/time.tmp \\ $file-tmp/mem.tmp \\ | awk &#39;BEGIN{print &quot;ID name state cores time mem&quot;}{print $0}&#39; &gt; $file.out rm -r $file-tmp # merge tagging files----------------------------------------------------------- rm list.txt for j in {1..22}; do echo &quot;tagging/gcta-hapmap3-chr-$j.tagging&quot; &gt;&gt; list.txt done ./ldak5.1 --join-tagging tagging/gcta-hapmap3 --taglist list.txt # ldsc intercept---------------------------------------------------------------- mkdir sumher-good for i in {awake,bmi,chron,ever,fvc,height,quals,imp,neur,pulse,reaction,sbp,snoring,hyper}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 5G #SBATCH -c 1 #SBATCH -t 5:0:0 ./ldak5.1 --sum-hers ../sumher-good/$i-sumher-gcta \\ --tagfile ../tagging/gcta-hapmap3.tagging \\ --summary ../unrelated/gwas-good/$i-linear.summaries \\ --check-sums NO \\ --intercept YES &quot;&gt; sh_script/$i-sumher-gcta-unrelated done for i in {awake,bmi,chron,ever,fvc,height,quals,imp,neur,pulse,reaction,sbp,snoring,hyper}; do sbatch -A snpher ../sh_script/$i-sumher-gcta-unrelated done&gt;../job-records/sumher-gcta-unrelated 4.4.2 under ldak-thin # get weights------------------------------------------------------------------- awk &lt; ldak-thin/ldak-thin-hapmap3.in &#39;{print $1, 1}&#39; &gt; ldak-thin/weights.ldak-thin-hapmap3 # calculate tagging under ldak-thin--------------------------------------------- for j in {1..22}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --partition normal #SBATCH --mem 40G #SBATCH -c 5 #SBATCH -t 10:0:0 #SBATCH --constraint \\&quot;s04|s05\\&quot; ./ldak5.1 --calc-tagging ../tagging/ldak-thin-hapmap3-chr-$j \\ --bfile ../gen/geno-unrel \\ --weights ../ldak-thin/weights.ldak-thin-hapmap3 \\ --power -.25 \\ --window-cm 1 \\ --chr $j \\ --save-matrix YES \\ --max-threads 5 &quot; &gt; sh_script/tagging-ldak-thin-hapmap3-chr$j.sh done # submit scripts for j in {1..22}; do sbatch -A snpher ../sh_script/tagging-ldak-thin-hapmap3-chr$j.sh done &gt; ../job-records/tagging-ldak-thin-hapmap3 # check job completion---------------------------------------------------------- file=job-records/tagging-ldak-thin-hapmap3 jobs=`awk &#39;{print $4}&#39; $file` mkdir $file-tmp for i in $jobs; do jobinfo $i | awk -F &quot;:&quot; -v i=$i &#39;$1~/Name/ {print i, $2}&#39; &gt;&gt; $file-tmp/name.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/State/ {print$2}&#39; &gt;&gt; $file-tmp/state.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Cores/ {print$2}&#39; &gt;&gt; $file-tmp/cores.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Used walltime/ {print $2 &quot;:&quot; $3 &quot;:&quot; $4}&#39; &gt;&gt; $file-tmp/time.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Max Mem/ {split($2,a,/[(]/ ); print a[1]}&#39; &gt;&gt; $file-tmp/mem.tmp done paste $file-tmp/name.tmp \\ $file-tmp/state.tmp \\ $file-tmp/cores.tmp \\ $file-tmp/time.tmp \\ $file-tmp/mem.tmp \\ | awk &#39;BEGIN{print &quot;ID name state cores time mem&quot;}{print $0}&#39; &gt; $file.out rm -r $file-tmp # merge tagging files----------------------------------------------------------- rm list.txt rm matlist.txt for j in {1..22}; do echo &quot;tagging/ldak-thin-hapmap3-chr-$j.tagging&quot; &gt;&gt; list.txt echo &quot;tagging/ldak-thin-hapmap3-chr-$j.matrix&quot; &gt;&gt; matlist.txt done ./ldak5.1 --join-tagging tagging/ldak-thin-hapmap3 --taglist list.txt --matlist matlist.txt # ldsc intercept---------------------------------------------------------------- for i in {awake,bmi,chron,ever,fvc,height,quals,imp,neur,pulse,reaction,sbp,snoring,hyper}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 5G #SBATCH -c 1 #SBATCH -t 00:30:0 ./ldak5.1 --sum-hers ../sumher-good/$i-sumher-ldak-thin \\ --tagfile ../tagging/ldak-thin-hapmap3.tagging \\ --summary ../unrelated/gwas-good/$i-linear.summaries \\ --check-sums NO \\ --intercept YES &quot;&gt; sh_script/$i-sumher-ldak-thin-unrelated done for i in {awake,bmi,chron,ever,fvc,height,quals,imp,neur,pulse,reaction,sbp,snoring,hyper}; do sbatch -A snpher ../sh_script/$i-sumher-ldak-thin-unrelated done&gt;../job-records/sumher-ldak-thin-unrelated 4.4.3 summary # original ldsc grep Intercept *ldsc.log | awk &#39;{split($1, a, /[-]/); split($3, b, /[()]/); print a[1], $2, b[2]}&#39; &gt; ../../summary/ldsc-good # sumher under gcta grep Intercept_Estimate *gcta.extra | awk &#39;{ split($1, a, /[-]/); print a[1], $2}&#39; &gt;../summary/sumher-gcta-good-est grep Intercept_SD *gcta.extra | awk &#39;{ split($1, a, /[-]/); print a[1], $2}&#39; &gt;../summary/sumher-gcta-good-sd cd ../summary/ paste sumher-gcta-good-est sumher-gcta-good-sd | awk &#39;{print $1, $2, $4}&#39; &gt; sumber-gcta-good # submer under ldak-thin grep Intercept_Estimate *ldak-thin.extra | awk &#39;{ split($1, a, /[-]/); print a[1], $2}&#39; &gt;../summary/sumher-ldak-thin-good-est grep Intercept_SD *ldak-thin.extra | awk &#39;{ split($1, a, /[-]/); print a[1], $2}&#39; &gt;../summary/sumher-ldak-thin-good-sd cd ../summary/ paste sumher-ldak-thin-good-est sumher-ldak-thin-good-sd | awk &#39;{print $1, $2, $4}&#39; &gt; sumher-ldak-thin-good 4.5 REML 4.5.1 making grms # making grm ------------------------------------------------------------------- #::: # under gcta #::: # all snps echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --partition normal #SBATCH --mem 60G #SBATCH -c 10 #SBATCH -t 20:0:0 #SBATCH --constraint \\&quot;s04|s05\\&quot; ./ldak5.1 --max-threads 10 \\ --calc-kins-direct ../kinship/gcta-all-unrel \\ --bfile ../gen/geno-unrel \\ --power -1 \\ --ignore-weights YES \\ --single YES &quot; &gt; sh_script/grm-all-snps-unrel sbatch -A snpher ../sh_script/grm-all-snps-unrel &gt; ../job-records/grm-all-snps-unrel # grm by snp blocks: right vs. left awk &#39;$1&lt;8 {print $2}&#39; geno-unrel.bim &gt; left-hapmap3.snps awk &#39;$1&gt;=8 {print $2}&#39; geno-unrel.bim &gt; right-hapmap3.snps for i in left right; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --partition normal #SBATCH --mem 60G #SBATCH -c 10 #SBATCH -t 20:0:0 #SBATCH --constraint \\&quot;s04|s05\\&quot; ./ldak5.1 --max-threads 10 \\ --calc-kins-direct ../kinship/gcta-$i-unrel \\ --bfile ../gen/geno-unrel \\ --extract ../gen/$i-hapmap3.snps \\ --power -1 \\ --ignore-weights YES \\ --single YES &quot; &gt; sh_script/grm-gcta-$i-unrel done for i in left right; do sbatch -A snpher ../sh_script/grm-gcta-$i-unrel done &gt; ../job-records/grm-gcta-by-snps-unrel #::: # under ldak-thin #::: #----------- # 1. thin snps #----------- for j in {1..22}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --partition normal #SBATCH --mem 10G #SBATCH -c 4 #SBATCH -t 4:0:0 #SBATCH --constraint \\&quot;s04|s05\\&quot; ./ldak5.1 --max-threads 4 \\ --window-prune 0.98 \\ --window-kb 100 \\ --extract ../gen/snps-unrel-inds.use \\ --bfile ../gen/geno-unrel \\ --thin ../ldak-thin/chr$j-hapmap3 \\ --chr $j &quot; &gt; sh_script/ldak-thin$j-hapmap3 done # submit script for j in {1..22}; do sbatch -A snpher ../sh_script/ldak-thin$j-hapmap3 done &gt; ../job-records/ldak-thin-hapmap3 # check job completion--- file=job-records/ldak-thin-hapmap3 jobs=`awk &#39;{print $4}&#39; $file` mkdir $file-tmp for i in $jobs; do jobinfo $i | awk -F &quot;:&quot; -v i=$i &#39;$1~/Name/ {print i, $2}&#39; &gt;&gt; $file-tmp/name.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/State/ {print$2}&#39; &gt;&gt; $file-tmp/state.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Cores/ {print$2}&#39; &gt;&gt; $file-tmp/cores.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Used walltime/ {print $2 &quot;:&quot; $3 &quot;:&quot; $4}&#39; &gt;&gt; $file-tmp/time.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Max Mem/ {split($2,a,/[(]/ ); print a[1]}&#39; &gt;&gt; $file-tmp/mem.tmp done paste $file-tmp/name.tmp \\ $file-tmp/state.tmp \\ $file-tmp/cores.tmp \\ $file-tmp/time.tmp \\ $file-tmp/mem.tmp \\ | awk &#39;BEGIN{print &quot;ID name state cores time mem&quot;}{print $0}&#39; &gt; $file.out rm -r $file-tmp # combine snp list cat ldak-thin/chr{1..22}-hapmap3.in &gt; ldak-thin/ldak-thin-hapmap3.in #---------------------- # 2. kinship matrix under ldak-thin #------------------------ echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --partition normal #SBATCH --mem 60G #SBATCH -c 10 #SBATCH -t 20:0:0 #SBATCH --constraint \\&quot;s04|s05\\&quot; ./ldak5.1 --max-threads 10 \\ --calc-kins-direct ../kinship/ldak-thin-all-unrel \\ --bfile ../gen/geno-unrel \\ --extract ../ldak-thin/ldak-thin-hapmap3.in \\ --power -0.25 \\ --ignore-weights YES \\ --single YES &quot; &gt; sh_script/ldak-thin-grm-all-snps-unrel sbatch -A snpher ../sh_script/ldak-thin-grm-all-snps-unrel &gt; ../job-records/ldak-thin-grm-all-snps-unrel # grm by snp blocks: right vs. left awk &#39;{split($1, a, /[:]/); if (a[1]&lt;8) print $1}&#39; \\ ldak-thin/ldak-thin-hapmap3.in &gt; gen/left-ldak-thin-hapmap3.snps awk &#39;{split($1, a, /[:]/); if (a[1]&gt;=8) print $1}&#39; \\ ldak-thin/ldak-thin-hapmap3.in &gt; gen/right-ldak-thin-hapmap3.snps for i in left right; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --partition normal #SBATCH --mem 60G #SBATCH -c 10 #SBATCH -t 20:0:0 #SBATCH --constraint \\&quot;s04|s05\\&quot; ./ldak5.1 --max-threads 10 \\ --calc-kins-direct ../kinship/ldak-thin-$i-unrel \\ --bfile ../gen/geno-unrel \\ --extract ../gen/$i-ldak-thin-hapmap3.snps \\ --power -0.25 \\ --ignore-weights YES \\ --single YES &quot; &gt; sh_script/ldak-thin-grm-$i-unrel done for i in left right; do sbatch -A snpher ../sh_script/ldak-thin-grm-$i-unrel done &gt; ../job-records/grm-ldak-thin-by-snps-unrel 4.5.2 fast-reml #::: # under gcta #::: # make script files------------------------------------------------------------- mkdir reml-good for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do for k in all left right; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 100G #SBATCH -c 2 #SBATCH -t 5:0:0 ./ldak5.1 --fast-reml ../reml-good/$i-gcta-$k \\ --repetitions 20 \\ --pheno ../phen/continuous-traits/$i.raw.pheno \\ --keep ../unrelated/rand.100000 \\ --covar ../phen/covariates.use \\ --grm ../kinship/gcta-$k-unrel \\ --max-threads 2 \\ --single YES &quot;&gt; sh_script/$i-reml-good-gcta-$k-snps done done # submit script files----------------------------------------------------------- for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do for k in all left right; do sbatch -A snpher ../sh_script/$i-reml-good-gcta-$k-snps done done&gt;../job-records/reml-good-gcta # check job completion---------------------------------------------------------- file=job-records/reml-good-gcta jobs=`awk &#39;{print $4}&#39; $file` mkdir $file-tmp for i in $jobs; do jobinfo $i | awk -F &quot;:&quot; -v i=$i &#39;$1~/Name/ {print i, $2}&#39; &gt;&gt; $file-tmp/name.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/State/ {print$2}&#39; &gt;&gt; $file-tmp/state.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Cores/ {print$2}&#39; &gt;&gt; $file-tmp/cores.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Used walltime/ {print $2 &quot;:&quot; $3 &quot;:&quot; $4}&#39; &gt;&gt; $file-tmp/time.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Max Mem/ {split($2,a,/[(]/ ); print a[1]}&#39; &gt;&gt; $file-tmp/mem.tmp done paste $file-tmp/name.tmp \\ $file-tmp/state.tmp \\ $file-tmp/cores.tmp \\ $file-tmp/time.tmp \\ $file-tmp/mem.tmp \\ | awk &#39;BEGIN{print &quot;ID name state cores time mem&quot;}{print $0}&#39; &gt; $file.out rm -r $file-tmp #::: # under ldak-thin #::: # make script files------------------------------------------------------------- for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do for k in all left right; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 100G #SBATCH -c 2 #SBATCH -t 5:0:0 ./ldak5.1 --fast-reml ../reml-good/$i-ldak-thin-$k \\ --repetitions 20 \\ --pheno ../phen/continuous-traits/$i.raw.pheno \\ --keep ../unrelated/rand.100000 \\ --covar ../phen/covariates.use \\ --grm ../kinship/ldak-thin-$k-unrel \\ --max-threads 2 \\ --single YES &quot;&gt; sh_script/$i-reml-good-ldak-thin-$k-snps done done # submit script files----------------------------------------------------------- for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do for k in all left right; do sbatch -A snpher ../sh_script/$i-reml-good-ldak-thin-$k-snps done done &gt;../job-records/reml-good-ldak-thin # check job completion---------------------------------------------------------- file=job-records/reml-good-ldak-thin jobs=`awk &#39;{print $4}&#39; $file` mkdir $file-tmp for i in $jobs; do jobinfo $i | awk -F &quot;:&quot; -v i=$i &#39;$1~/Name/ {print i, $2}&#39; &gt;&gt; $file-tmp/name.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/State/ {print$2}&#39; &gt;&gt; $file-tmp/state.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Cores/ {print$2}&#39; &gt;&gt; $file-tmp/cores.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Used walltime/ {print $2 &quot;:&quot; $3 &quot;:&quot; $4}&#39; &gt;&gt; $file-tmp/time.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Max Mem/ {split($2,a,/[(]/ ); print a[1]}&#39; &gt;&gt; $file-tmp/mem.tmp done paste $file-tmp/name.tmp \\ $file-tmp/state.tmp \\ $file-tmp/cores.tmp \\ $file-tmp/time.tmp \\ $file-tmp/mem.tmp \\ | awk &#39;BEGIN{print &quot;ID name state cores time mem&quot;}{print $0}&#39; &gt; $file.out rm -r $file-tmp 4.5.3 inflation test #:::::::::::: # under gcta #:::::::::::: # extract h2 estimates --------------------------------------------------------- # right for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do outfile=reml-good/$i-gcta-right.reml awk -v i=$i &#39;$1==&quot;Her_All&quot; {print i, $2, $3}&#39; $outfile &gt;&gt; summary/est.tmp awk &#39;$1==&quot;Converged&quot; {print$2}&#39; $outfile &gt;&gt; summary/converge.tmp done paste summary/est.tmp \\ summary/converge.tmp \\ | awk &#39;BEGIN{print &quot;code h2 se converge&quot;}{print i, $0}&#39; \\ &gt; summary/reml-gcta-good.right rm summary/est.tmp summary/converge.tmp # left for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do outfile=reml-good/$i-gcta-left.reml awk -v i=$i &#39;$1==&quot;Her_All&quot; {print i, $2, $3}&#39; $outfile &gt;&gt; summary/est.tmp awk &#39;$1==&quot;Converged&quot; {print$2}&#39; $outfile &gt;&gt; summary/converge.tmp done paste summary/est.tmp \\ summary/converge.tmp \\ | awk &#39;BEGIN{print &quot;code h2 se converge&quot;}{print i, $0}&#39; \\ &gt; summary/reml-gcta-good.left rm summary/est.tmp summary/converge.tmp # all for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do outfile=reml-good/$i-gcta-all.reml awk -v i=$i &#39;$1==&quot;Her_All&quot; {print i, $2, $3}&#39; $outfile &gt;&gt; summary/est.tmp awk &#39;$1==&quot;Converged&quot; {print$2}&#39; $outfile &gt;&gt; summary/converge.tmp done paste summary/est.tmp \\ summary/converge.tmp \\ | awk &#39;BEGIN{print &quot;code h2 se converge&quot;}{print i, $0}&#39; \\ &gt; summary/reml-gcta-good.all rm summary/est.tmp summary/converge.tmp # inflation test---------------------------------------------------------------- R full=read.table(paste0(&quot;summary/reml-gcta-good.all&quot;), header=T) left=read.table(paste0(&quot;summary/reml-gcta-good.left&quot;), header=T) right=read.table(paste0(&quot;summary/reml-gcta-good.right&quot;), header=T) # some analyses did not complete --&gt; match dataframes dim(full);dim(left);dim(right) common=intersect(full$code, left$code) common=intersect(common, right$code) m1=match(common, right$code) m2=match(common, full$code) m3=match(common, left$code) right=right[m1,] full=full[m2,] left=left[m3,] for(i in 1:dim(full)[1]){ est1=left$h2[i] sd1=left$se[i] est2=right$h2[i] sd2=right$se[i] est=full$h2[i] sd=full$se[i] N=100000 d1=rnorm(N,est1,sd1) d2=rnorm(N,est2,sd2) d=rnorm(N,est,sd) p=1-mean(d1+d2-d&gt;=0) out0=data.frame(code=full$code[i], right_est=est2, right_sd=sd2, left_est=est1, left_sd=sd1, all_est=est, all_sd=sd, p_inflation=p) if(i==1){out=out0}else{out=rbind(out,out0)} } write.table(out, paste0(&quot;summary/reml-gcta-inflation-good-gwas.txt&quot;), col.names=T, row.names=F, quote=F) #:::::::::::: # under ldak-thin #:::::::::::: # extract h2 estimates --------------------------------------------------------- # right for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do outfile=reml-good/$i-ldak-thin-right.reml awk -v i=$i &#39;$1==&quot;Her_All&quot; {print i, $2, $3}&#39; $outfile &gt;&gt; summary/est.tmp awk &#39;$1==&quot;Converged&quot; {print$2}&#39; $outfile &gt;&gt; summary/converge.tmp done paste summary/est.tmp \\ summary/converge.tmp \\ | awk &#39;BEGIN{print &quot;code h2 se converge&quot;}{print i, $0}&#39; \\ &gt; summary/reml-ldak-thin-good.right rm summary/est.tmp summary/converge.tmp # left for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do outfile=reml-good/$i-ldak-thin-left.reml awk -v i=$i &#39;$1==&quot;Her_All&quot; {print i, $2, $3}&#39; $outfile &gt;&gt; summary/est.tmp awk &#39;$1==&quot;Converged&quot; {print$2}&#39; $outfile &gt;&gt; summary/converge.tmp done paste summary/est.tmp \\ summary/converge.tmp \\ | awk &#39;BEGIN{print &quot;code h2 se converge&quot;}{print i, $0}&#39; \\ &gt; summary/reml-ldak-thin-good.left rm summary/est.tmp summary/converge.tmp # all for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do outfile=reml-good/$i-ldak-thin-all.reml awk -v i=$i &#39;$1==&quot;Her_All&quot; {print i, $2, $3}&#39; $outfile &gt;&gt; summary/est.tmp awk &#39;$1==&quot;Converged&quot; {print$2}&#39; $outfile &gt;&gt; summary/converge.tmp done paste summary/est.tmp \\ summary/converge.tmp \\ | awk &#39;BEGIN{print &quot;code h2 se converge&quot;}{print i, $0}&#39; \\ &gt; summary/reml-ldak-thin-good.all rm summary/est.tmp summary/converge.tmp # inflation test---------------------------------------------------------------- R full=read.table(paste0(&quot;summary/reml-ldak-thin-good.all&quot;), header=T) left=read.table(paste0(&quot;summary/reml-ldak-thin-good.left&quot;), header=T) right=read.table(paste0(&quot;summary/reml-ldak-thin-good.right&quot;), header=T) # some analyses did not complete --&gt; match dataframes dim(full);dim(left);dim(right) common=intersect(full$code, left$code) common=intersect(common, right$code) m1=match(common, right$code) m2=match(common, full$code) m3=match(common, left$code) right=right[m1,] full=full[m2,] left=left[m3,] for(i in 1:dim(full)[1]){ est1=left$h2[i] sd1=left$se[i] est2=right$h2[i] sd2=right$se[i] est=full$h2[i] sd=full$se[i] N=100000 d1=rnorm(N,est1,sd1) d2=rnorm(N,est2,sd2) d=rnorm(N,est,sd) p=1-mean(d1+d2-d&gt;=0) out0=data.frame(code=full$code[i], right_est=est2, right_sd=sd2, left_est=est1, left_sd=sd1, all_est=est, all_sd=sd, p_inflation=p) if(i==1){out=out0}else{out=rbind(out,out0)} } write.table(out, paste0(&quot;summary/reml-ldak-thin-inflation.txt&quot;), col.names=T, row.names=F, quote=F) 4.6 HE 4.6.1 estimation # regress grm on covariates----------------------------------------------------- for grm in gcta-all-unrel gcta-left-unrel gcta-right-unrel ldak-thin-all-unrel ldak-thin-left-unrel ldak-thin-right-unrel; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 50G #SBATCH -c 5 #SBATCH -t 10:0:0 ./ldak5.1 --adjust-grm ../kinship/$grm.covar \\ --grm ../kinship/$grm \\ --covar ../phen/covariates.use \\ --max-threads 5 &quot;&gt; sh_script/$grm-adjust-unrel.sh done # submit jobs for grm in gcta-all-unrel gcta-left-unrel gcta-right-unrel ldak-thin-all-unrel ldak-thin-left-unrel ldak-thin-right-unrel; do sbatch -A snpher ../sh_script/$grm-adjust-unrel.sh done &gt; ../job-records/grm-unrel-adjust-for-HE # check job completion---------------------------------------------------------- file=job-records/grm-unrel-adjust-for-HE jobs=`awk &#39;{print $4}&#39; $file` mkdir $file-tmp for i in $jobs; do jobinfo $i | awk -F &quot;:&quot; -v i=$i &#39;$1~/Name/ {print i, $2}&#39; &gt;&gt; $file-tmp/name.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/State/ {print$2}&#39; &gt;&gt; $file-tmp/state.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Cores/ {print$2}&#39; &gt;&gt; $file-tmp/cores.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Used walltime/ {print $2 &quot;:&quot; $3 &quot;:&quot; $4}&#39; &gt;&gt; $file-tmp/time.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Max Mem/ {split($2,a,/[(]/ ); print a[1]}&#39; &gt;&gt; $file-tmp/mem.tmp done paste $file-tmp/name.tmp \\ $file-tmp/state.tmp \\ $file-tmp/cores.tmp \\ $file-tmp/time.tmp \\ $file-tmp/mem.tmp \\ | awk &#39;BEGIN{print &quot;ID name state cores time mem&quot;}{print $0}&#39; &gt; $file.out rm -r $file-tmp # HE under gcta----------------------------------------------------------------- for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do for k in all left right; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 2G #SBATCH -c 1 #SBATCH -t 00:30:0 ./ldak5.1 --he ../he-good/$i-he-gcta-$k \\ --pheno ../phen/continuous-traits/$i.raw.pheno \\ --grm ../kinship/gcta-$k-unrel.covar \\ --kinship-details NO \\ --check-root NO \\ --covar ../phen/covariates.use \\ --max-threads 1 \\ --memory-save YES &quot;&gt; sh_script/$i-he-good-gcta-$k-snps.sh done done # submit files------------------------------------------------------------------ for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do for k in all left right; do sbatch -A snpher ../sh_script/$i-he-good-gcta-$k-snps.sh done done &gt; ../job-records/he-good-gcta # HE under ldak-thin------------------------------------------------------------ for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do for k in all left right; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 2G #SBATCH -c 1 #SBATCH -t 0:30:0 ./ldak5.1 --he ../he-good/$i-he-ldak-thin-$k \\ --pheno ../phen/continuous-traits/$i.raw.pheno \\ --grm ../kinship/ldak-thin-$k-unrel.covar \\ --kinship-details NO \\ --check-root NO \\ --covar ../phen/covariates.use \\ --max-threads 1 \\ --memory-save YES &quot;&gt; sh_script/$i-he-good-ldak-thin-$k-snps.sh done done # submit files------------------------------------------------------------------ for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do for k in all left right; do sbatch -A snpher ../sh_script/$i-he-good-ldak-thin-$k-snps.sh done done &gt; ../job-records/he-good-ldak-thin 4.6.2 summary #:::::::::::: # under gcta #:::::::::::: # extract h2 estimates --------------------------------------------------------- # right rm summary/he-gcta-unrel.right for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do outfile=he-good/$i-he-gcta-right.he awk -v i=$i &#39;$1==&quot;Her_All&quot; {print i, $2, $3}&#39; $outfile &gt;&gt; summary/he-gcta-unrel.right done # left rm summary/he-gcta-unrel.left for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do outfile=he-good/$i-he-gcta-left.he awk -v i=$i &#39;$1==&quot;Her_All&quot; {print i, $2, $3}&#39; $outfile &gt;&gt; summary/he-gcta-unrel.left done # all rm summary/he-gcta-unrel.all for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do outfile=he-good/$i-he-gcta-all.he awk -v i=$i &#39;$1==&quot;Her_All&quot; {print i, $2, $3}&#39; $outfile &gt;&gt; summary/he-gcta-unrel.all done # inflation test---------------------------------------------------------------- R full=read.table(paste0(&quot;summary/he-gcta-unrel.all&quot;), header=F) left=read.table(paste0(&quot;summary/he-gcta-unrel.left&quot;), header=F) right=read.table(paste0(&quot;summary/he-gcta-unrel.right&quot;), header=F) names(full)=names(left)=names(right)=c(&quot;code&quot;,&quot;h2&quot;,&quot;se&quot;) # some analyses did not complete --&gt; match dataframes dim(full);dim(left);dim(right) common=intersect(full$code, left$code) common=intersect(common, right$code) m1=match(common, right$code) m2=match(common, full$code) m3=match(common, left$code) right=right[m1,] full=full[m2,] left=left[m3,] for(i in 1:dim(full)[1]){ est1=left$h2[i] sd1=left$se[i] est2=right$h2[i] sd2=right$se[i] est=full$h2[i] sd=full$se[i] N=100000 d1=rnorm(N,est1,sd1) d2=rnorm(N,est2,sd2) d=rnorm(N,est,sd) p=1-mean(d1+d2-d&gt;=0) out0=data.frame(code=full$code[i], right_est=est2, right_sd=sd2, left_est=est1, left_sd=sd1, all_est=est, all_sd=sd, p_inflation=p) if(i==1){out=out0}else{out=rbind(out,out0)} } write.table(out, paste0(&quot;summary/he-gcta-inflation-unrel-gwas.txt&quot;), col.names=T, row.names=F, quote=F) #:::::::::::: # under ldak-thin #:::::::::::: # extract h2 estimates --------------------------------------------------------- # right rm summary/he-ldak-thin-unrel.right for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do outfile=he-good/$i-he-ldak-thin-right.he awk -v i=$i &#39;$1==&quot;Her_All&quot; {print i, $2, $3}&#39; $outfile &gt;&gt; summary/he-ldak-thin-unrel.right done # left rm summary/he-ldak-thin-unrel.left for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do outfile=he-good/$i-he-ldak-thin-left.he awk -v i=$i &#39;$1==&quot;Her_All&quot; {print i, $2, $3}&#39; $outfile &gt;&gt; summary/he-ldak-thin-unrel.left done # all rm summary/he-ldak-thin-unrel.all for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do outfile=he-good/$i-he-ldak-thin-all.he awk -v i=$i &#39;$1==&quot;Her_All&quot; {print i, $2, $3}&#39; $outfile &gt;&gt; summary/he-ldak-thin-unrel.all done # inflation test---------------------------------------------------------------- R full=read.table(paste0(&quot;summary/he-ldak-thin-unrel.all&quot;), header=F) left=read.table(paste0(&quot;summary/he-ldak-thin-unrel.left&quot;), header=F) right=read.table(paste0(&quot;summary/he-ldak-thin-unrel.right&quot;), header=F) names(full)=names(left)=names(right)=c(&quot;code&quot;,&quot;h2&quot;,&quot;se&quot;) # some analyses did not complete --&gt; match dataframes dim(full);dim(left);dim(right) common=intersect(full$code, left$code) common=intersect(common, right$code) m1=match(common, right$code) m2=match(common, full$code) m3=match(common, left$code) right=right[m1,] full=full[m2,] left=left[m3,] for(i in 1:dim(full)[1]){ est1=left$h2[i] sd1=left$se[i] est2=right$h2[i] sd2=right$se[i] est=full$h2[i] sd=full$se[i] N=100000 d1=rnorm(N,est1,sd1) d2=rnorm(N,est2,sd2) d=rnorm(N,est,sd) p=1-mean(d1+d2-d&gt;=0) out0=data.frame(code=full$code[i], right_est=est2, right_sd=sd2, left_est=est1, left_sd=sd1, all_est=est, all_sd=sd, p_inflation=p) if(i==1){out=out0}else{out=rbind(out,out0)} } write.table(out, paste0(&quot;summary/he-ldak-thin-inflation-unrel-gwas.txt&quot;), col.names=T, row.names=F, quote=F) "],["bad.html", "5 Bad GWAS 5.1 ID list 5.2 GWAS 5.3 ldsc intercept 5.4 REML 5.5 HE", " 5 Bad GWAS 5.1 ID list 5.1.1 initial selection Randomly select participants with complete data and use the SNP list as for unrelated. # extract white, asian &amp; black from ukbb---------------------------------------- R dat=read.table(&quot;phen/covariates.phen&quot;, header=T, stringsAsFactors = F) # White: British(1001) # Asian or Asian British: Indian(3001)+Pakistani(3002)+Bangladeshi(3003)+other Asian backgroud(3004) # Black: Caribbean(4001)+African(4002)+other Black Background(4003) dat=dat[complete.cases(dat),] white=1001 asian=3001:3004 black=4001:4003 out1=dat[dat$ethnicity%in%white,] out2=dat[dat$ethnicity%in%asian,] out3=dat[dat$ethnicity%in%black,] write.table(out1[,&quot;eid&quot;], &quot;white-complete-cov.id&quot;, col.names=F, row.names=F, quote=F) write.table(out2[,&quot;eid&quot;], &quot;asian-complete-cov.id&quot;, col.names=F, row.names=F, quote=F) write.table(out3[,&quot;eid&quot;], &quot;black-complete-cov.id&quot;, col.names=F, row.names=F, quote=F) # overlapping UNRELATED WHITE across 14 traits---------------------------------- # overlapping = no missing data for the 14 traits cp icd10/unrelated.inds overlap.ind # unrelated white British dir=phen/continuous-traits/ for tt in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do mv overlap.ind temp awk &#39;(NR==FNR){a[$1];next}($1 in a){print $1, $2}&#39; temp $dir/$tt.raw.pheno &gt; overlap.ind wc -l overlap.ind echo $tt done rm temp # overlapping + complete data for covariates + unrelated awk &#39;NR==FNR{a[$1]; next} ($1 in a) {print $1, $1}&#39; unrelated/overlap.ind white-complete-cov.id &gt; overlap-white-complete-cov.id # N = 147,008 # overlapping UNRELATED ASIAN across 14 traits---------------------------------- cp asian-complete-cov.id overlap-asian-complete-cov.id dir=phen/continuous-traits/ for tt in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do mv overlap-asian-complete-cov.id temp awk &#39;(NR==FNR){a[$1];next}($1 in a){print $1, $2}&#39; temp $dir/$tt.raw.pheno &gt; overlap-asian-complete-cov.id wc -l overlap-asian-complete-cov.id # N = 4,052 echo $tt done rm temp # relatedness filtering # see below # overlapping UNRELATED BLACK across 14 traits---------------------------------- cp black-complete-cov.id overlap-black-complete-cov.id dir=phen/continuous-traits/ for tt in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do mv overlap-black-complete-cov.id temp awk &#39;(NR==FNR){a[$1];next}($1 in a){print $1, $2}&#39; temp $dir/$tt.raw.pheno &gt; overlap-black-complete-cov.id wc -l overlap-black-complete-cov.id # N = 3,583 echo $tt done rm temp # relatedness filtering # see below 5.1.2 relatedness filtering For black and Asian people only. #------------- # 0. make bfiles #------------ # id lists overlap-white-complete-cov.id # N=147,008 overlap-black-complete-cov.id # N=3,583 overlap-asian-complete-cov.id # N=4,052 awk &#39;{print $0}&#39; overlap-white-complete-cov.id overlap-black-complete-cov.id overlap-asian-complete-cov.id &gt; overlap-mixed-complete-cov.id # 154,643 # bfiles by chr for j in {1..22}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 20G #SBATCH -c 3 #SBATCH -t 1:0:0 ./plink2 --pfile ../gen/geno_plink/bhr$j \\ --keep ../overlap-mixed-complete-cov.id \\ --extract ../gen/snps-unrel-inds.use \\ --make-bed \\ --memory 20000 \\ --out ../gen/tmp/bhr$j-mix \\ --threads 3 \\ &quot;&gt; sh_script/chr$j-mix.sh done # submit script for i in {1..22}; do sbatch -A snpher ../sh_script/chr$i-mix.sh done&gt;../job-records/mkbfile-mix-pop # merge bfiles rm bfile-mix.list for j in {1..22}; do echo &quot;../gen/tmp/bhr$j-mix&quot; &gt;&gt;bfile-mix.list done echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 20G #SBATCH -c 3 #SBATCH -t 10:0:0 ./ldak5.1 --make-bed ../gen/geno-mix \\ --mbfile ../gen/bfile-mix.list \\ --max-threads 3 \\ --exclude-dups YES &quot;&gt; sh_script/merge-mbfiles-mix-pop.sh # submit the script sbatch -A snpher ../sh_script/merge-mbfiles-mix-pop.sh &gt;../job-records/merge-mbfiles-mix #------- # 1. prune SNPs #------- for j in {1..22}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --partition normal #SBATCH --mem 10G #SBATCH -c 4 #SBATCH -t 5:0:0 #SBATCH --constraint \\&quot;s04|s05\\&quot; ./ldak5.1 --max-threads 4 \\ --window-prune 0.05 \\ --window-kb 1000 \\ --bfile ../gen/geno-mix \\ --chr $j \\ --thin ../thin/thin-chr$j &quot; &gt; sh_script/thin$j done for j in {1..22}; do sbatch -A snpher ../sh_script/thin$j done &gt; ../job-records/thin-snps #------------- # 2. kinship matrix under GCTA #------------- for pop in {black,asian}; do for j in {1..22}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --partition normal #SBATCH --mem 20G #SBATCH -c 3 #SBATCH -t 1:0:0 #SBATCH --constraint \\&quot;s04|s05\\&quot; ./ldak5.1 --max-threads 3 \\ --calc-kins-direct ../kinship/$pop-gcta-thin$j \\ --bfile ../gen/geno-mix \\ --keep ../overlap-$pop-complete-cov.id\\ --extract ../thin/thin-chr$j.in \\ --chr $j \\ --power -1 \\ --ignore-weights YES \\ --single YES &quot; &gt; sh_script/$pop-grm$j done done # submit files for pop in {black,asian}; do for j in {1..22}; do sbatch -A snpher ../sh_script/$pop-grm$j done done &gt; ../job-records/grm-pops # merge grms for pop in {black,asian}; do rm $pop-grm.list for j in {1..22} do echo &quot;../kinship/$pop-gcta-thin$j&quot; &gt;&gt; $pop-grm.list done done for pop in {black,asian}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 80G #SBATCH -c 10 #SBATCH -t 12:0:0 ./ldak5.1 --add-grm ../kinship/$pop-gcta-thin --mgrm ../$pop-grm.list &quot;&gt; sh_script/$pop-grm.sh done for pop in {black,asian}; do sbatch -A snpher ../sh_script/$pop-grm.sh done &gt; ../job-records/grm-merge #can now delete per-chr files #rm *gcta-thin{1..22}.* #----------------------- # 3. Relatedness filtering #------------------------ # relatedness filtering for pop in {asian,black};do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 20G #SBATCH -c 3 #SBATCH -t 2:0:0 ./ldak5.1 --filter ../relatedness/$pop-cut.05 \\ --grm ../kinship/$pop-gcta-thin \\ --max-rel 0.05 \\ --max-threads 3 &quot;&gt; sh_script/$pop-rel-cut.05.sh done # submit script for pop in {asian,black};do sbatch -A snpher ../sh_script/$pop-rel-cut.05.sh done &gt; ../job-records/relatedness-filtering # remaining individuals # asian-cut.05.keep N = 3,448 # black-cut.05.keep N = 3,024 # sum = 6,472 5.1.3 final list To match the good GWAS, we will have N = 100k in total and replace 6,472 whites with Asians and Blacks. # select shuf rand.100000 | head -n 93528 &gt; white.rand.93528 cat white.rand.93528 relatedness/asian-cut.05.keep relatedness/black-cut.05.keep &gt; mix-pop-gwas.id 5.2 GWAS We use basic covariates only: age, sex and townsend # covariates awk &#39;{print $1, $2, $3, $4, $5}&#39; covariates.use &gt; basic-covariates.use awk &#39;NR&lt;=5{print $0}&#39; covariates.use-names &gt; basic-covariates.use # gwas for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do for j in {1..22}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 8G #SBATCH -c 2 #SBATCH -t 5:0:0 ./ldak5.1 --linear ../gwas-mix/$i-linear-chr-$j \\ --pheno ../phen/continuous-traits/$i.raw.pheno \\ --bfile ../gen/geno-mix \\ --covar ../phen/basic-covariates.use \\ --keep ../mix-pop-gwas.id \\ --extract ../gen/snps-unrel-inds.use \\ --max-threads 2 \\ --chr $j &quot;&gt; sh_script/$i-linear-chr-$j.sh done done # --covar ../phen/covariates.use # submit files------------------------------------------------------------------ for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do for j in {1..22}; do sbatch -A snpher ../sh_script/$i-linear-chr-$j.sh done done&gt;../job-records/gwas-mix-pop # check job completion---------------------------------------------------------- file=job-records/gwas-mix-pop jobs=`awk &#39;{print $4}&#39; $file` mkdir $file-tmp for i in $jobs; do jobinfo $i | awk -F &quot;:&quot; -v i=$i &#39;$1~/Name/ {print i, $2}&#39; &gt;&gt; $file-tmp/name.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/State/ {print$2}&#39; &gt;&gt; $file-tmp/state.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Cores/ {print$2}&#39; &gt;&gt; $file-tmp/cores.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Used walltime/ {print $2 &quot;:&quot; $3 &quot;:&quot; $4}&#39; &gt;&gt; $file-tmp/time.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Max Mem/ {split($2,a,/[(]/ ); print a[1]}&#39; &gt;&gt; $file-tmp/mem.tmp done paste $file-tmp/name.tmp \\ $file-tmp/state.tmp \\ $file-tmp/cores.tmp \\ $file-tmp/time.tmp \\ $file-tmp/mem.tmp \\ | awk &#39;BEGIN{print &quot;ID name state cores time mem&quot;}{print $0}&#39; &gt; $file.out rm -r $file-tmp # combine results # only need .summaries &amp; .pvalues for i in {awake,bmi,quals,chron,ever,fvc,height,imp,neur,pulse,reaction,sbp,snoring,hyper}; do for j in {1..22}; do if [ $j == 1 ]; then awk &#39;{print $0}&#39; $i-linear-chr-$j.summaries &gt; $i-linear.summaries awk &#39;{print $0}&#39; $i-linear-chr-$j.pvalues &gt; $i-linear.pvalues else awk &#39;NR&gt;1 {print $0}&#39; $i-linear-chr-$j.summaries &gt;&gt; $i-linear.summaries awk &#39;NR&gt;1 {print $0}&#39; $i-linear-chr-$j.pvalues &gt;&gt; $i-linear.pvalues fi done done 5.3 ldsc intercept 5.3.1 under gcta #::::::::::::: # using original ldsc #::::::::::::: # format stats for ldsc--------------------------------------------------------- library(vroom) options(scipen = 100) rs=vroom(&quot;doug/ukbb.ldsc&quot;, col_names=F) phen=c(&quot;awake&quot;,&quot;bmi&quot;,&quot;chron&quot;,&quot;ever&quot;,&quot;fvc&quot;, &quot;height&quot;,&quot;imp&quot;,&quot;neur&quot;,&quot;pulse&quot;,&quot;quals&quot;, &quot;reaction&quot;,&quot;sbp&quot;,&quot;snoring&quot;,&quot;hyper&quot;, &quot;quals&quot;) for(i in phen){ stat=vroom(paste0(&quot;gwas-mix/&quot;,i,&quot;-linear.summaries&quot;), col_names=T) p=vroom(paste0(&quot;gwas-mix/&quot;,i,&quot;-linear.pvalues&quot;), col_names=T) m1=match(rs$X1, stat$Predictor) m2=match(rs$X1, p$Predictor) out=data.frame(SNP=rs$X2, N=stat$n[m1], Z=(sqrt(stat$Stat)*stat$Direction)[m1], A1=stat$A1[m1], A2=stat$A2[m1], pval=p$P[m2], stringsAsFactors=F) out=out[complete.cases(out),] write.table(out, paste0(&quot;gwas-mix/&quot;,i,&quot;-linear-rs.summaries&quot;), col.names=T, row.names=F, quote=F) } # perform ldsc------------------------------------------------------------------ mkdir out-mix-pop for i in {awake,bmi,chron,ever,fvc,height,quals,imp,neur,pulse,reaction,sbp,snoring,hyper}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 2G #SBATCH -c 3 #SBATCH -t 08:00:0 .././munge_sumstats.py \\ --sumstats ../../gwas-mix/$i-linear-rs.summaries \\ --out ../out-mix-pop/$i \\ --merge-alleles ../w_hm3.snplist .././ldsc.py \\ --h2 ../out-mix-pop/$i.sumstats.gz \\ --ref-ld-chr ../eur_w_ld_chr/ \\ --w-ld-chr ../eur_w_ld_chr/ \\ --out ../out-mix-pop/$i-ldsc &quot;&gt;sh_script/ldsc-$i-mix-pop.sh done # submit jobs------------------------------------------------------------------- for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,reaction,sbp,snoring,hyper,quals}; do sbatch -A snpher ../sh_script/ldsc-$i-mix-pop.sh done&gt;../../job-records/ldsc-mix-pop # check job completion---------------------------------------------------------- file=job-records/ldsc-mix-pop jobs=`awk &#39;{print $4}&#39; $file` mkdir $file-tmp for i in $jobs; do jobinfo $i | awk -F &quot;:&quot; -v i=$i &#39;$1~/Name/ {print i, $2}&#39; &gt;&gt; $file-tmp/name.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/State/ {print$2}&#39; &gt;&gt; $file-tmp/state.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Cores/ {print$2}&#39; &gt;&gt; $file-tmp/cores.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Used walltime/ {print $2 &quot;:&quot; $3 &quot;:&quot; $4}&#39; &gt;&gt; $file-tmp/time.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Max Mem/ {split($2,a,/[(]/ ); print a[1]}&#39; &gt;&gt; $file-tmp/mem.tmp done paste $file-tmp/name.tmp \\ $file-tmp/state.tmp \\ $file-tmp/cores.tmp \\ $file-tmp/time.tmp \\ $file-tmp/mem.tmp \\ | awk &#39;BEGIN{print &quot;ID name state cores time mem&quot;}{print $0}&#39; &gt; $file.out rm -r $file-tmp #::::::::::::: # using sumher #::::::::::::: # insert genetic distance into bim file----------------------------------------- # here we want to use the same genetic distance as for unrelated individuals, i.e., good GWAS R dat=read.table(&quot;gen/geno-mix.bim&quot;, header=F, stringsAsFactors=F) ref=read.table(&quot;gen/geno-unrel.bim&quot;, header=F, stringsAsFactors=F) m=match(dat$V2,ref$V2) out=data.frame(dat$V1, dat$V2, ref$V3[m], dat$V4, dat$V5, dat$V6, stringsAsFactors=F) write.table(out,&quot;gen/geno-mix.bim2&quot;, col.names=F, row.names=F, quote=F) mv geno-mix.bim geno-mix.bim0 mv geno-mix.bim2 geno-mix.bim # compute tagging under gcta---------------------------------------------------- for j in {1..22}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 5G #SBATCH -c 1 #SBATCH -t 5:0:0 ./ldak5.1 --calc-tagging ../tagging-mix-pop/gcta-hapmap3-chr-$j \\ --bfile ../gen/geno-mix \\ --ignore-weights YES \\ --power -1 \\ --window-cm 1 \\ --chr $j &quot;&gt; sh_script/tagging-gcta-hapmap3-chr$j done for j in {1..22}; do sbatch -A snpher ../sh_script/tagging-gcta-hapmap3-chr$j done &gt; ../job-records/tagging-gcta-hadmap3-mix-pop # check job completion---------------------------------------------------------- file=job-records/tagging-gcta-hadmap3-mix-pop jobs=`awk &#39;{print $4}&#39; $file` mkdir $file-tmp for i in $jobs; do jobinfo $i | awk -F &quot;:&quot; -v i=$i &#39;$1~/Name/ {print i, $2}&#39; &gt;&gt; $file-tmp/name.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/State/ {print$2}&#39; &gt;&gt; $file-tmp/state.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Cores/ {print$2}&#39; &gt;&gt; $file-tmp/cores.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Used walltime/ {print $2 &quot;:&quot; $3 &quot;:&quot; $4}&#39; &gt;&gt; $file-tmp/time.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Max Mem/ {split($2,a,/[(]/ ); print a[1]}&#39; &gt;&gt; $file-tmp/mem.tmp done paste $file-tmp/name.tmp \\ $file-tmp/state.tmp \\ $file-tmp/cores.tmp \\ $file-tmp/time.tmp \\ $file-tmp/mem.tmp \\ | awk &#39;BEGIN{print &quot;ID name state cores time mem&quot;}{print $0}&#39; &gt; $file.out rm -r $file-tmp # merge tagging files----------------------------------------------------------- rm list.txt for j in {1..22}; do echo &quot;tagging-mix-pop/gcta-hapmap3-chr-$j.tagging&quot; &gt;&gt; list.txt done ./ldak5.1 --join-tagging tagging-mix-pop/gcta-hapmap3 --taglist list.txt # ldsc intercept---------------------------------------------------------------- mkdir sumher-mix for i in {awake,bmi,chron,ever,fvc,height,quals,imp,neur,pulse,reaction,sbp,snoring,hyper}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 5G #SBATCH -c 1 #SBATCH -t 5:0:0 ./ldak5.1 --sum-hers ../sumher-mix/$i-sumher-gcta \\ --tagfile ../tagging-mix-pop/gcta-hapmap3.tagging \\ --summary ../gwas-mix/$i-linear.summaries \\ --check-sums NO \\ --intercept YES &quot;&gt; sh_script/$i-sumher-gcta-mix-pop done for i in {awake,bmi,chron,ever,fvc,height,quals,imp,neur,pulse,reaction,sbp,snoring,hyper}; do sbatch -A snpher ../sh_script/$i-sumher-gcta-mix-pop done&gt;../job-records/sumher-gcta-mix-pop # check job completion---------------------------------------------------------- file=job-records/sumher-gcta-mix-pop jobs=`awk &#39;{print $4}&#39; $file` mkdir $file-tmp for i in $jobs; do jobinfo $i | awk -F &quot;:&quot; -v i=$i &#39;$1~/Name/ {print i, $2}&#39; &gt;&gt; $file-tmp/name.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/State/ {print$2}&#39; &gt;&gt; $file-tmp/state.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Cores/ {print$2}&#39; &gt;&gt; $file-tmp/cores.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Used walltime/ {print $2 &quot;:&quot; $3 &quot;:&quot; $4}&#39; &gt;&gt; $file-tmp/time.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Max Mem/ {split($2,a,/[(]/ ); print a[1]}&#39; &gt;&gt; $file-tmp/mem.tmp done paste $file-tmp/name.tmp \\ $file-tmp/state.tmp \\ $file-tmp/cores.tmp \\ $file-tmp/time.tmp \\ $file-tmp/mem.tmp \\ | awk &#39;BEGIN{print &quot;ID name state cores time mem&quot;}{print $0}&#39; &gt; $file.out rm -r $file-tmp 5.3.2 under ldak-thin # get weights------------------------------------------------------------------- awk &lt; ldak-thin/ldak-thin-hapmap3.in &#39;{print $1, 1}&#39; &gt; ldak-thin/weights.ldak-thin-hapmap3 # calculate tagging under ldak-thin--------------------------------------------- for j in {1..22}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --partition normal #SBATCH --mem 40G #SBATCH -c 5 #SBATCH -t 10:0:0 #SBATCH --constraint \\&quot;s04|s05\\&quot; ./ldak5.1 --calc-tagging ../tagging-mix-pop/ldak-thin-hapmap3-chr-$j \\ --bfile ../gen/geno-mix \\ --weights ../ldak-thin/weights.ldak-thin-hapmap3 \\ --power -.25 \\ --window-cm 1 \\ --chr $j \\ --save-matrix YES \\ --max-threads 5 &quot; &gt; sh_script/tagging-ldak-thin-hapmap3-chr$j.sh done # submit scripts for j in {1..22}; do sbatch -A snpher ../sh_script/tagging-ldak-thin-hapmap3-chr$j.sh done &gt; ../job-records/tagging-ldak-thin-hapmap3 # check job completion---------------------------------------------------------- file=job-records/tagging-ldak-thin-hapmap3 jobs=`awk &#39;{print $4}&#39; $file` mkdir $file-tmp for i in $jobs; do jobinfo $i | awk -F &quot;:&quot; -v i=$i &#39;$1~/Name/ {print i, $2}&#39; &gt;&gt; $file-tmp/name.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/State/ {print$2}&#39; &gt;&gt; $file-tmp/state.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Cores/ {print$2}&#39; &gt;&gt; $file-tmp/cores.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Used walltime/ {print $2 &quot;:&quot; $3 &quot;:&quot; $4}&#39; &gt;&gt; $file-tmp/time.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Max Mem/ {split($2,a,/[(]/ ); print a[1]}&#39; &gt;&gt; $file-tmp/mem.tmp done paste $file-tmp/name.tmp \\ $file-tmp/state.tmp \\ $file-tmp/cores.tmp \\ $file-tmp/time.tmp \\ $file-tmp/mem.tmp \\ | awk &#39;BEGIN{print &quot;ID name state cores time mem&quot;}{print $0}&#39; &gt; $file.out rm -r $file-tmp # merge tagging files----------------------------------------------------------- rm list.txt rm matlist.txt for j in {1..22}; do echo &quot;tagging-mix-pop/ldak-thin-hapmap3-chr-$j.tagging&quot; &gt;&gt; list.txt echo &quot;tagging-mix-pop/ldak-thin-hapmap3-chr-$j.matrix&quot; &gt;&gt; matlist.txt done ./ldak5.1 --join-tagging tagging-mix-pop/ldak-thin-hapmap3 --taglist list.txt --matlist matlist.txt # ldsc intercept---------------------------------------------------------------- for i in {awake,bmi,chron,ever,fvc,height,quals,imp,neur,pulse,reaction,sbp,snoring,hyper}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 5G #SBATCH -c 1 #SBATCH -t 00:30:0 ./ldak5.1 --sum-hers ../sumher-mix/$i-sumher-ldak-thin \\ --tagfile ../tagging-mix-pop/ldak-thin-hapmap3.tagging \\ --summary ../gwas-mix/$i-linear.summaries \\ --check-sums NO \\ --intercept YES &quot;&gt; sh_script/$i-sumher-ldak-thin-mix done for i in {awake,bmi,chron,ever,fvc,height,quals,imp,neur,pulse,reaction,sbp,snoring,hyper}; do sbatch -A snpher ../sh_script/$i-sumher-ldak-thin-mix done&gt;../job-records/sumher-ldak-thin-mix # check job-completion file=job-records/sumher-ldak-thin-mix jobs=`awk &#39;{print $4}&#39; $file` mkdir $file-tmp for i in $jobs; do jobinfo $i | awk -F &quot;:&quot; -v i=$i &#39;$1~/Name/ {print i, $2}&#39; &gt;&gt; $file-tmp/name.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/State/ {print$2}&#39; &gt;&gt; $file-tmp/state.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Cores/ {print$2}&#39; &gt;&gt; $file-tmp/cores.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Used walltime/ {print $2 &quot;:&quot; $3 &quot;:&quot; $4}&#39; &gt;&gt; $file-tmp/time.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Max Mem/ {split($2,a,/[(]/ ); print a[1]}&#39; &gt;&gt; $file-tmp/mem.tmp done paste $file-tmp/name.tmp \\ $file-tmp/state.tmp \\ $file-tmp/cores.tmp \\ $file-tmp/time.tmp \\ $file-tmp/mem.tmp \\ | awk &#39;BEGIN{print &quot;ID name state cores time mem&quot;}{print $0}&#39; &gt; $file.out rm -r $file-tmp 5.3.3 summary # without 40 PCs---------------------------------------------------------------------- # original ldsc grep Intercept *ldsc.log | awk &#39;{split($1, a, /[-]/); split($3, b, /[()]/); print a[1], $2, b[2]}&#39; &gt; ../../summary/ldsc-mix # sumher under gcta grep Intercept_Estimate *gcta.extra | awk &#39;{ split($1, a, /[-]/); print a[1], $2}&#39; &gt;../summary/sumher-gcta-mix-est grep Intercept_SD *gcta.extra | awk &#39;{ split($1, a, /[-]/); print a[1], $2}&#39; &gt;../summary/sumher-gcta-mix-sd cd ../summary/ paste sumher-gcta-mix-est sumher-gcta-mix-sd | awk &#39;{print $1, $2, $4}&#39; &gt; sumher-gcta-mix rm sumher-gcta-mix-sd sumher-gcta-mix-est # suhmer under ldak-thin grep Intercept_Estimate *ldak-thin.extra | awk &#39;{ split($1, a, /[-]/); print a[1], $2}&#39; &gt;../summary/sumher-ldak-thin-mix-est grep Intercept_SD *ldak-thin.extra | awk &#39;{ split($1, a, /[-]/); print a[1], $2}&#39; &gt;../summary/sumher-ldak-thin-mix-sd cd ../summary/ paste sumher-ldak-thin-mix-est sumher-ldak-thin-mix-sd | awk &#39;{print $1, $2, $4}&#39; &gt; sumher-ldak-thin-mix rm sumher-ldak-thin-mix-sd sumher-ldak-thin-mix-est # with covariates (i.e., including all 40 PCs)------------------------------------------- # original ldsc grep Intercept *ldsc.log | awk &#39;{split($1, a, /[-]/); split($3, b, /[()]/); print a[1], $2, b[2]}&#39; &gt; ../../summary/ldsc-mix-with-cov # sumher under gcta grep Intercept_Estimate *gcta.extra | awk &#39;{ split($1, a, /[-]/); print a[1], $2}&#39; &gt;../summary/sumher-gcta-mix-est grep Intercept_SD *gcta.extra | awk &#39;{ split($1, a, /[-]/); print a[1], $2}&#39; &gt;../summary/sumher-gcta-mix-sd cd ../summary/ paste sumher-gcta-mix-est sumher-gcta-mix-sd | awk &#39;{print $1, $2, $4}&#39; &gt; sumher-gcta-mix-with-cov rm sumher-gcta-mix-sd sumher-gcta-mix-est # suhmer under ldak-thin grep Intercept_Estimate *ldak-thin.extra | awk &#39;{ split($1, a, /[-]/); print a[1], $2}&#39; &gt;../summary/sumher-ldak-thin-mix-est grep Intercept_SD *ldak-thin.extra | awk &#39;{ split($1, a, /[-]/); print a[1], $2}&#39; &gt;../summary/sumher-ldak-thin-mix-sd cd ../summary/ paste sumher-ldak-thin-mix-est sumher-ldak-thin-mix-sd | awk &#39;{print $1, $2, $4}&#39; &gt; sumher-ldak-thin-mix-with-cov rm sumher-ldak-thin-mix-sd sumher-ldak-thin-mix-est 5.4 REML 5.4.1 making grms # making grm ------------------------------------------------------------------- #::: # under gcta #::: # all snps echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --partition normal #SBATCH --mem 120G #SBATCH -c 10 #SBATCH -t 20:0:0 #SBATCH --constraint \\&quot;s04|s05\\&quot; ./ldak5.1 --max-threads 10 \\ --calc-kins-direct ../kinship/gcta-all-mix \\ --bfile ../gen/geno-mix \\ --keep ../mix-pop-gwas.id \\ --power -1 \\ --ignore-weights YES \\ --single YES &quot; &gt; sh_script/grm-all-snps-mix sbatch -A snpher ../sh_script/grm-all-snps-mix &gt; ../job-records/grm-all-snps-mix # grm by snp blocks: right vs. left awk &#39;$1&lt;8 {print $2}&#39; geno-mix.bim &gt; left-mix-pop.snps awk &#39;$1&gt;=8 {print $2}&#39; geno-mix.bim &gt; right-mix-pop.snps for i in left right; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --partition normal #SBATCH --mem 100G #SBATCH -c 10 #SBATCH -t 20:0:0 #SBATCH --constraint \\&quot;s04|s05\\&quot; ./ldak5.1 --max-threads 10 \\ --calc-kins-direct ../kinship/gcta-$i-mix \\ --bfile ../gen/geno-mix \\ --keep ../mix-pop-gwas.id \\ --extract ../gen/$i-mix-pop.snps \\ --power -1 \\ --ignore-weights YES \\ --single YES &quot; &gt; sh_script/grm-gcta-$i-mix done for i in left right; do sbatch -A snpher ../sh_script/grm-gcta-$i-mix done &gt; ../job-records/grm-gcta-by-snps-mix # check job completion---------------------------------------------------------- file=job-records/grm-gcta-by-snps-mix jobs=`awk &#39;{print $4}&#39; $file` mkdir $file-tmp for i in $jobs; do jobinfo $i | awk -F &quot;:&quot; -v i=$i &#39;$1~/Name/ {print i, $2}&#39; &gt;&gt; $file-tmp/name.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/State/ {print$2}&#39; &gt;&gt; $file-tmp/state.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Cores/ {print$2}&#39; &gt;&gt; $file-tmp/cores.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Used walltime/ {print $2 &quot;:&quot; $3 &quot;:&quot; $4}&#39; &gt;&gt; $file-tmp/time.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Max Mem/ {split($2,a,/[(]/ ); print a[1]}&#39; &gt;&gt; $file-tmp/mem.tmp done paste $file-tmp/name.tmp \\ $file-tmp/state.tmp \\ $file-tmp/cores.tmp \\ $file-tmp/time.tmp \\ $file-tmp/mem.tmp \\ | awk &#39;BEGIN{print &quot;ID name state cores time mem&quot;}{print $0}&#39; &gt; $file.out rm -r $file-tmp #::: # under ldak-thin #::: #----------- # 1. thin snps #----------- # we omit this step and use ldak-thin/ldak-thin-hapmap3.in, which was created previously # using geno-unrel bfiles. See above. #---------------------- # 2. kinship matrix under ldak-thin #------------------------ echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --partition normal #SBATCH --mem 100G #SBATCH -c 10 #SBATCH -t 20:0:0 #SBATCH --constraint \\&quot;s04|s05\\&quot; ./ldak5.1 --max-threads 10 \\ --calc-kins-direct ../kinship/ldak-thin-all-mix \\ --bfile ../gen/geno-mix \\ --keep ../mix-pop-gwas.id \\ --extract ../ldak-thin/ldak-thin-hapmap3.in \\ --power -0.25 \\ --ignore-weights YES \\ --single YES &quot; &gt; sh_script/ldak-thin-grm-all-snps-mix sbatch -A snpher ../sh_script/ldak-thin-grm-all-snps-mix&gt; ../job-records/ldak-thin-grm-all-snps-mix # grm by snp blocks: right vs. left awk &#39;{split($1, a, /[:]/); if (a[1]&lt;8) print $1}&#39; \\ ldak-thin/ldak-thin-hapmap3.in &gt; gen/left-ldak-thin-hapmap3.snps awk &#39;{split($1, a, /[:]/); if (a[1]&gt;=8) print $1}&#39; \\ ldak-thin/ldak-thin-hapmap3.in &gt; gen/right-ldak-thin-hapmap3.snps for i in left right; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --partition normal #SBATCH --mem 100G #SBATCH -c 10 #SBATCH -t 20:0:0 #SBATCH --constraint \\&quot;s04|s05\\&quot; ./ldak5.1 --max-threads 10 \\ --calc-kins-direct ../kinship/ldak-thin-$i-mix \\ --bfile ../gen/geno-mix \\ --keep ../mix-pop-gwas.id \\ --extract ../gen/$i-ldak-thin-hapmap3.snps \\ --power -0.25 \\ --ignore-weights YES \\ --single YES &quot; &gt; sh_script/ldak-thin-grm-$i-mix done for i in left right; do sbatch -A snpher ../sh_script/ldak-thin-grm-$i-mix done &gt; ../job-records/grm-ldak-thin-by-snps-mix # check job completion---------------------------------------------------------- file=job-records/grm-ldak-thin-by-snps-mix jobs=`awk &#39;{print $4}&#39; $file` mkdir $file-tmp for i in $jobs; do jobinfo $i | awk -F &quot;:&quot; -v i=$i &#39;$1~/Name/ {print i, $2}&#39; &gt;&gt; $file-tmp/name.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/State/ {print$2}&#39; &gt;&gt; $file-tmp/state.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Cores/ {print$2}&#39; &gt;&gt; $file-tmp/cores.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Used walltime/ {print $2 &quot;:&quot; $3 &quot;:&quot; $4}&#39; &gt;&gt; $file-tmp/time.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Max Mem/ {split($2,a,/[(]/ ); print a[1]}&#39; &gt;&gt; $file-tmp/mem.tmp done paste $file-tmp/name.tmp \\ $file-tmp/state.tmp \\ $file-tmp/cores.tmp \\ $file-tmp/time.tmp \\ $file-tmp/mem.tmp \\ | awk &#39;BEGIN{print &quot;ID name state cores time mem&quot;}{print $0}&#39; &gt; $file.out rm -r $file-tmp 5.4.2 fast-reml #::: # under gcta #::: # make script files------------------------------------------------------------- mkdir reml-mix for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do for k in all left right; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 100G #SBATCH -c 2 #SBATCH -t 5:0:0 ./ldak5.1 --fast-reml ../reml-mix/$i-gcta-$k \\ --repetitions 20 \\ --pheno ../phen/continuous-traits/$i.raw.pheno \\ --covar ../phen/basic-covariates.use \\ --grm ../kinship/gcta-$k-mix \\ --max-threads 2 \\ --single YES &quot;&gt; sh_script/$i-reml-mix-gcta-$k-snps done done # submit script files----------------------------------------------------------- for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do for k in all left right; do sbatch -A snpher ../sh_script/$i-reml-mix-gcta-$k-snps done done&gt;../job-records/reml-mix-gcta # check job completion---------------------------------------------------------- file=job-records/reml-mix-gcta jobs=`awk &#39;{print $4}&#39; $file` mkdir $file-tmp for i in $jobs; do jobinfo $i | awk -F &quot;:&quot; -v i=$i &#39;$1~/Name/ {print i, $2}&#39; &gt;&gt; $file-tmp/name.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/State/ {print$2}&#39; &gt;&gt; $file-tmp/state.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Cores/ {print$2}&#39; &gt;&gt; $file-tmp/cores.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Used walltime/ {print $2 &quot;:&quot; $3 &quot;:&quot; $4}&#39; &gt;&gt; $file-tmp/time.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Max Mem/ {split($2,a,/[(]/ ); print a[1]}&#39; &gt;&gt; $file-tmp/mem.tmp done paste $file-tmp/name.tmp \\ $file-tmp/state.tmp \\ $file-tmp/cores.tmp \\ $file-tmp/time.tmp \\ $file-tmp/mem.tmp \\ | awk &#39;BEGIN{print &quot;ID name state cores time mem&quot;}{print $0}&#39; &gt; $file.out rm -r $file-tmp # cancel jobs for i in {1..14}; do job=`awk -v i=$i &#39;NR==i{print $0}&#39; kill-jobs` scancel $job done #::: # under ldak-thin #::: # make script files------------------------------------------------------------- for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do for k in all left right; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 100G #SBATCH -c 2 #SBATCH -t 5:0:0 ./ldak5.1 --fast-reml ../reml-mix/$i-ldak-thin-$k \\ --repetitions 20 \\ --pheno ../phen/continuous-traits/$i.raw.pheno \\ --covar ../phen/basic-covariates.use \\ --grm ../kinship/ldak-thin-$k-mix \\ --max-threads 2 \\ --single YES &quot;&gt; sh_script/$i-reml-mix-ldak-thin-$k-snps done done # submit script files----------------------------------------------------------- for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do for k in all left right; do sbatch -A snpher ../sh_script/$i-reml-mix-ldak-thin-$k-snps done done &gt;../job-records/reml-mix-ldak-thin # check job completion---------------------------------------------------------- file=job-records/reml-mix-ldak-thin jobs=`awk &#39;{print $4}&#39; $file` mkdir $file-tmp for i in $jobs; do jobinfo $i | awk -F &quot;:&quot; -v i=$i &#39;$1~/Name/ {print i, $2}&#39; &gt;&gt; $file-tmp/name.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/State/ {print$2}&#39; &gt;&gt; $file-tmp/state.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Cores/ {print$2}&#39; &gt;&gt; $file-tmp/cores.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Used walltime/ {print $2 &quot;:&quot; $3 &quot;:&quot; $4}&#39; &gt;&gt; $file-tmp/time.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Max Mem/ {split($2,a,/[(]/ ); print a[1]}&#39; &gt;&gt; $file-tmp/mem.tmp done paste $file-tmp/name.tmp \\ $file-tmp/state.tmp \\ $file-tmp/cores.tmp \\ $file-tmp/time.tmp \\ $file-tmp/mem.tmp \\ | awk &#39;BEGIN{print &quot;ID name state cores time mem&quot;}{print $0}&#39; &gt; $file.out rm -r $file-tmp 5.4.3 inflation test #:::::::::::: # under gcta #:::::::::::: # extract h2 estimates --------------------------------------------------------- # right for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do outfile=reml-mix/$i-gcta-right.reml awk -v i=$i &#39;$1==&quot;Her_All&quot; {print i, $2, $3}&#39; $outfile &gt;&gt; summary/est.tmp awk &#39;$1==&quot;Converged&quot; {print$2}&#39; $outfile &gt;&gt; summary/converge.tmp done paste summary/est.tmp \\ summary/converge.tmp \\ | awk &#39;BEGIN{print &quot;code h2 se converge&quot;}{print i, $0}&#39; \\ &gt; summary/reml-gcta-mix.right rm summary/est.tmp summary/converge.tmp # left for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do outfile=reml-mix/$i-gcta-left.reml awk -v i=$i &#39;$1==&quot;Her_All&quot; {print i, $2, $3}&#39; $outfile &gt;&gt; summary/est.tmp awk &#39;$1==&quot;Converged&quot; {print$2}&#39; $outfile &gt;&gt; summary/converge.tmp done paste summary/est.tmp \\ summary/converge.tmp \\ | awk &#39;BEGIN{print &quot;code h2 se converge&quot;}{print i, $0}&#39; \\ &gt; summary/reml-gcta-mix.left rm summary/est.tmp summary/converge.tmp # all for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do outfile=reml-mix/$i-gcta-all.reml awk -v i=$i &#39;$1==&quot;Her_All&quot; {print i, $2, $3}&#39; $outfile &gt;&gt; summary/est.tmp awk &#39;$1==&quot;Converged&quot; {print$2}&#39; $outfile &gt;&gt; summary/converge.tmp done paste summary/est.tmp \\ summary/converge.tmp \\ | awk &#39;BEGIN{print &quot;code h2 se converge&quot;}{print i, $0}&#39; \\ &gt; summary/reml-gcta-mix.all rm summary/est.tmp summary/converge.tmp # inflation test---------------------------------------------------------------- R full=read.table(paste0(&quot;summary/reml-gcta-mix.all&quot;), header=T) left=read.table(paste0(&quot;summary/reml-gcta-mix.left&quot;), header=T) right=read.table(paste0(&quot;summary/reml-gcta-mix.right&quot;), header=T) # some analyses did not complete --&gt; match dataframes dim(full);dim(left);dim(right) common=intersect(full$code, left$code) common=intersect(common, right$code) m1=match(common, right$code) m2=match(common, full$code) m3=match(common, left$code) right=right[m1,] full=full[m2,] left=left[m3,] for(i in 1:dim(full)[1]){ est1=left$h2[i] sd1=left$se[i] est2=right$h2[i] sd2=right$se[i] est=full$h2[i] sd=full$se[i] N=100000 d1=rnorm(N,est1,sd1) d2=rnorm(N,est2,sd2) d=rnorm(N,est,sd) p=1-mean(d1+d2-d&gt;=0) out0=data.frame(code=full$code[i], right_est=est2, right_sd=sd2, left_est=est1, left_sd=sd1, all_est=est, all_sd=sd, p_inflation=p) if(i==1){out=out0}else{out=rbind(out,out0)} } write.table(out, paste0(&quot;summary/reml-gcta-inflation-mix-gwas.txt&quot;), col.names=T, row.names=F, quote=F) #:::::::::::: # under ldak-thin #:::::::::::: # extract h2 estimates --------------------------------------------------------- # right for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do outfile=reml-mix/$i-ldak-thin-right.reml awk -v i=$i &#39;$1==&quot;Her_All&quot; {print i, $2, $3}&#39; $outfile &gt;&gt; summary/est.tmp awk &#39;$1==&quot;Converged&quot; {print$2}&#39; $outfile &gt;&gt; summary/converge.tmp done paste summary/est.tmp \\ summary/converge.tmp \\ | awk &#39;BEGIN{print &quot;code h2 se converge&quot;}{print i, $0}&#39; \\ &gt; summary/reml-ldak-thin-mix.right rm summary/est.tmp summary/converge.tmp # left for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do outfile=reml-mix/$i-ldak-thin-left.reml awk -v i=$i &#39;$1==&quot;Her_All&quot; {print i, $2, $3}&#39; $outfile &gt;&gt; summary/est.tmp awk &#39;$1==&quot;Converged&quot; {print$2}&#39; $outfile &gt;&gt; summary/converge.tmp done paste summary/est.tmp \\ summary/converge.tmp \\ | awk &#39;BEGIN{print &quot;code h2 se converge&quot;}{print i, $0}&#39; \\ &gt; summary/reml-ldak-thin-mix.left rm summary/est.tmp summary/converge.tmp # all for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do outfile=reml-mix/$i-ldak-thin-all.reml awk -v i=$i &#39;$1==&quot;Her_All&quot; {print i, $2, $3}&#39; $outfile &gt;&gt; summary/est.tmp awk &#39;$1==&quot;Converged&quot; {print$2}&#39; $outfile &gt;&gt; summary/converge.tmp done paste summary/est.tmp \\ summary/converge.tmp \\ | awk &#39;BEGIN{print &quot;code h2 se converge&quot;}{print i, $0}&#39; \\ &gt; summary/reml-ldak-thin-mix.all rm summary/est.tmp summary/converge.tmp # inflation test---------------------------------------------------------------- R full=read.table(paste0(&quot;summary/reml-ldak-thin-mix.all&quot;), header=T) left=read.table(paste0(&quot;summary/reml-ldak-thin-mix.left&quot;), header=T) right=read.table(paste0(&quot;summary/reml-ldak-thin-mix.right&quot;), header=T) # some analyses did not complete --&gt; match dataframes dim(full);dim(left);dim(right) common=intersect(full$code, left$code) common=intersect(common, right$code) m1=match(common, right$code) m2=match(common, full$code) m3=match(common, left$code) right=right[m1,] full=full[m2,] left=left[m3,] for(i in 1:dim(full)[1]){ est1=left$h2[i] sd1=left$se[i] est2=right$h2[i] sd2=right$se[i] est=full$h2[i] sd=full$se[i] N=100000 d1=rnorm(N,est1,sd1) d2=rnorm(N,est2,sd2) d=rnorm(N,est,sd) p=1-mean(d1+d2-d&gt;=0) out0=data.frame(code=full$code[i], right_est=est2, right_sd=sd2, left_est=est1, left_sd=sd1, all_est=est, all_sd=sd, p_inflation=p) if(i==1){out=out0}else{out=rbind(out,out0)} } write.table(out, paste0(&quot;summary/reml-ldak-thin-inflation-mix-gwas.txt&quot;), col.names=T, row.names=F, quote=F) 5.5 HE 5.5.1 estimation # regress grm on covariates----------------------------------------------------- for grm in gcta-all-mix gcta-left-mix gcta-right-mix ldak-thin-all-mix ldak-thin-left-mix ldak-thin-right-mix; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 50G #SBATCH -c 5 #SBATCH -t 10:0:0 ./ldak5.1 --adjust-grm ../kinship/$grm.covar \\ --grm ../kinship/$grm \\ --covar ../phen/basic-covariates.use \\ --max-threads 5 &quot;&gt; sh_script/$grm-adjust.sh done # submit jobs for grm in gcta-all-mix gcta-left-mix gcta-right-mix ldak-thin-all-mix ldak-thin-left-mix ldak-thin-right-mix; do sbatch -A snpher ../sh_script/$grm-adjust.sh done &gt; ../job-records/grm-adjust-for-HE # check job completion---------------------------------------------------------- file=job-records/grm-adjust-for-HE jobs=`awk &#39;{print $4}&#39; $file` mkdir $file-tmp for i in $jobs; do jobinfo $i | awk -F &quot;:&quot; -v i=$i &#39;$1~/Name/ {print i, $2}&#39; &gt;&gt; $file-tmp/name.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/State/ {print$2}&#39; &gt;&gt; $file-tmp/state.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Cores/ {print$2}&#39; &gt;&gt; $file-tmp/cores.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Used walltime/ {print $2 &quot;:&quot; $3 &quot;:&quot; $4}&#39; &gt;&gt; $file-tmp/time.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Max Mem/ {split($2,a,/[(]/ ); print a[1]}&#39; &gt;&gt; $file-tmp/mem.tmp done paste $file-tmp/name.tmp \\ $file-tmp/state.tmp \\ $file-tmp/cores.tmp \\ $file-tmp/time.tmp \\ $file-tmp/mem.tmp \\ | awk &#39;BEGIN{print &quot;ID name state cores time mem&quot;}{print $0}&#39; &gt; $file.out rm -r $file-tmp # HE under gcta----------------------------------------------------------------- for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do for k in all left right; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 2G #SBATCH -c 1 #SBATCH -t 00:30:0 ./ldak5.1 --he ../he-mix/$i-he-gcta-$k \\ --pheno ../phen/continuous-traits/$i.raw.pheno \\ --grm ../kinship/gcta-$k-mix.covar \\ --kinship-details NO \\ --check-root NO \\ --covar ../phen/basic-covariates.use \\ --max-threads 1 \\ --memory-save YES &quot;&gt; sh_script/$i-he-gcta-$k-snps.sh done done # submit files------------------------------------------------------------------ for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do for k in all left right; do sbatch -A snpher ../sh_script/$i-he-gcta-$k-snps.sh done done &gt; ../job-records/he-gcta # HE under ldak-thin------------------------------------------------------------ for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do for k in all left right; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 2G #SBATCH -c 1 #SBATCH -t 0:30:0 ./ldak5.1 --he ../he-mix/$i-he-ldak-thin-$k \\ --pheno ../phen/continuous-traits/$i.raw.pheno \\ --grm ../kinship/ldak-thin-$k-mix.covar \\ --kinship-details NO \\ --check-root NO \\ --covar ../phen/basic-covariates.use \\ --max-threads 1 \\ --memory-save YES &quot;&gt; sh_script/$i-he-ldak-thin-$k-snps.sh done done # submit files------------------------------------------------------------------ for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do for k in all left right; do sbatch -A snpher ../sh_script/$i-he-ldak-thin-$k-snps.sh done done &gt; ../job-records/he-ldak-thin 5.5.2 summary #:::::::::::: # under gcta #:::::::::::: # extract h2 estimates --------------------------------------------------------- # right rm summary/he-gcta-mix.right for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do outfile=he-mix/$i-he-gcta-right.he awk -v i=$i &#39;$1==&quot;Her_All&quot; {print i, $2, $3}&#39; $outfile &gt;&gt; summary/he-gcta-mix.right done # left rm summary/he-gcta-mix.left for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do outfile=he-mix/$i-he-gcta-left.he awk -v i=$i &#39;$1==&quot;Her_All&quot; {print i, $2, $3}&#39; $outfile &gt;&gt; summary/he-gcta-mix.left done # all rm summary/he-gcta-mix.all for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do outfile=he-mix/$i-he-gcta-all.he awk -v i=$i &#39;$1==&quot;Her_All&quot; {print i, $2, $3}&#39; $outfile &gt;&gt; summary/he-gcta-mix.all done # inflation test---------------------------------------------------------------- R full=read.table(paste0(&quot;summary/he-gcta-mix.all&quot;), header=F) left=read.table(paste0(&quot;summary/he-gcta-mix.left&quot;), header=F) right=read.table(paste0(&quot;summary/he-gcta-mix.right&quot;), header=F) names(full)=names(left)=names(right)=c(&quot;code&quot;,&quot;h2&quot;,&quot;se&quot;) # some analyses did not complete --&gt; match dataframes dim(full);dim(left);dim(right) common=intersect(full$code, left$code) common=intersect(common, right$code) m1=match(common, right$code) m2=match(common, full$code) m3=match(common, left$code) right=right[m1,] full=full[m2,] left=left[m3,] for(i in 1:dim(full)[1]){ est1=left$h2[i] sd1=left$se[i] est2=right$h2[i] sd2=right$se[i] est=full$h2[i] sd=full$se[i] N=100000 d1=rnorm(N,est1,sd1) d2=rnorm(N,est2,sd2) d=rnorm(N,est,sd) p=1-mean(d1+d2-d&gt;=0) out0=data.frame(code=full$code[i], right_est=est2, right_sd=sd2, left_est=est1, left_sd=sd1, all_est=est, all_sd=sd, p_inflation=p) if(i==1){out=out0}else{out=rbind(out,out0)} } write.table(out, paste0(&quot;summary/he-gcta-inflation-mix-gwas.txt&quot;), col.names=T, row.names=F, quote=F) #:::::::::::: # under ldak-thin #:::::::::::: # extract h2 estimates --------------------------------------------------------- # right rm summary/he-ldak-thin-mix.right for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do outfile=he-mix/$i-he-ldak-thin-right.he awk -v i=$i &#39;$1==&quot;Her_All&quot; {print i, $2, $3}&#39; $outfile &gt;&gt; summary/he-ldak-thin-mix.right done # left rm summary/he-ldak-thin-mix.left for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do outfile=he-mix/$i-he-ldak-thin-left.he awk -v i=$i &#39;$1==&quot;Her_All&quot; {print i, $2, $3}&#39; $outfile &gt;&gt; summary/he-ldak-thin-mix.left done # all rm summary/he-ldak-thin-mix.all for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do outfile=he-mix/$i-he-gcta-all.he awk -v i=$i &#39;$1==&quot;Her_All&quot; {print i, $2, $3}&#39; $outfile &gt;&gt; summary/he-ldak-thin-mix.all done # inflation test---------------------------------------------------------------- R full=read.table(paste0(&quot;summary/he-ldak-thin-mix.all&quot;), header=F) left=read.table(paste0(&quot;summary/he-ldak-thin-mix.left&quot;), header=F) right=read.table(paste0(&quot;summary/he-ldak-thin-mix.right&quot;), header=F) names(full)=names(left)=names(right)=c(&quot;code&quot;,&quot;h2&quot;,&quot;se&quot;) # some analyses did not complete --&gt; match dataframes dim(full);dim(left);dim(right) common=intersect(full$code, left$code) common=intersect(common, right$code) m1=match(common, right$code) m2=match(common, full$code) m3=match(common, left$code) right=right[m1,] full=full[m2,] left=left[m3,] for(i in 1:dim(full)[1]){ est1=left$h2[i] sd1=left$se[i] est2=right$h2[i] sd2=right$se[i] est=full$h2[i] sd=full$se[i] N=100000 d1=rnorm(N,est1,sd1) d2=rnorm(N,est2,sd2) d=rnorm(N,est,sd) p=1-mean(d1+d2-d&gt;=0) out0=data.frame(code=full$code[i], right_est=est2, right_sd=sd2, left_est=est1, left_sd=sd1, all_est=est, all_sd=sd, p_inflation=p) if(i==1){out=out0}else{out=rbind(out,out0)} } write.table(out, paste0(&quot;summary/he-ldak-thin-inflation-mix-gwas.txt&quot;), col.names=T, row.names=F, quote=F) "],["ukbb.html", "6 UKBB recommended 6.1 total N = 337k 6.2 QC of hp3 SNPs 6.3 GWAS 6.4 ldsc intercept 6.5 HE", " 6 UKBB recommended 6.1 total N = 337k Here we want to identify the unrelated white individuals recommended by the UKBB. Email from Florian: “We restrict individuals to the ones used for computing the principal components (PCs) in the UK Biobank (Field 22020). These individuals are unrelated and have passed some quality control including removing samples with a missing rate on autosomes larger than 0.02, having a mismatch between inferred sex and self-reported sex, and outliers based on heterozygosity (more details can be found in section S3 of Bycroft et al. (2018)).” And the White British are from this: https://biobank.ctsu.ox.ac.uk/crystal/field.cgi?id=22006 So required data fields: PC: 22020 White british: 22006 options(scipen = 100) # extract data head=read.table(&quot;phen/ukb45861.header&quot;, sep=&quot;,&quot;, header=F, stringsAsFactors = F) # function to get the variables get=function(nm){ colnum=grep(nm,head,fixed=TRUE) out=data.frame(t(rbind(colnum, head[,colnum]))) names(out)=c(&quot;column&quot;, &quot;field&quot;) return (out) } # get the variables out=rbind(get(&#39;22020-0&#39;), # PC get(&#39;22006-0&#39;)) # white british write.table(out,&quot;phen/vars.colnum&quot;, col.names=F, row.names=F, sep=&quot;\\t&quot;, quote=F) # extract dat awk -F &#39;&quot;,&quot;&#39; &#39;(NR==FNR){a[$1];next}{printf &quot;%s\\&quot;&quot;, $1;for(i in a){printf &quot; \\&quot;%s\\&quot;&quot;, $i};printf &quot;\\n&quot;}&#39; phen/vars.colnum phen/ukb45861.csv &gt; phen/ukbb-recommended.dat # get the id list of the intersect of the two data fields dat=read.table(&quot;phen/ukbb-recommended.dat&quot;, header=T, stringsAsFactors=F) id1=dat$eid[dat$X22020.0.0==1 &amp; !is.na(dat$X22020.0.0)] id2=dat$eid[dat$X22006.0.0==1 &amp; !is.na(dat$X22006.0.0)] out=intersect(id1,id2) # N = 337,462 write.table(out, &quot;ukbb-recommend.id&quot;, col.names=F, row.names=F, quote=F) 6.2 QC of hp3 SNPs Here we do QC to 1.2M hapmap3 SNPs for the UKBB recommended individuals. # QC SNPs----------------------------------------------------------------------- # stating number of SNPs= 1,184,423 # note: at this stage, we use all UKBB recommended IDs # we will do a random selection of IDs later. for j in {1..22}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 20G #SBATCH -c 3 #SBATCH -t 1:0:0 ./plink2 --pfile ../gen/geno_plink/bhr$j \\ --keep ../ukbb-recommend.id \\ --extract ../doug/ukbb.ldsc \\ --hwe 0.0001 \\ --hard-call-threshold .05 \\ --mach-r2-filter 0.8 2 \\ --make-bed \\ --memory 20000 \\ --out ../gen/tmp/bhr$j-norm \\ --threads 3 &quot;&gt; sh_script/chr$j.sh done # submit jobs for j in {1..22}; do sbatch -A snpher ../sh_script/chr$j.sh done &gt; ../job-records/qc-norm # merge files rm bfile-norm.list for j in {1..22}; do echo &quot;../gen/tmp/bhr$j-norm&quot; &gt;&gt;bfile-norm.list done echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 20G #SBATCH -c 3 #SBATCH -t 20:0:0 ./ldak5.1 --make-bed ../gen/geno-norm \\ --mbfile ../gen/bfile-norm.list \\ --max-threads 3 \\ --exclude-dups YES &quot;&gt; sh_script/mbfile-norm.sh # submit the script sbatch -A snpher ../sh_script/mbfile-norm.sh &gt;../job-records/mbfiles-norm # randomly select 100k individuals shuf ukbb-recommend.id | head -n 100000 &gt; ukbb-recommned-rand.100000 # make bfile for these individuals echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 20G #SBATCH -c 3 #SBATCH -t 20:0:0 ./ldak5.1 --make-bed ../gen/geno-norm-100k \\ --bfile ../gen/geno-norm \\ --keep ../ukbb-recommned-rand.100000 \\ --max-threads 3 \\ --exclude-dups YES &quot;&gt; sh_script/mbfile-norm-100k.sh # submit the script sbatch -A snpher ../sh_script/mbfile-norm-100k.sh &gt;../job-records/mbfiles-norm-100k # MAF &amp; call-rate awk &lt; geno-norm-100k.stats &#39;($5&gt;.01 &amp;&amp; $6&gt;=0.95 &amp;&amp; NR&gt;1){print $1}&#39; &gt; snps-norm-100k.use # m = 1,100,799 SNPs 6.3 GWAS # linear regression------------------------------------------------------------- mkdir gwas-norm for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 10G #SBATCH -c 2 #SBATCH -t 10:0:0 ./ldak5.1 --linear ../gwas-norm/$i-linear \\ --pheno ../phen/continuous-traits/$i.raw.pheno \\ --bfile ../gen/geno-norm-100k \\ --keep ../ukbb-recommned-rand.100000 \\ --extract ../gen/snps-norm-100k.use \\ --covar ../phen/covariates.use \\ --max-threads 2 \\ &quot;&gt; sh_script/$i-linear.sh done # submit files------------------------------------------------------------------ for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do sbatch -A snpher ../sh_script/$i-linear.sh done&gt;../job-records/gwas-norm # check job completion---------------------------------------------------------- file=job-records/gwas-norm jobs=`awk &#39;{print $4}&#39; $file` mkdir $file-tmp for i in $jobs; do jobinfo $i | awk -F &quot;:&quot; -v i=$i &#39;$1~/Name/ {print i, $2}&#39; &gt;&gt; $file-tmp/name.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/State/ {print$2}&#39; &gt;&gt; $file-tmp/state.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Cores/ {print$2}&#39; &gt;&gt; $file-tmp/cores.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Used walltime/ {print $2 &quot;:&quot; $3 &quot;:&quot; $4}&#39; &gt;&gt; $file-tmp/time.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Max Mem/ {split($2,a,/[(]/ ); print a[1]}&#39; &gt;&gt; $file-tmp/mem.tmp done paste $file-tmp/name.tmp \\ $file-tmp/state.tmp \\ $file-tmp/cores.tmp \\ $file-tmp/time.tmp \\ $file-tmp/mem.tmp \\ | awk &#39;BEGIN{print &quot;ID name state cores time mem&quot;}{print $0}&#39; &gt; $file.out rm -r $file-tmp 6.4 ldsc intercept 6.4.1 under gcta #::::::::::::: # using original ldsc #::::::::::::: # format stats for ldsc--------------------------------------------------------- library(vroom) options(scipen = 100) rs=vroom(&quot;doug/ukbb.ldsc&quot;, col_names=F) phen=c(&quot;awake&quot;,&quot;bmi&quot;,&quot;chron&quot;,&quot;ever&quot;,&quot;fvc&quot;, &quot;height&quot;,&quot;imp&quot;,&quot;neur&quot;,&quot;pulse&quot;,&quot;quals&quot;, &quot;reaction&quot;,&quot;sbp&quot;,&quot;snoring&quot;,&quot;hyper&quot;, &quot;quals&quot;) for(i in phen){ stat=vroom(paste0(&quot;gwas-norm/&quot;,i,&quot;-linear.summaries&quot;), col_names=T) p=vroom(paste0(&quot;gwas-norm/&quot;,i,&quot;-linear.pvalues&quot;), col_names=T) m1=match(rs$X1, stat$Predictor) m2=match(rs$X1, p$Predictor) out=data.frame(SNP=rs$X2, N=stat$n[m1], Z=(sqrt(stat$Stat)*stat$Direction)[m1], A1=stat$A1[m1], A2=stat$A2[m1], pval=p$P[m2], stringsAsFactors=F) out=out[complete.cases(out),] write.table(out, paste0(&quot;gwas-norm/&quot;,i,&quot;-linear-rs.summaries&quot;), col.names=T, row.names=F, quote=F) } # perform ldsc------------------------------------------------------------------ mkdir out-norm-100k for i in {awake,bmi,chron,ever,fvc,height,quals,imp,neur,pulse,reaction,sbp,snoring,hyper}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 2G #SBATCH -c 3 #SBATCH -t 24:00:0 .././munge_sumstats.py \\ --sumstats ../../gwas-norm/$i-linear-rs.summaries \\ --out ../out-norm-100k/$i \\ --merge-alleles ../w_hm3.snplist .././ldsc.py \\ --h2 ../out-norm-100k/$i.sumstats.gz \\ --ref-ld-chr ../eur_w_ld_chr/ \\ --w-ld-chr ../eur_w_ld_chr/ \\ --out ../out-norm-100k/$i-ldsc &quot;&gt;sh_script/ldsc-$i-norm-100k.sh done # submit jobs------------------------------------------------------------------- for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,reaction,sbp,snoring,hyper,quals}; do sbatch -A snpher ../sh_script/ldsc-$i-norm-100k.sh done&gt;../../job-records/ldsc-norm-100k #::::::::::::: # using sumher #::::::::::::: # insert genetic distance into bim file----------------------------------------- head geno-norm-100k.fam &gt; small-norm for j in {1..22}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --mem 8G #SBATCH -c 1 #SBATCH -t 3:00:0 #SBATCH --constraint \\&quot;s04|s05\\&quot; ./plink1.9 --bfile ../gen/geno-norm-100k \\ --chr $j \\ --cm-map /home/zhoux/snpher/faststorage/genetic_maps/genetic_map_chr@_combined_b37.txt \\ --make-bed \\ --out new$j \\ --keep ../gen/small-norm &quot; &gt; sh_script/map$j done for j in {1..22}; do sbatch -A snpher ../sh_script/map$j done &gt; genetic-distance-hapmap3 cd /home/zhoux/dsmwpred/xuan/quality-control/qc-10oct/gen cat new{1..22}.bim | awk &#39;{print $2, $3}&#39; &gt; maps-hapmap3-norm-100k.txt rm new{1..22}.{bim,bed,fam,log} awk &#39;(NR==FNR){arr[$1]=$2;next}{print $1, $2, arr[$2], $4, $5, $6}&#39; &gt; geno-norm-100k.bim2 maps-hapmap3-norm-100k.txt geno-norm-100k.bim mv geno-norm-100k.bim geno-norm-100k.bim0 mv geno-norm-100k.bim2 geno-norm-100k.bim # compute tagging under gcta---------------------------------------------------- mkdir tagging-norm-100k for j in {1..22}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 5G #SBATCH -c 1 #SBATCH -t 5:0:0 ./ldak5.1 --calc-tagging ../tagging-norm-100k/gcta-hapmap3-chr-$j \\ --bfile ../gen/geno-norm-100k \\ --ignore-weights YES \\ --power -1 \\ --window-cm 1 \\ --chr $j &quot;&gt; sh_script/tagging-gcta-hapmap3-chr$j done for j in {1..22}; do sbatch -A snpher ../sh_script/tagging-gcta-hapmap3-chr$j done &gt; ../job-records/tagging-gcta-hapmap3-norm-100k # check job completion---------------------------------------------------------- file=job-records/tagging-gcta-hapmap3-norm-100k jobs=`awk &#39;{print $4}&#39; $file` mkdir $file-tmp for i in $jobs; do jobinfo $i | awk -F &quot;:&quot; -v i=$i &#39;$1~/Name/ {print i, $2}&#39; &gt;&gt; $file-tmp/name.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/State/ {print$2}&#39; &gt;&gt; $file-tmp/state.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Cores/ {print$2}&#39; &gt;&gt; $file-tmp/cores.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Used walltime/ {print $2 &quot;:&quot; $3 &quot;:&quot; $4}&#39; &gt;&gt; $file-tmp/time.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Max Mem/ {split($2,a,/[(]/ ); print a[1]}&#39; &gt;&gt; $file-tmp/mem.tmp done paste $file-tmp/name.tmp \\ $file-tmp/state.tmp \\ $file-tmp/cores.tmp \\ $file-tmp/time.tmp \\ $file-tmp/mem.tmp \\ | awk &#39;BEGIN{print &quot;ID name state cores time mem&quot;}{print $0}&#39; &gt; $file.out rm -r $file-tmp # merge tagging files----------------------------------------------------------- rm list.txt for j in {1..22}; do echo &quot;tagging-norm-100k/gcta-hapmap3-chr-$j.tagging&quot; &gt;&gt; list.txt done ./ldak5.1 --join-tagging tagging-norm-100k/gcta-hapmap3 --taglist list.txt # ldsc intercept---------------------------------------------------------------- mkdir sumher-norm-100k dirin1=tagging-norm-100k dirin2=gwas-norm dirout=sumher-norm-100k for i in {awake,bmi,chron,ever,fvc,height,quals,imp,neur,pulse,reaction,sbp,snoring,hyper}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 5G #SBATCH -c 1 #SBATCH -t 5:0:0 ./ldak5.1 --sum-hers ../$dirout/$i-sumher-gcta \\ --tagfile ../$dirin1/gcta-hapmap3.tagging \\ --summary ../$dirin2/$i-linear.summaries \\ --check-sums NO \\ --intercept YES &quot;&gt; sh_script/$i-sumher-gcta done for i in {awake,bmi,chron,ever,fvc,height,quals,imp,neur,pulse,reaction,sbp,snoring,hyper}; do sbatch -A snpher ../sh_script/$i-sumher-gcta done&gt;../job-records/sumher-gcta-norm-100k 6.4.2 under ldak-thin # get weights------------------------------------------------------------------- awk &lt; ldak-thin/ldak-thin-norm.in &#39;{print $1, 1}&#39; &gt; ldak-thin/weights.ldak-thin-norm # calculate tagging under ldak-thin--------------------------------------------- dirout=tagging-norm-100k filein1=geno-norm-100k filein2=weights.ldak-thin-norm for j in {1..22}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --partition normal #SBATCH --mem 40G #SBATCH -c 5 #SBATCH -t 10:0:0 #SBATCH --constraint \\&quot;s04|s05\\&quot; ./ldak5.1 --calc-tagging ../$dirout/ldak-thin-hapmap3-chr-$j \\ --bfile ../gen/$filein1 \\ --weights ../ldak-thin/$filein2 \\ --power -.25 \\ --window-cm 1 \\ --chr $j \\ --save-matrix YES \\ --max-threads 5 &quot; &gt; sh_script/tagging-ldak-thin-hapmap3-chr$j.sh done # submit scripts for j in {1..22}; do sbatch -A snpher ../sh_script/tagging-ldak-thin-hapmap3-chr$j.sh done &gt; ../job-records/tagging-ldak-thin-norm-100k # check job completion---------------------------------------------------------- file=job-records/tagging-ldak-thin-norm-100k jobs=`awk &#39;{print $4}&#39; $file` mkdir $file-tmp for i in $jobs; do jobinfo $i | awk -F &quot;:&quot; -v i=$i &#39;$1~/Name/ {print i, $2}&#39; &gt;&gt; $file-tmp/name.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/State/ {print$2}&#39; &gt;&gt; $file-tmp/state.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Cores/ {print$2}&#39; &gt;&gt; $file-tmp/cores.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Used walltime/ {print $2 &quot;:&quot; $3 &quot;:&quot; $4}&#39; &gt;&gt; $file-tmp/time.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Max Mem/ {split($2,a,/[(]/ ); print a[1]}&#39; &gt;&gt; $file-tmp/mem.tmp done paste $file-tmp/name.tmp \\ $file-tmp/state.tmp \\ $file-tmp/cores.tmp \\ $file-tmp/time.tmp \\ $file-tmp/mem.tmp \\ | awk &#39;BEGIN{print &quot;ID name state cores time mem&quot;}{print $0}&#39; &gt; $file.out rm -r $file-tmp # merge tagging files----------------------------------------------------------- rm list.txt rm matlist.txt for j in {1..22}; do echo &quot;tagging-norm-100k/ldak-thin-hapmap3-chr-$j.tagging&quot; &gt;&gt; list.txt echo &quot;tagging-norm-100k/ldak-thin-hapmap3-chr-$j.matrix&quot; &gt;&gt; matlist.txt done dirout=tagging-norm-100k ./ldak5.1 --join-tagging $dirout/ldak-thin-hapmap3 --taglist list.txt --matlist matlist.txt # ldsc intercept---------------------------------------------------------------- dirin1=tagging-norm-100k dirin2=gwas-norm dirout=sumher-norm-100k for i in {awake,bmi,chron,ever,fvc,height,quals,imp,neur,pulse,reaction,sbp,snoring,hyper}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 5G #SBATCH -c 1 #SBATCH -t 00:30:0 ./ldak5.1 --sum-hers ../$dirout/$i-sumher-ldak-thin \\ --tagfile ../$dirin1/ldak-thin-hapmap3.tagging \\ --summary ../$dirin2/$i-linear.summaries \\ --check-sums NO \\ --intercept YES &quot;&gt; sh_script/$i-sumher-ldak-thin done for i in {awake,bmi,chron,ever,fvc,height,quals,imp,neur,pulse,reaction,sbp,snoring,hyper}; do sbatch -A snpher ../sh_script/$i-sumher-ldak-thin done&gt;../job-records/sumher-ldak-thin-norm-100k 6.4.3 summary # original ldsc grep Intercept *ldsc.log | awk &#39;{split($1, a, /[-]/); split($3, b, /[()]/); print a[1], $2, b[2]}&#39; &gt; ../../summary/ldsc-norm-100k # sumher under gcta grep Intercept_Estimate *gcta.extra | awk &#39;{ split($1, a, /[-]/); print a[1], $2}&#39; &gt;../summary/sumher-gcta-norm-100k-est grep Intercept_SD *gcta.extra | awk &#39;{ split($1, a, /[-]/); print a[1], $2}&#39; &gt;../summary/sumher-gcta-norm-100k-sd cd ../summary/ paste sumher-gcta-norm-100k-est sumher-gcta-norm-100k-sd | awk &#39;{print $1, $2, $4}&#39; &gt; sumher-gcta-norm-100k # suhmer under ldak-thin grep Intercept_Estimate *ldak-thin.extra | awk &#39;{ split($1, a, /[-]/); print a[1], $2}&#39; &gt;../summary/sumher-ldak-thin-norm-100k-est grep Intercept_SD *ldak-thin.extra | awk &#39;{ split($1, a, /[-]/); print a[1], $2}&#39; &gt;../summary/sumher-ldak-thin-norm-100k-sd cd ../summary/ paste sumher-ldak-thin-norm-100k-est sumher-ldak-thin-norm-100k-sd | awk &#39;{print $1, $2, $4}&#39; &gt; sumher-ldak-thin-norm-100k 6.5 HE 6.5.1 making grms # making grm ------------------------------------------------------------------- #::: # under gcta #::: # all snps echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --partition normal #SBATCH --mem 60G #SBATCH -c 10 #SBATCH -t 08:0:0 #SBATCH --constraint \\&quot;s04|s05\\&quot; ./ldak5.1 --max-threads 10 \\ --calc-kins-direct ../kinship/gcta-all-norm \\ --bfile ../gen/geno-norm-100k \\ --extract ../gen/snps-norm-100k.use \\ --power -1 \\ --ignore-weights YES \\ --single YES &quot; &gt; sh_script/grm-all-snps-norm sbatch -A snpher ../sh_script/grm-all-snps-norm &gt; ../job-records/grm-all-snps-norm # grm by snp blocks: right vs. left awk &#39;$1&lt;8 {print $2}&#39; geno-norm-100k.bim &gt; left-snps-norm-100k.use awk &#39;$1&gt;=8 {print $2}&#39; geno-norm-100k.bim &gt; right-snps-norm-100k.use for i in left right; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --partition normal #SBATCH --mem 60G #SBATCH -c 10 #SBATCH -t 20:0:0 #SBATCH --constraint \\&quot;s04|s05\\&quot; ./ldak5.1 --max-threads 10 \\ --calc-kins-direct ../kinship/gcta-$i-norm \\ --bfile ../gen/geno-norm-100k \\ --extract ../gen/$i-snps-norm-100k.use \\ --power -1 \\ --ignore-weights YES \\ --single YES &quot; &gt; sh_script/grm-gcta-$i-norm done for i in left right; do sbatch -A snpher ../sh_script/grm-gcta-$i-norm done &gt; ../job-records/grm-gcta-by-snps-norm #::: # under ldak-thin #::: #----------- # 1. thin snps #----------- for j in {1..22}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --partition normal #SBATCH --mem 10G #SBATCH -c 4 #SBATCH -t 4:0:0 #SBATCH --constraint \\&quot;s04|s05\\&quot; ./ldak5.1 --max-threads 4 \\ --window-prune 0.98 \\ --window-kb 100 \\ --extract ../gen/snps-norm-100k.use \\ --bfile ../gen/geno-norm-100k \\ --thin ../ldak-thin/chr$j-norm \\ --chr $j &quot; &gt; sh_script/ldak-thin$j-norm done # submit script for j in {1..22}; do sbatch -A snpher ../sh_script/ldak-thin$j-norm done &gt; ../job-records/ldak-thin-norm # check job completion--- file=job-records/ldak-thin-norm jobs=`awk &#39;{print $4}&#39; $file` mkdir $file-tmp for i in $jobs; do jobinfo $i | awk -F &quot;:&quot; -v i=$i &#39;$1~/Name/ {print i, $2}&#39; &gt;&gt; $file-tmp/name.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/State/ {print$2}&#39; &gt;&gt; $file-tmp/state.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Cores/ {print$2}&#39; &gt;&gt; $file-tmp/cores.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Used walltime/ {print $2 &quot;:&quot; $3 &quot;:&quot; $4}&#39; &gt;&gt; $file-tmp/time.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Max Mem/ {split($2,a,/[(]/ ); print a[1]}&#39; &gt;&gt; $file-tmp/mem.tmp done paste $file-tmp/name.tmp \\ $file-tmp/state.tmp \\ $file-tmp/cores.tmp \\ $file-tmp/time.tmp \\ $file-tmp/mem.tmp \\ | awk &#39;BEGIN{print &quot;ID name state cores time mem&quot;}{print $0}&#39; &gt; $file.out rm -r $file-tmp # combine snp list cat ldak-thin/chr{1..22}-norm.in &gt; ldak-thin/ldak-thin-norm.in #---------------------- # 2. kinship matrix under ldak-thin #------------------------ echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --partition normal #SBATCH --mem 60G #SBATCH -c 10 #SBATCH -t 08:0:0 #SBATCH --constraint \\&quot;s04|s05\\&quot; ./ldak5.1 --max-threads 10 \\ --calc-kins-direct ../kinship/ldak-thin-all-norm \\ --bfile ../gen/geno-norm-100k \\ --extract ../ldak-thin/ldak-thin-norm.in \\ --power -0.25 \\ --ignore-weights YES \\ --single YES &quot; &gt; sh_script/ldak-thin-grm-all-snps-norm sbatch -A snpher ../sh_script/ldak-thin-grm-all-snps-norm &gt; ../job-records/ldak-thin-grm-all-snps-norm # grm by snp blocks: right vs. left awk &#39;{split($1, a, /[:]/); if (a[1]&lt;8) print $1}&#39; \\ ldak-thin/ldak-thin-norm.in &gt; gen/left-ldak-thin-norm.snps awk &#39;{split($1, a, /[:]/); if (a[1]&gt;=8) print $1}&#39; \\ ldak-thin/ldak-thin-norm.in &gt; gen/right-ldak-thin-norm.snps for i in left right; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --partition normal #SBATCH --mem 60G #SBATCH -c 10 #SBATCH -t 08:0:0 #SBATCH --constraint \\&quot;s04|s05\\&quot; ./ldak5.1 --max-threads 10 \\ --calc-kins-direct ../kinship/ldak-thin-$i-norm \\ --bfile ../gen/geno-norm-100k \\ --extract ../gen/$i-ldak-thin-norm.snps \\ --power -0.25 \\ --ignore-weights YES \\ --single YES &quot; &gt; sh_script/ldak-thin-grm-$i-norm done for i in left right; do sbatch -A snpher ../sh_script/ldak-thin-grm-$i-norm done &gt; ../job-records/grm-ldak-thin-by-snps-norm 6.5.2 estimation NEED To check what covariates to adjust for HE basic.covariates.use or covariates.use? # regress grm on covariates----------------------------------------------------- for grm in gcta-all-norm gcta-left-norm gcta-right-norm ldak-thin-all-norm ldak-thin-left-norm ldak-thin-right-norm; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 50G #SBATCH -c 5 #SBATCH -t 10:0:0 ./ldak5.1 --adjust-grm ../kinship/$grm.covar \\ --grm ../kinship/$grm \\ --covar ../phen/covariates.use \\ --max-threads 5 &quot;&gt; sh_script/$grm-adjust.sh done # submit jobs for grm in gcta-all-norm gcta-left-norm gcta-right-norm ldak-thin-all-norm ldak-thin-left-norm ldak-thin-right-norm; do sbatch -A snpher ../sh_script/$grm-adjust.sh done &gt; ../job-records/grm-adjust-for-HE # check job completion---------------------------------------------------------- file=job-records/grm-adjust-for-HE jobs=`awk &#39;{print $4}&#39; $file` mkdir $file-tmp for i in $jobs; do jobinfo $i | awk -F &quot;:&quot; -v i=$i &#39;$1~/Name/ {print i, $2}&#39; &gt;&gt; $file-tmp/name.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/State/ {print$2}&#39; &gt;&gt; $file-tmp/state.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Cores/ {print$2}&#39; &gt;&gt; $file-tmp/cores.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Used walltime/ {print $2 &quot;:&quot; $3 &quot;:&quot; $4}&#39; &gt;&gt; $file-tmp/time.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Max Mem/ {split($2,a,/[(]/ ); print a[1]}&#39; &gt;&gt; $file-tmp/mem.tmp done paste $file-tmp/name.tmp \\ $file-tmp/state.tmp \\ $file-tmp/cores.tmp \\ $file-tmp/time.tmp \\ $file-tmp/mem.tmp \\ | awk &#39;BEGIN{print &quot;ID name state cores time mem&quot;}{print $0}&#39; &gt; $file.out rm -r $file-tmp # HE under gcta----------------------------------------------------------------- for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do for k in all left right; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 2G #SBATCH -c 1 #SBATCH -t 00:30:0 ./ldak5.1 --he ../he-norm/$i-he-gcta-$k \\ --pheno ../phen/continuous-traits/$i.raw.pheno \\ --grm ../kinship/gcta-$k-norm.covar \\ --kinship-details NO \\ --check-root NO \\ --covar ../phen/covariates.use \\ --max-threads 1 \\ --memory-save YES &quot;&gt; sh_script/$i-he-gcta-$k-snps-norm.sh done done # submit files------------------------------------------------------------------ for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do for k in all left right; do sbatch -A snpher ../sh_script/$i-he-gcta-$k-snps-norm.sh done done &gt; ../job-records/he-gcta # HE under ldak-thin------------------------------------------------------------ for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do for k in all left right; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 2G #SBATCH -c 1 #SBATCH -t 0:30:0 ./ldak5.1 --he ../he-norm/$i-he-ldak-thin-$k \\ --pheno ../phen/continuous-traits/$i.raw.pheno \\ --grm ../kinship/ldak-thin-$k-norm.covar \\ --kinship-details NO \\ --check-root NO \\ --covar ../phen/covariates.use \\ --max-threads 1 \\ --memory-save YES &quot;&gt; sh_script/$i-he-ldak-thin-$k-norm.sh done done # submit files------------------------------------------------------------------ for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do for k in all left right; do sbatch -A snpher ../sh_script/$i-he-ldak-thin-$k-norm.sh done done &gt; ../job-records/he-ldak-thin 6.5.3 summary #:::::::::::: # under gcta #:::::::::::: # extract h2 estimates --------------------------------------------------------- # right rm summary/he-gcta-norm.right for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do outfile=he-norm/$i-he-gcta-right.he awk -v i=$i &#39;$1==&quot;Her_All&quot; {print i, $2, $3}&#39; $outfile &gt;&gt; summary/he-gcta-norm.right done # left rm summary/he-gcta-norm.left for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do outfile=he-norm/$i-he-gcta-left.he awk -v i=$i &#39;$1==&quot;Her_All&quot; {print i, $2, $3}&#39; $outfile &gt;&gt; summary/he-gcta-norm.left done # all rm summary/he-gcta-norm.all for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do outfile=he-norm/$i-he-gcta-all.he awk -v i=$i &#39;$1==&quot;Her_All&quot; {print i, $2, $3}&#39; $outfile &gt;&gt; summary/he-gcta-norm.all done # inflation test---------------------------------------------------------------- R full=read.table(paste0(&quot;summary/he-gcta-norm.all&quot;), header=F) left=read.table(paste0(&quot;summary/he-gcta-norm.left&quot;), header=F) right=read.table(paste0(&quot;summary/he-gcta-norm.right&quot;), header=F) names(full)=names(left)=names(right)=c(&quot;code&quot;,&quot;h2&quot;,&quot;se&quot;) # some analyses did not complete --&gt; match dataframes dim(full);dim(left);dim(right) common=intersect(full$code, left$code) common=intersect(common, right$code) m1=match(common, right$code) m2=match(common, full$code) m3=match(common, left$code) right=right[m1,] full=full[m2,] left=left[m3,] for(i in 1:dim(full)[1]){ est1=left$h2[i] sd1=left$se[i] est2=right$h2[i] sd2=right$se[i] est=full$h2[i] sd=full$se[i] N=100000 d1=rnorm(N,est1,sd1) d2=rnorm(N,est2,sd2) d=rnorm(N,est,sd) p=1-mean(d1+d2-d&gt;=0) out0=data.frame(code=full$code[i], right_est=est2, right_sd=sd2, left_est=est1, left_sd=sd1, all_est=est, all_sd=sd, p_inflation=p) if(i==1){out=out0}else{out=rbind(out,out0)} } write.table(out, paste0(&quot;summary/he-gcta-inflation-norm.txt&quot;), col.names=T, row.names=F, quote=F) #:::::::::::: # under ldak-thin #:::::::::::: # extract h2 estimates --------------------------------------------------------- # right rm summary/he-ldak-thin-norm.right for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do outfile=he-norm/$i-he-ldak-thin-right.he awk -v i=$i &#39;$1==&quot;Her_All&quot; {print i, $2, $3}&#39; $outfile &gt;&gt; summary/he-ldak-thin-norm.right done # left rm summary/he-ldak-thin-norm.left for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do outfile=he-norm/$i-he-ldak-thin-left.he awk -v i=$i &#39;$1==&quot;Her_All&quot; {print i, $2, $3}&#39; $outfile &gt;&gt; summary/he-ldak-thin-norm.left done # all rm summary/he-ldak-thin-norm.all for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do outfile=he-norm/$i-he-gcta-all.he awk -v i=$i &#39;$1==&quot;Her_All&quot; {print i, $2, $3}&#39; $outfile &gt;&gt; summary/he-ldak-thin-norm.all done # inflation test---------------------------------------------------------------- R full=read.table(paste0(&quot;summary/he-ldak-thin-norm.all&quot;), header=F) left=read.table(paste0(&quot;summary/he-ldak-thin-norm.left&quot;), header=F) right=read.table(paste0(&quot;summary/he-ldak-thin-norm.right&quot;), header=F) names(full)=names(left)=names(right)=c(&quot;code&quot;,&quot;h2&quot;,&quot;se&quot;) # some analyses did not complete --&gt; match dataframes dim(full);dim(left);dim(right) common=intersect(full$code, left$code) common=intersect(common, right$code) m1=match(common, right$code) m2=match(common, full$code) m3=match(common, left$code) right=right[m1,] full=full[m2,] left=left[m3,] for(i in 1:dim(full)[1]){ est1=left$h2[i] sd1=left$se[i] est2=right$h2[i] sd2=right$se[i] est=full$h2[i] sd=full$se[i] N=100000 d1=rnorm(N,est1,sd1) d2=rnorm(N,est2,sd2) d=rnorm(N,est,sd) p=1-mean(d1+d2-d&gt;=0) out0=data.frame(code=full$code[i], right_est=est2, right_sd=sd2, left_est=est1, left_sd=sd1, all_est=est, all_sd=sd, p_inflation=p) if(i==1){out=out0}else{out=rbind(out,out0)} } write.table(out, paste0(&quot;summary/he-ldak-thin-inflation-norm.txt&quot;), col.names=T, row.names=F, quote=F) "],["control.html", "7 control GWAS 7.1 ID list 7.2 QC of hp3 SNPs 7.3 GWAS 7.4 ldsc intercept 7.5 HE", " 7 control GWAS Here we perform GWASs that serve as the control group for the good versus bad GWASs comparison. For the bad GWASs (section 5), we have a total of 100k individuals, which consist of 93,528 unrelated white British (from the good GWASs) and 6,472 blacks and Asians. We observed inflation of the test statistics. Although unlikely, it is still possible that some of the inflation is due to random errors. To rule out this possibility [or to ascertain that the observed inflation is due to population stratification not random errors], we used the same 93,528 unrelated white British but replaced the 6,472 blacks and Asians with unrelated white British that were not included in the good GWASs. 7.1 ID list We used previously obtained id lists (see section 4.1 for the good GWAS id list and section 5.1 for the bad GWAS id list ) to derive the id list for the control GWASs. These are: overlap-complete-cases.id: N = 147,008. Unrelated white British who have no missing data for all 14 traits and covariates. rand.100000: ID list for the good gwas. Randomly selected from overlap-complete-cases.id white.rand.93528: unrelated whites as a part of the bad gwas ID list. Randomly selected from rand.100000 Here are the steps: identify IDs from overlap-complete-cases.id not included in rand.100000. randomly select 6,472 from the identified IDs. combine white.rand.93528 with the randomly selected 6,472 IDs. options(scipen = 100) id1=read.table(&quot;unrelated/overlap-complete-cases.id&quot;, header=F) id2=read.table(&quot;unrelated/rand.100000&quot;, header=F) id3=read.table(&quot;white.rand.93528&quot;, header=F) # pool for selection common=intersect(id1$V1, id2$V1) pool=id1[!id1$V1%in%common,] # randomly select 6,472 from the pool sel=pool[sample(dim(pool)[1], 6472, replace=F),] # combine with &#39;white.rand.93528&#39; write.table(rbind(sel,id3), &#39;control-gwas.id&#39;, quote=F, row.names=F, col.names=F) 7.2 QC of hp3 SNPs # QC SNPs----------------------------------------------------------------------- # stating number of SNPs= 1,184,423 for j in {1..22}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 20G #SBATCH -c 3 #SBATCH -t 1:0:0 ./plink2 --pfile ../gen/geno_plink/bhr$j \\ --keep ../control-gwas.id \\ --extract ../doug/ukbb.ldsc \\ --hwe 0.0001 \\ --hard-call-threshold .05 \\ --mach-r2-filter 0.8 2 \\ --make-bed \\ --memory 20000 \\ --out ../gen/tmp/bhr$j \\ --threads 3 &quot;&gt; sh_script/chr$j.sh done # submit jobs for j in {1..22}; do sbatch -A snpher ../sh_script/chr$j.sh done &gt; ../job-records/qc-control-gwas file=job-records/qc-control-gwas jobs=`awk &#39;{print $4}&#39; $file` mkdir $file-tmp for i in $jobs; do jobinfo $i | awk -F &quot;:&quot; -v i=$i &#39;$1~/Name/ {print i, $2}&#39; &gt;&gt; $file-tmp/name.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/State/ {print$2}&#39; &gt;&gt; $file-tmp/state.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Cores/ {print$2}&#39; &gt;&gt; $file-tmp/cores.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Used walltime/ {print $2 &quot;:&quot; $3 &quot;:&quot; $4}&#39; &gt;&gt; $file-tmp/time.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Max Mem/ {split($2,a,/[(]/ ); print a[1]}&#39; &gt;&gt; $file-tmp/mem.tmp done paste $file-tmp/name.tmp \\ $file-tmp/state.tmp \\ $file-tmp/cores.tmp \\ $file-tmp/time.tmp \\ $file-tmp/mem.tmp \\ | awk &#39;BEGIN{print &quot;ID name state cores time mem&quot;}{print $0}&#39; &gt; $file.out rm -r $file-tmp # merge files rm bfile-control-gwas.list for j in {1..22}; do echo &quot;../gen/tmp/bhr$j&quot; &gt;&gt;bfile-control-gwas.list done echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 20G #SBATCH -c 3 #SBATCH -t 40:0:0 ./ldak5.1 --make-bed ../gen/geno-control \\ --mbfile ../gen/bfile-control-gwas.list \\ --max-threads 3 \\ --exclude-dups YES &quot;&gt; sh_script/mbfile-control.sh # submit the script sbatch -A snpher ../sh_script/mbfile-control.sh &gt;../job-records/mbfiles-control-gwas # MAF &amp; call-rate awk &lt; geno-control.stats &#39;($5&gt;.01 &amp;&amp; $6&gt;=0.95 &amp;&amp; NR&gt;1){print $1}&#39; &gt; snps-control-gwas.use # m = 1,103,182 SNPs 7.3 GWAS # linear regression------------------------------------------------------------- mkdir gwas-control dirout=gwas-control filein=geno-control id=control-gwas.id snp=snps-control-gwas.use for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 10G #SBATCH -c 2 #SBATCH -t 10:0:0 ./ldak5.1 --linear ../$dirout/$i-linear \\ --pheno ../phen/continuous-traits/$i.raw.pheno \\ --bfile ../gen/$filein \\ --keep ../$id \\ --extract ../gen/$snp \\ --covar ../phen/covariates.use \\ --max-threads 2 \\ &quot;&gt; sh_script/$i-linear.sh done # submit files------------------------------------------------------------------ for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do sbatch -A snpher ../sh_script/$i-linear.sh done&gt;../job-records/gwas-control # check job completion---------------------------------------------------------- file=job-records/gwas-control jobs=`awk &#39;{print $4}&#39; $file` mkdir $file-tmp for i in $jobs; do jobinfo $i | awk -F &quot;:&quot; -v i=$i &#39;$1~/Name/ {print i, $2}&#39; &gt;&gt; $file-tmp/name.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/State/ {print$2}&#39; &gt;&gt; $file-tmp/state.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Cores/ {print$2}&#39; &gt;&gt; $file-tmp/cores.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Used walltime/ {print $2 &quot;:&quot; $3 &quot;:&quot; $4}&#39; &gt;&gt; $file-tmp/time.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Max Mem/ {split($2,a,/[(]/ ); print a[1]}&#39; &gt;&gt; $file-tmp/mem.tmp done paste $file-tmp/name.tmp \\ $file-tmp/state.tmp \\ $file-tmp/cores.tmp \\ $file-tmp/time.tmp \\ $file-tmp/mem.tmp \\ | awk &#39;BEGIN{print &quot;ID name state cores time mem&quot;}{print $0}&#39; &gt; $file.out rm -r $file-tmp 7.4 ldsc intercept 7.4.1 under gcta # UP TO HERE #::::::::::::: # using original ldsc #::::::::::::: # format stats for ldsc--------------------------------------------------------- library(vroom) options(scipen = 100) rs=vroom(&quot;doug/ukbb.ldsc&quot;, col_names=F) phen=c(&quot;awake&quot;,&quot;bmi&quot;,&quot;chron&quot;,&quot;ever&quot;,&quot;fvc&quot;, &quot;height&quot;,&quot;imp&quot;,&quot;neur&quot;,&quot;pulse&quot;,&quot;quals&quot;, &quot;reaction&quot;,&quot;sbp&quot;,&quot;snoring&quot;,&quot;hyper&quot;, &quot;quals&quot;) for(i in phen){ stat=vroom(paste0(&quot;gwas-control/&quot;,i,&quot;-linear.summaries&quot;), col_names=T) p=vroom(paste0(&quot;gwas-control/&quot;,i,&quot;-linear.pvalues&quot;), col_names=T) m1=match(rs$X1, stat$Predictor) m2=match(rs$X1, p$Predictor) out=data.frame(SNP=rs$X2, N=stat$n[m1], Z=(sqrt(stat$Stat)*stat$Direction)[m1], A1=stat$A1[m1], A2=stat$A2[m1], pval=p$P[m2], stringsAsFactors=F) out=out[complete.cases(out),] write.table(out, paste0(&quot;gwas-control/&quot;,i,&quot;-linear-rs.summaries&quot;), col.names=T, row.names=F, quote=F) } # perform ldsc------------------------------------------------------------------ mkdir out-control for i in {awake,bmi,chron,ever,fvc,height,quals,imp,neur,pulse,reaction,sbp,snoring,hyper}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 2G #SBATCH -c 3 #SBATCH -t 24:00:0 .././munge_sumstats.py \\ --sumstats ../../gwas-control/$i-linear-rs.summaries \\ --out ../out-control/$i \\ --merge-alleles ../w_hm3.snplist .././ldsc.py \\ --h2 ../out-control/$i.sumstats.gz \\ --ref-ld-chr ../eur_w_ld_chr/ \\ --w-ld-chr ../eur_w_ld_chr/ \\ --out ../out-control/$i-ldsc &quot;&gt;sh_script/ldsc-$i-control.sh done # submit jobs------------------------------------------------------------------- for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,reaction,sbp,snoring,hyper,quals}; do sbatch -A snpher ../sh_script/ldsc-$i-control.sh done&gt;../../job-records/ldsc-control #::::::::::::: # using sumher #::::::::::::: # insert genetic distance into bim file----------------------------------------- head geno-control.fam &gt; small-control for j in {1..22}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --mem 8G #SBATCH -c 1 #SBATCH -t 3:00:0 #SBATCH --constraint \\&quot;s04|s05\\&quot; ./plink1.9 --bfile ../gen/geno-control \\ --chr $j \\ --cm-map /home/zhoux/snpher/faststorage/genetic_maps/genetic_map_chr@_combined_b37.txt \\ --make-bed \\ --out new$j \\ --keep ../gen/small-control &quot; &gt; sh_script/map$j done for j in {1..22}; do sbatch -A snpher ../sh_script/map$j done &gt; genetic-distance-hapmap3 cd /home/zhoux/dsmwpred/xuan/quality-control/qc-10oct/gen cat new{1..22}.bim | awk &#39;{print $2, $3}&#39; &gt; maps-hapmap3-control.txt rm new{1..22}.{bim,bed,fam,log} awk &#39;(NR==FNR){arr[$1]=$2;next}{print $1, $2, arr[$2], $4, $5, $6}&#39; &gt; geno-control.bim2 maps-hapmap3-control.txt geno-control.bim mv geno-control.bim geno-control.bim0 mv geno-control.bim2 geno-control.bim # compute tagging under gcta---------------------------------------------------- mkdir tagging-control for j in {1..22}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 5G #SBATCH -c 1 #SBATCH -t 5:0:0 ./ldak5.1 --calc-tagging ../tagging-control/gcta-hapmap3-chr-$j \\ --bfile ../gen/geno-control \\ --ignore-weights YES \\ --power -1 \\ --window-cm 1 \\ --chr $j &quot;&gt; sh_script/tagging-gcta-hapmap3-chr$j done for j in {1..22}; do sbatch -A snpher ../sh_script/tagging-gcta-hapmap3-chr$j done &gt; ../job-records/tagging-gcta-hapmap3-control # check job completion---------------------------------------------------------- file=job-records/tagging-gcta-hapmap3-control jobs=`awk &#39;{print $4}&#39; $file` mkdir $file-tmp for i in $jobs; do jobinfo $i | awk -F &quot;:&quot; -v i=$i &#39;$1~/Name/ {print i, $2}&#39; &gt;&gt; $file-tmp/name.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/State/ {print$2}&#39; &gt;&gt; $file-tmp/state.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Cores/ {print$2}&#39; &gt;&gt; $file-tmp/cores.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Used walltime/ {print $2 &quot;:&quot; $3 &quot;:&quot; $4}&#39; &gt;&gt; $file-tmp/time.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Max Mem/ {split($2,a,/[(]/ ); print a[1]}&#39; &gt;&gt; $file-tmp/mem.tmp done paste $file-tmp/name.tmp \\ $file-tmp/state.tmp \\ $file-tmp/cores.tmp \\ $file-tmp/time.tmp \\ $file-tmp/mem.tmp \\ | awk &#39;BEGIN{print &quot;ID name state cores time mem&quot;}{print $0}&#39; &gt; $file.out rm -r $file-tmp # merge tagging files----------------------------------------------------------- rm list.txt for j in {1..22}; do echo &quot;tagging-control/gcta-hapmap3-chr-$j.tagging&quot; &gt;&gt; list.txt done ./ldak5.1 --join-tagging tagging-control/gcta-hapmap3 --taglist list.txt # ldsc intercept---------------------------------------------------------------- mkdir sumher-control dirin1=tagging-control dirin2=gwas-control dirout=sumher-control for i in {awake,bmi,chron,ever,fvc,height,quals,imp,neur,pulse,reaction,sbp,snoring,hyper}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 5G #SBATCH -c 1 #SBATCH -t 5:0:0 ./ldak5.1 --sum-hers ../$dirout/$i-sumher-gcta \\ --tagfile ../$dirin1/gcta-hapmap3.tagging \\ --summary ../$dirin2/$i-linear.summaries \\ --check-sums NO \\ --intercept YES &quot;&gt; sh_script/$i-sumher-gcta done for i in {awake,bmi,chron,ever,fvc,height,quals,imp,neur,pulse,reaction,sbp,snoring,hyper}; do sbatch -A snpher ../sh_script/$i-sumher-gcta done&gt;../job-records/sumher-gcta-control 7.4.2 under ldak-thin # get weights------------------------------------------------------------------- awk &lt; ldak-thin/ldak-thin-control.in &#39;{print $1, 1}&#39; &gt; ldak-thin/weights.ldak-thin-control # calculate tagging under ldak-thin--------------------------------------------- dirout=tagging-control filein1=geno-control filein2=weights.ldak-thin-control for j in {1..22}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --partition normal #SBATCH --mem 40G #SBATCH -c 5 #SBATCH -t 10:0:0 #SBATCH --constraint \\&quot;s04|s05\\&quot; ./ldak5.1 --calc-tagging ../$dirout/ldak-thin-hapmap3-chr-$j \\ --bfile ../gen/$filein1 \\ --weights ../ldak-thin/$filein2 \\ --power -.25 \\ --window-cm 1 \\ --chr $j \\ --save-matrix YES \\ --max-threads 5 &quot; &gt; sh_script/tagging-ldak-thin-hapmap3-chr$j.sh done # submit scripts for j in {1..22}; do sbatch -A snpher ../sh_script/tagging-ldak-thin-hapmap3-chr$j.sh done &gt; ../job-records/tagging-ldak-thin-control # check job completion---------------------------------------------------------- file=job-records/tagging-ldak-thin-control jobs=`awk &#39;{print $4}&#39; $file` mkdir $file-tmp for i in $jobs; do jobinfo $i | awk -F &quot;:&quot; -v i=$i &#39;$1~/Name/ {print i, $2}&#39; &gt;&gt; $file-tmp/name.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/State/ {print$2}&#39; &gt;&gt; $file-tmp/state.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Cores/ {print$2}&#39; &gt;&gt; $file-tmp/cores.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Used walltime/ {print $2 &quot;:&quot; $3 &quot;:&quot; $4}&#39; &gt;&gt; $file-tmp/time.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Max Mem/ {split($2,a,/[(]/ ); print a[1]}&#39; &gt;&gt; $file-tmp/mem.tmp done paste $file-tmp/name.tmp \\ $file-tmp/state.tmp \\ $file-tmp/cores.tmp \\ $file-tmp/time.tmp \\ $file-tmp/mem.tmp \\ | awk &#39;BEGIN{print &quot;ID name state cores time mem&quot;}{print $0}&#39; &gt; $file.out rm -r $file-tmp # merge tagging files----------------------------------------------------------- rm list.txt rm matlist.txt for j in {1..22}; do echo &quot;tagging-control/ldak-thin-hapmap3-chr-$j.tagging&quot; &gt;&gt; list.txt echo &quot;tagging-control/ldak-thin-hapmap3-chr-$j.matrix&quot; &gt;&gt; matlist.txt done dirout=tagging-control ./ldak5.1 --join-tagging $dirout/ldak-thin-hapmap3 --taglist list.txt --matlist matlist.txt # ldsc intercept---------------------------------------------------------------- dirin1=tagging-control dirin2=gwas-control dirout=sumher-control for i in {awake,bmi,chron,ever,fvc,height,quals,imp,neur,pulse,reaction,sbp,snoring,hyper}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 5G #SBATCH -c 1 #SBATCH -t 00:30:0 ./ldak5.1 --sum-hers ../$dirout/$i-sumher-ldak-thin \\ --tagfile ../$dirin1/ldak-thin-hapmap3.tagging \\ --summary ../$dirin2/$i-linear.summaries \\ --check-sums NO \\ --intercept YES &quot;&gt; sh_script/$i-sumher-ldak-thin done for i in {awake,bmi,chron,ever,fvc,height,quals,imp,neur,pulse,reaction,sbp,snoring,hyper}; do sbatch -A snpher ../sh_script/$i-sumher-ldak-thin done&gt;../job-records/sumher-ldak-thin-control 7.4.3 summary nm=control # original ldsc cd ldsc/out-control grep Intercept *ldsc.log | awk &#39;{split($1, a, /[-]/); split($3, b, /[()]/); print a[1], $2, b[2]}&#39; &gt; ../../summary/ldsc-$nm # sumher under gcta cd sumher-control grep Intercept_Estimate *gcta.extra | awk &#39;{ split($1, a, /[-]/); print a[1], $2}&#39; &gt;../summary/sumher-gcta-$nm-est grep Intercept_SD *gcta.extra | awk &#39;{ split($1, a, /[-]/); print a[1], $2}&#39; &gt;../summary/sumher-gcta-$nm-sd cd ../summary/ paste sumher-gcta-$nm-est sumher-gcta-$nm-sd | awk &#39;{print $1, $2, $4}&#39; &gt; sumher-gcta-$nm # suhmer under ldak-thin grep Intercept_Estimate *ldak-thin.extra | awk &#39;{ split($1, a, /[-]/); print a[1], $2}&#39; &gt;../summary/sumher-ldak-thin-$nm-est grep Intercept_SD *ldak-thin.extra | awk &#39;{ split($1, a, /[-]/); print a[1], $2}&#39; &gt;../summary/sumher-ldak-thin-$nm-sd cd ../summary/ paste sumher-ldak-thin-$nm-est sumher-ldak-thin-$nm-sd | awk &#39;{print $1, $2, $4}&#39; &gt; sumher-ldak-thin-$nm 7.5 HE 7.5.1 making grms # making grm ------------------------------------------------------------------- #::: # under gcta #::: fileout=gcta-all-control filein=geno-control snp=snps-control-gwas.use # all snps echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --partition normal #SBATCH --mem 60G #SBATCH -c 10 #SBATCH -t 08:0:0 #SBATCH --constraint \\&quot;s04|s05\\&quot; ./ldak5.1 --max-threads 10 \\ --calc-kins-direct ../kinship/$fileout \\ --bfile ../gen/$filein \\ --extract ../gen/$snp \\ --power -1 \\ --ignore-weights YES \\ --single YES &quot; &gt; sh_script/grm-all-snps sbatch -A snpher ../sh_script/grm-all-snps &gt; ../job-records/grm-all-snps-control # grm by snp blocks: right vs. left awk &#39;$1&lt;8 {print $2}&#39; geno-control.bim &gt; left-snps-control.use awk &#39;$1&gt;=8 {print $2}&#39; geno-control.bim &gt; right-snps-control.use filein=geno-control for i in left right; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --partition normal #SBATCH --mem 60G #SBATCH -c 10 #SBATCH -t 20:0:0 #SBATCH --constraint \\&quot;s04|s05\\&quot; ./ldak5.1 --max-threads 10 \\ --calc-kins-direct ../kinship/gcta-$i-control \\ --bfile ../gen/$filein \\ --extract ../gen/$i-snps-control.use \\ --power -1 \\ --ignore-weights YES \\ --single YES &quot; &gt; sh_script/grm-gcta-$i done for i in left right; do sbatch -A snpher ../sh_script/grm-gcta-$i done &gt; ../job-records/grm-gcta-by-snps-control #::: # under ldak-thin #::: #----------- # 1. thin snps #----------- snp=snps-control-gwas.use filein=geno-control for j in {1..22}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --partition normal #SBATCH --mem 10G #SBATCH -c 4 #SBATCH -t 4:0:0 #SBATCH --constraint \\&quot;s04|s05\\&quot; ./ldak5.1 --max-threads 4 \\ --window-prune 0.98 \\ --window-kb 100 \\ --extract ../gen/$snp \\ --bfile ../gen/$filein \\ --thin ../ldak-thin/chr$j-control \\ --chr $j &quot; &gt; sh_script/ldak-thin$j done # submit script for j in {1..22}; do sbatch -A snpher ../sh_script/ldak-thin$j done &gt; ../job-records/ldak-thin-control # check job completion--- file=job-records/ldak-thin-control jobs=`awk &#39;{print $4}&#39; $file` mkdir $file-tmp for i in $jobs; do jobinfo $i | awk -F &quot;:&quot; -v i=$i &#39;$1~/Name/ {print i, $2}&#39; &gt;&gt; $file-tmp/name.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/State/ {print$2}&#39; &gt;&gt; $file-tmp/state.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Cores/ {print$2}&#39; &gt;&gt; $file-tmp/cores.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Used walltime/ {print $2 &quot;:&quot; $3 &quot;:&quot; $4}&#39; &gt;&gt; $file-tmp/time.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Max Mem/ {split($2,a,/[(]/ ); print a[1]}&#39; &gt;&gt; $file-tmp/mem.tmp done paste $file-tmp/name.tmp \\ $file-tmp/state.tmp \\ $file-tmp/cores.tmp \\ $file-tmp/time.tmp \\ $file-tmp/mem.tmp \\ | awk &#39;BEGIN{print &quot;ID name state cores time mem&quot;}{print $0}&#39; &gt; $file.out rm -r $file-tmp # combine snp list cat ldak-thin/chr{1..22}-control.in &gt; ldak-thin/ldak-thin-control.in #---------------------- # 2. kinship matrix under ldak-thin #----------------------- fileout=ldak-thin-all-control filein=geno-control snp=ldak-thin-control.in echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --partition normal #SBATCH --mem 60G #SBATCH -c 10 #SBATCH -t 08:0:0 #SBATCH --constraint \\&quot;s04|s05\\&quot; ./ldak5.1 --max-threads 10 \\ --calc-kins-direct ../kinship/$fileout \\ --bfile ../gen/$filein \\ --extract ../ldak-thin/$snp \\ --power -0.25 \\ --ignore-weights YES \\ --single YES &quot; &gt; sh_script/ldak-thin-grm-all-snps sbatch -A snpher ../sh_script/ldak-thin-grm-all-snps &gt; ../job-records/ldak-thin-grm-all-snps-control # grm by snp blocks: right vs. left awk &#39;{split($1, a, /[:]/); if (a[1]&lt;8) print $1}&#39; \\ ldak-thin/ldak-thin-control.in &gt; gen/left-ldak-thin-control.snps awk &#39;{split($1, a, /[:]/); if (a[1]&gt;=8) print $1}&#39; \\ ldak-thin/ldak-thin-control.in &gt; gen/right-ldak-thin-control.snps for i in left right; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --partition normal #SBATCH --mem 60G #SBATCH -c 10 #SBATCH -t 08:0:0 #SBATCH --constraint \\&quot;s04|s05\\&quot; ./ldak5.1 --max-threads 10 \\ --calc-kins-direct ../kinship/ldak-thin-$i-control \\ --bfile ../gen/geno-control \\ --extract ../gen/$i-ldak-thin-control.snps \\ --power -0.25 \\ --ignore-weights YES \\ --single YES &quot; &gt; sh_script/ldak-thin-grm-$i done for i in left right; do sbatch -A snpher ../sh_script/ldak-thin-grm-$i done &gt; ../job-records/grm-ldak-thin-by-snps-control 7.5.2 estimation NEED To check what covariates to adjust for HE basic.covariates.use or covariates.use? # regress grm on covariates----------------------------------------------------- for grm in gcta-all-control gcta-left-control gcta-right-control ldak-thin-all-control ldak-thin-left-control ldak-thin-right-control; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 50G #SBATCH -c 5 #SBATCH -t 10:0:0 ./ldak5.1 --adjust-grm ../kinship/$grm.covar \\ --grm ../kinship/$grm \\ --covar ../phen/covariates.use \\ --max-threads 5 &quot;&gt; sh_script/$grm-adjust.sh done # submit jobs for grm in gcta-all-control gcta-left-control gcta-right-control ldak-thin-all-control ldak-thin-left-control ldak-thin-right-control; do sbatch -A snpher ../sh_script/$grm-adjust.sh done &gt; ../job-records/grm-adjust-for-HE-control # check job completion---------------------------------------------------------- file=job-records/grm-adjust-for-HE-control jobs=`awk &#39;{print $4}&#39; $file` mkdir $file-tmp for i in $jobs; do jobinfo $i | awk -F &quot;:&quot; -v i=$i &#39;$1~/Name/ {print i, $2}&#39; &gt;&gt; $file-tmp/name.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/State/ {print$2}&#39; &gt;&gt; $file-tmp/state.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Cores/ {print$2}&#39; &gt;&gt; $file-tmp/cores.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Used walltime/ {print $2 &quot;:&quot; $3 &quot;:&quot; $4}&#39; &gt;&gt; $file-tmp/time.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Max Mem/ {split($2,a,/[(]/ ); print a[1]}&#39; &gt;&gt; $file-tmp/mem.tmp done paste $file-tmp/name.tmp \\ $file-tmp/state.tmp \\ $file-tmp/cores.tmp \\ $file-tmp/time.tmp \\ $file-tmp/mem.tmp \\ | awk &#39;BEGIN{print &quot;ID name state cores time mem&quot;}{print $0}&#39; &gt; $file.out rm -r $file-tmp # HE under gcta----------------------------------------------------------------- mkdir he-control dirout=he-control for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do for k in all left right; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 2G #SBATCH -c 1 #SBATCH -t 00:30:0 ./ldak5.1 --he ../$dirout/$i-he-gcta-$k \\ --pheno ../phen/continuous-traits/$i.raw.pheno \\ --grm ../kinship/gcta-$k-control.covar \\ --kinship-details NO \\ --check-root NO \\ --covar ../phen/covariates.use \\ --max-threads 1 \\ --memory-save YES &quot;&gt; sh_script/$i-he-gcta-$k-snps-control.sh done done # submit files------------------------------------------------------------------ for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do for k in all left right; do sbatch -A snpher ../sh_script/$i-he-gcta-$k-snps-control.sh done done &gt; ../job-records/he-gcta-control # HE under ldak-thin------------------------------------------------------------ dirout=he-control for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do for k in all left right; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 2G #SBATCH -c 1 #SBATCH -t 0:30:0 ./ldak5.1 --he ../$dirout/$i-he-ldak-thin-$k \\ --pheno ../phen/continuous-traits/$i.raw.pheno \\ --grm ../kinship/ldak-thin-$k-control.covar \\ --kinship-details NO \\ --check-root NO \\ --covar ../phen/covariates.use \\ --max-threads 1 \\ --memory-save YES &quot;&gt; sh_script/$i-he-ldak-thin-$k-control.sh done done # submit files------------------------------------------------------------------ for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do for k in all left right; do sbatch -A snpher ../sh_script/$i-he-ldak-thin-$k-control.sh done done &gt; ../job-records/he-ldak-thin-control 7.5.3 summary #:::::::::::: # under gcta #:::::::::::: nm=control # extract h2 estimates --------------------------------------------------------- # right rm summary/he-gcta-$nm.right for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do outfile=he-$nm/$i-he-gcta-right.he awk -v i=$i &#39;$1==&quot;Her_All&quot; {print i, $2, $3}&#39; $outfile &gt;&gt; summary/he-gcta-$nm.right done # left rm summary/he-gcta-$nm.left for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do outfile=he-$nm/$i-he-gcta-left.he awk -v i=$i &#39;$1==&quot;Her_All&quot; {print i, $2, $3}&#39; $outfile &gt;&gt; summary/he-gcta-$nm.left done # all rm summary/he-gcta-$nm.all for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do outfile=he-$nm/$i-he-gcta-all.he awk -v i=$i &#39;$1==&quot;Her_All&quot; {print i, $2, $3}&#39; $outfile &gt;&gt; summary/he-gcta-$nm.all done # inflation test---------------------------------------------------------------- R full=read.table(paste0(&quot;summary/he-gcta-control.all&quot;), header=F) left=read.table(paste0(&quot;summary/he-gcta-control.left&quot;), header=F) right=read.table(paste0(&quot;summary/he-gcta-control.right&quot;), header=F) names(full)=names(left)=names(right)=c(&quot;code&quot;,&quot;h2&quot;,&quot;se&quot;) # some analyses did not complete --&gt; match dataframes dim(full);dim(left);dim(right) common=intersect(full$code, left$code) common=intersect(common, right$code) m1=match(common, right$code) m2=match(common, full$code) m3=match(common, left$code) right=right[m1,] full=full[m2,] left=left[m3,] for(i in 1:dim(full)[1]){ est1=left$h2[i] sd1=left$se[i] est2=right$h2[i] sd2=right$se[i] est=full$h2[i] sd=full$se[i] N=100000 d1=rnorm(N,est1,sd1) d2=rnorm(N,est2,sd2) d=rnorm(N,est,sd) p=1-mean(d1+d2-d&gt;=0) out0=data.frame(code=full$code[i], right_est=est2, right_sd=sd2, left_est=est1, left_sd=sd1, all_est=est, all_sd=sd, p_inflation=p) if(i==1){out=out0}else{out=rbind(out,out0)} } write.table(out, paste0(&quot;summary/he-gcta-inflation-control.txt&quot;), col.names=T, row.names=F, quote=F) #:::::::::::: # under ldak-thin #:::::::::::: nm=control # extract h2 estimates --------------------------------------------------------- # right rm summary/he-ldak-thin-$nm.right for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do outfile=he-$nm/$i-he-ldak-thin-right.he awk -v i=$i &#39;$1==&quot;Her_All&quot; {print i, $2, $3}&#39; $outfile &gt;&gt; summary/he-ldak-thin-$nm.right done # left rm summary/he-ldak-thin-$nm.left for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do outfile=he-$nm/$i-he-ldak-thin-left.he awk -v i=$i &#39;$1==&quot;Her_All&quot; {print i, $2, $3}&#39; $outfile &gt;&gt; summary/he-ldak-thin-$nm.left done # all rm summary/he-ldak-thin-$nm.all for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do outfile=he-$nm/$i-he-gcta-all.he awk -v i=$i &#39;$1==&quot;Her_All&quot; {print i, $2, $3}&#39; $outfile &gt;&gt; summary/he-ldak-thin-$nm.all done # inflation test---------------------------------------------------------------- R full=read.table(paste0(&quot;summary/he-ldak-thin-control.all&quot;), header=F) left=read.table(paste0(&quot;summary/he-ldak-thin-control.left&quot;), header=F) right=read.table(paste0(&quot;summary/he-ldak-thin-control.right&quot;), header=F) names(full)=names(left)=names(right)=c(&quot;code&quot;,&quot;h2&quot;,&quot;se&quot;) # some analyses did not complete --&gt; match dataframes dim(full);dim(left);dim(right) common=intersect(full$code, left$code) common=intersect(common, right$code) m1=match(common, right$code) m2=match(common, full$code) m3=match(common, left$code) right=right[m1,] full=full[m2,] left=left[m3,] for(i in 1:dim(full)[1]){ est1=left$h2[i] sd1=left$se[i] est2=right$h2[i] sd2=right$se[i] est=full$h2[i] sd=full$se[i] N=100000 d1=rnorm(N,est1,sd1) d2=rnorm(N,est2,sd2) d=rnorm(N,est,sd) p=1-mean(d1+d2-d&gt;=0) out0=data.frame(code=full$code[i], right_est=est2, right_sd=sd2, left_est=est1, left_sd=sd1, all_est=est, all_sd=sd, p_inflation=p) if(i==1){out=out0}else{out=rbind(out,out0)} } write.table(out, paste0(&quot;summary/he-ldak-thin-inflation-control.txt&quot;), col.names=T, row.names=F, quote=F) "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
