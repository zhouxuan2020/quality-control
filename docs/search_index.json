[["index.html", "GWAS Quality Control 1 General Info 1.1 Topic 1.2 Frequently used commands", " GWAS Quality Control updated on 2022-03-08 1 General Info 1.1 Topic We propose a new method to detect the inflation of GWAS test statistics caused by population stratification (&amp; cryptic relatedness). Here we document all analyses and results. Background: Existing methods: use summary statistics to detect and correct inflation in GWAS test statistics. genomic inflation factor: \\(S_{median}\\)/\\(\\chi^2 (1)_{median}\\) &gt; 1 ? does not account for inflation due to polygenicity LD score regression (Bulik-Sullivan et al., 2015) (LDSC): \\(S_{j} = 1 + n_{j}a + n_{j}\\sum_{i}^{k}(r_{ji}^2 \\ q_{i}/Q) h^2_{snp} + \\epsilon_{j}\\) under GCTA: \\(q_{i}=1, Q=\\sum_{i}^{m}q_i=m\\) under LDAK-thin: \\(q_{i}=I_{i}[f_{i}(1-f_{i})]^{0.75}\\) It separates the inflation due to confounding (intercept) and the inflation due to polygenicity (slope). The inflation due to confounding may not be constant but SNP specific instead (Holmes et al., 2019). Hence, summary statistics may not be good after all to detect the inflation due to confounding. Proposed method: use individual level data to detect inflation and maybe extended to summary statistics (?). \\(T = (\\hat{h^2}_{right} + \\hat{h^2}_{left}) - \\hat{h^2}_{whole} &gt; 0\\) ? Confounding causes cross-chromosome correlations, such that each part of the genome tags each other. Hence, for confounded GWASs, \\(T = (\\hat{h^2}_{right} + \\hat{h^2}_{left}) - \\hat{h^2}_{whole} &gt; 0\\). when \\(h_{right}^2, h_{left}^2, h_{whole}^2\\) are estimated using Haseman Elston regression, this test amounts to testing \\(tr(K_{left}K_{right}) = 0\\) or average SNP correlation^2 (between left and right) = 0. Challenge: We do not know the distribution of \\(T\\) under the null (i.e., no confounding). Consequently, the test is an approximate test. We hope to get an exact test. Also we want to simplify the test by directly testing if \\(tr(K_{left}K_{right}) = 0\\) or average SNP correlation^2 (between left and right) = 0. Still we need to work out the distribution of average SNP correlation^2 (between left and right) under the null (i.e., no association). Design: good GWASs: 100k unrelated white British bad or confounded GWASs: 93k unrelated white British + 7k blacks &amp; Asians control GWASs: 93k unrelated white British + 7k unrelated white British (who are not included in the good GWASs) We also checked if confouding is evident for the UKBB recommended white British (a randomly selection of 100k out of 337k), on which most UKBB GWASs are based. Results: So far the proposed and existing methods perform equally well. good GWAS: no sig. inflation due to confounding bad GWAS: sig. inflation due to confounding control GWAS: no sig. inflation due to confounding UKBB recommended: no evidence of inflation by any of the methods. The proposed method does not seem to be more advantageous than existing methods. However, this does not mean that the existing methods are without problems. The inflation may not be constant as assumed by existing methods. 1.2 Frequently used commands ssh -l zhoux login.genome.au.dk sftp zhoux@login.genome.au.dk lcd /home/zhoux/Dropbox/github/quality-control/main-files cd /home/zhoux/dsmwpred/xuan/quality-control/qc-10oct srun --mem=15g -c 2 -t 5:0:0 --constraint \"s04|s05\" -A snpher --pty /bin/bash References Bulik-Sullivan, B. K., Loh, P.-R., Finucane, H. K., Ripke, S., Yang, J., Patterson, N., Daly, M. J., Price, A. L., &amp; Neale, B. M. (2015). LD score regression distinguishes confounding from polygenicity in genome-wide association studies. Nature Genetics, 47(3), 291–295. Holmes, J. B., Speed, D., &amp; Balding, D. J. (2019). Summary statistic analyses can mistake confounding bias for heritability. Genetic Epidemiology, 43(8), 930–940. https://doi.org/https://doi.org/10.1002/gepi.22259 "],["summaries.html", "2 Summaries 2.1 Good GWAS 2.2 Bad GWAS 2.3 UKBB recommended 2.4 Control GWAS", " 2 Summaries To compare the proposed method against existing ones, we performed good and bad GWASs for 14 traits using N = 100k. While both sets of GWASs were based on quality-controlled genotype data, bad GWASs used individuals of different ethnicity and hence were confounded by population stratification, which is known to cause inflation in test statistics. As expected, for the good GWASs, no inflation was detected by the methods, though with some exceptions ( Tables 2.1 ). In contrast, for the bad GWASs significant inflation was evident based on all methods ( see Tables 2.3 &amp; 2.4 ). The detected inflation for the GWASs is not due to random errors because no inflation was observed for the control GWASs ( see Tables 2.7 &amp; 2.8 ) 2.1 Good GWAS Code for the good GWAS can be found in section 6. Basically, we used 100k unrelated white British with quality-controlled genotype data for the GWASs. We tested the GWAS test statistics for inflation using ldsc, sumher and the proposed method (based on individual level data using Haseman Elston regression) 2.1.1 ldsc &amp; sumher Table 2.1: Good GWAS: LDSC regression line intercept estimates (SE) using ldsc and sumher ldsc sumher-gcta sumher-ldak-thin trait est se wald_p est se wald_p est se wald_p awake 1.002 0.007 7.8e-01 0.997 0.008 6.8e-01 0.995 0.009 5.8e-01 bmi 1.017 0.009 6.2e-02 0.994 0.010 5.3e-01 0.997 0.010 7.3e-01 chron 1.012 0.008 1.2e-01 1.011 0.009 2.0e-01 1.013 0.009 1.4e-01 ever 1.000 0.007 9.4e-01 0.996 0.009 6.1e-01 0.995 0.009 5.6e-01 fvc 1.032 0.010 1.4e-03 1.014 0.010 1.4e-01 1.007 0.010 4.6e-01 height 1.094 0.017 1.9e-08 1.018 0.012 1.4e-01 1.031 0.012 7.9e-03 hyper 1.018 0.009 5.6e-02 1.013 0.009 1.5e-01 1.002 0.009 8.6e-01 imp 1.016 0.011 1.3e-01 0.987 0.010 1.8e-01 0.991 0.010 3.4e-01 neur 1.004 0.009 6.8e-01 0.997 0.009 7.1e-01 0.996 0.009 6.5e-01 pulse 1.029 0.010 2.3e-03 1.016 0.009 8.5e-02 1.019 0.009 4.2e-02 quals 1.020 0.008 1.5e-02 1.014 0.009 1.3e-01 1.012 0.009 2.1e-01 reaction 1.010 0.007 1.6e-01 1.007 0.009 4.0e-01 1.003 0.009 7.0e-01 sbp 1.007 0.009 3.9e-01 0.999 0.009 8.8e-01 0.997 0.009 7.2e-01 snoring 1.008 0.007 2.6e-01 1.004 0.008 6.3e-01 1.004 0.009 6.4e-01 Note: p-values are based on the wald test that compares the ldsc regression line intercept against 1. p-values &lt;= Bonferroni corrected alpha (i.e., 0.05/14) are highlighted 2.1.2 Haseman Elston Regression Table 2.2: Good GWAS: Heritability estimates (SE) using Haseman Elston regression under assumed heritability models trait right_est right_sd left_est left_sd all_est all_sd p_inflation under gcta awake 0.040 0.004 0.034 0.004 0.073 0.005 4.9e-01 bmi 0.137 0.005 0.126 0.005 0.263 0.007 4.9e-01 chron 0.060 0.004 0.048 0.004 0.108 0.005 4.8e-01 ever 0.041 0.004 0.043 0.004 0.085 0.005 5.1e-01 fvc 0.110 0.005 0.100 0.004 0.210 0.006 4.9e-01 height 0.294 0.007 0.264 0.006 0.558 0.009 4.8e-01 imp 0.154 0.006 0.141 0.005 0.295 0.008 4.9e-01 neur 0.064 0.004 0.057 0.004 0.121 0.006 4.9e-01 pulse 0.081 0.004 0.076 0.004 0.156 0.006 5.0e-01 quals 0.088 0.004 0.089 0.004 0.177 0.006 5.1e-01 reaction 0.034 0.004 0.038 0.004 0.072 0.005 5.1e-01 sbp 0.086 0.005 0.076 0.004 0.162 0.007 4.9e-01 snoring 0.034 0.004 0.033 0.004 0.068 0.005 5.0e-01 hyper 0.065 0.005 0.049 0.004 0.114 0.006 4.8e-01 under ldak-thin awake 0.037 0.004 0.033 0.004 0.070 0.005 4.9e-01 bmi 0.134 0.005 0.122 0.005 0.256 0.007 5.0e-01 chron 0.056 0.004 0.048 0.004 0.104 0.005 5.0e-01 ever 0.039 0.004 0.041 0.004 0.080 0.005 5.0e-01 fvc 0.105 0.005 0.100 0.004 0.205 0.006 5.0e-01 height 0.269 0.006 0.253 0.006 0.522 0.009 4.9e-01 imp 0.149 0.006 0.135 0.005 0.284 0.008 4.9e-01 neur 0.064 0.005 0.056 0.004 0.120 0.006 5.0e-01 pulse 0.077 0.004 0.073 0.004 0.150 0.006 5.0e-01 quals 0.085 0.004 0.089 0.004 0.173 0.006 5.0e-01 reaction 0.034 0.004 0.038 0.004 0.072 0.005 5.0e-01 sbp 0.088 0.006 0.076 0.004 0.163 0.007 5.0e-01 snoring 0.033 0.004 0.033 0.004 0.065 0.005 5.0e-01 hyper 0.068 0.005 0.049 0.004 0.117 0.006 5.0e-01 Note: p-values are for testing whether the sum of ‘left’ and ‘right’ heritability estimates are greater than the heritability estimate based on the whole genome. p-values &lt;= Bonferroni corrected alpha (i.e., 0.05/14) are highlighted 2.2 Bad GWAS Code for the bad GWAS can be found in section 7. Basically, we used 100k unrelated individuals that consist of 93,528 whites and 6,472 blacks and Asians (i.e., mixed populations). Hence, the GWASs were confounded by population stratification. We performed the confounded GWASs and tested the test statistics for inflation using ldsc, sumher and the proposed method (based on individual level data using Haseman Elston regression) 2.2.1 ldsc &amp; sumher Table 2.3: Bad GWAS: LDSC regression line intercept estimates (SE) using ldsc and sumher ldsc sumher-gcta sumher-ldak-thin trait est se wald_p est se wald_p est se wald_p awake 3.441 0.027 0.0e+00 3.513 0.026 0.0e+00 3.758 0.018 0.0e+00 bmi 5.040 0.030 0.0e+00 8.893 0.066 0.0e+00 9.536 0.045 0.0e+00 chron 1.453 0.012 1.9e-311 1.402 0.011 2.4e-283 1.465 0.011 0.0e+00 ever 6.838 0.028 0.0e+00 15.830 0.114 0.0e+00 16.885 0.080 0.0e+00 fvc NA NA NA 78.325 0.564 0.0e+00 83.464 0.393 0.0e+00 height NA NA NA 14.197 0.107 0.0e+00 15.475 0.103 0.0e+00 hyper 4.673 0.029 0.0e+00 6.891 0.050 0.0e+00 7.320 0.034 0.0e+00 imp NA NA NA 8.930 0.064 0.0e+00 9.467 0.045 0.0e+00 neur 4.179 0.026 0.0e+00 5.349 0.038 0.0e+00 5.682 0.027 0.0e+00 pulse 1.444 0.013 7.8e-260 1.406 0.012 1.5e-269 1.452 0.012 2.5e-323 quals 2.082 0.018 0.0e+00 2.023 0.016 0.0e+00 2.147 0.017 0.0e+00 reaction 8.123 0.031 0.0e+00 33.822 0.241 0.0e+00 35.822 0.169 0.0e+00 sbp 3.028 0.026 0.0e+00 3.050 0.023 0.0e+00 3.313 0.016 0.0e+00 snoring 1.050 0.007 3.1e-11 1.052 0.008 5.2e-10 1.047 0.009 6.3e-08 Note: p-values are based on the wald test that compares the ldsc regression line intercept against 1. p-values &lt;= Bonferroni corrected alpha (i.e., 0.05/14) are highlighted 2.2.2 Haseman Elston Regression Table 2.4: Bad GWAS: Heritability estimates (SE) using Haseman Elston regression under assumed heritability models trait right_est right_sd left_est left_sd all_est all_sd p_inflation under gcta awake 0.075 0.012 0.075 0.012 0.080 0.012 1.8e-04 bmi 0.237 0.023 0.235 0.023 0.249 0.025 0.0e+00 chron 0.016 0.004 0.016 0.004 0.017 0.004 2.0e-02 ever 0.439 0.028 0.434 0.027 0.461 0.029 0.0e+00 fvc 2.280 0.063 2.237 0.062 2.384 0.067 0.0e+00 height 0.406 0.023 0.402 0.023 0.426 0.024 0.0e+00 imp 0.228 0.015 0.227 0.015 0.240 0.016 0.0e+00 neur 0.128 0.015 0.129 0.015 0.136 0.016 1.0e-05 pulse 0.018 0.004 0.019 0.004 0.020 0.004 2.6e-03 quals 0.037 0.006 0.038 0.006 0.040 0.006 2.9e-04 reaction 0.959 0.059 0.950 0.059 1.008 0.063 0.0e+00 sbp 0.064 0.011 0.064 0.010 0.068 0.011 4.6e-04 snoring 0.004 0.001 0.005 0.001 0.005 0.001 3.1e-03 hyper 0.175 0.020 0.172 0.020 0.183 0.021 0.0e+00 under ldak-thin awake 0.090 0.014 0.090 0.014 0.080 0.012 2.0e-05 bmi 0.278 0.027 0.273 0.027 0.249 0.025 0.0e+00 chron 0.021 0.005 0.021 0.005 0.017 0.004 1.8e-03 ever 0.533 0.033 0.525 0.032 0.461 0.029 0.0e+00 fvc 2.782 0.076 2.734 0.074 2.384 0.067 0.0e+00 height 0.527 0.029 0.526 0.029 0.426 0.024 0.0e+00 imp 0.283 0.018 0.281 0.017 0.240 0.016 0.0e+00 neur 0.150 0.018 0.150 0.018 0.136 0.016 0.0e+00 pulse 0.024 0.004 0.025 0.004 0.020 0.004 1.0e-05 quals 0.049 0.007 0.050 0.007 0.040 0.006 0.0e+00 reaction 1.146 0.070 1.135 0.069 1.008 0.063 0.0e+00 sbp 0.077 0.012 0.075 0.012 0.068 0.011 1.0e-05 snoring 0.006 0.001 0.007 0.001 0.005 0.001 5.0e-05 hyper 0.206 0.024 0.202 0.023 0.183 0.021 0.0e+00 Note: p-values are for testing whether the sum of ‘left’ and ‘right’ heritability estimates are greater than the heritability estimate based on the whole genome. p-values &lt;= Bonferroni corrected alpha (i.e., 0.05/14) are highlighted 2.3 UKBB recommended Code for this GWAS can be found in section 8. Basically, we randomly selected 100k white British from a total of 337k individuals that are recommended by the UKBB (i.e., QCed by the UKBB). We performed the GWASs and tested the test statistics for inflation using ldsc, sumher and the proposed method (based on individual level data using Haseman Elston regression). 2.3.1 ldsc &amp; sumher Table 2.5: UKBB recommended: LDSC regression line intercept estimates (SE) using ldsc and sumher ldsc sumher-gcta sumher-ldak-thin trait est se wald_p est se wald_p est se wald_p awake 1.017 0.007 9.8e-03 1.015 0.008 7.0e-02 1.012 0.009 1.7e-01 bmi 1.016 0.009 8.4e-02 0.995 0.010 6.1e-01 0.996 0.010 6.6e-01 chron 1.014 0.008 8.2e-02 1.008 0.009 3.4e-01 1.010 0.009 2.4e-01 ever 0.990 0.007 1.3e-01 0.986 0.008 1.1e-01 0.986 0.009 1.1e-01 fvc 1.036 0.009 2.8e-05 1.021 0.009 2.4e-02 1.018 0.009 6.4e-02 height 1.102 0.015 2.9e-11 1.030 0.012 1.1e-02 1.043 0.012 2.4e-04 hyper 1.010 0.007 1.7e-01 1.003 0.009 6.9e-01 1.003 0.009 7.3e-01 imp 1.029 0.009 1.2e-03 1.004 0.010 6.9e-01 1.005 0.010 5.8e-01 neur 1.010 0.009 2.9e-01 1.007 0.009 4.1e-01 1.001 0.009 8.7e-01 pulse 1.007 0.009 4.2e-01 0.992 0.009 4.0e-01 0.995 0.009 5.6e-01 quals 1.015 0.009 7.4e-02 1.004 0.009 6.9e-01 1.002 0.009 8.5e-01 reaction 1.016 0.007 2.1e-02 1.015 0.009 8.1e-02 1.016 0.009 7.1e-02 sbp 1.022 0.009 8.9e-03 1.016 0.009 8.0e-02 1.011 0.009 2.1e-01 snoring 1.005 0.008 5.6e-01 1.002 0.008 8.5e-01 1.001 0.009 8.9e-01 Note: p-values are based on the wald test that compares the ldsc regression line intercept against 1. p-values &lt;= Bonferroni corrected alpha (i.e., 0.05/14) are highlighted 2.3.2 Haseman Elston Regression Table 2.6: UKBB recommended: Heritability estimates (SE) using Haseman Elston regression under assumed heritability models trait right_est right_sd left_est left_sd all_est all_sd p_inflation under gcta awake 0.034 0.004 0.030 0.003 0.062 0.005 3.7e-01 bmi 0.135 0.005 0.124 0.005 0.251 0.007 1.9e-01 chron 0.061 0.005 0.048 0.004 0.104 0.006 3.0e-01 ever 0.034 0.004 0.040 0.004 0.071 0.005 3.9e-01 fvc 0.098 0.005 0.103 0.005 0.194 0.007 2.4e-01 height 0.274 0.007 0.264 0.006 0.522 0.009 8.7e-02 imp 0.142 0.005 0.142 0.005 0.276 0.007 1.9e-01 neur 0.064 0.006 0.055 0.005 0.115 0.007 3.3e-01 pulse 0.084 0.005 0.077 0.004 0.155 0.006 2.5e-01 quals 0.084 0.004 0.089 0.004 0.168 0.006 2.4e-01 reaction 0.037 0.004 0.040 0.004 0.075 0.005 3.7e-01 sbp 0.086 0.005 0.073 0.004 0.154 0.007 2.8e-01 snoring 0.038 0.004 0.032 0.004 0.067 0.005 3.7e-01 hyper 0.057 0.004 0.046 0.004 0.100 0.006 3.2e-01 under ldak-thin awake 0.033 0.004 0.031 0.003 0.062 0.005 4.2e-01 bmi 0.134 0.006 0.122 0.005 0.251 0.007 3.0e-01 chron 0.059 0.005 0.047 0.004 0.104 0.006 4.0e-01 ever 0.032 0.004 0.039 0.004 0.071 0.005 5.0e-01 fvc 0.094 0.005 0.101 0.005 0.194 0.007 4.3e-01 height 0.257 0.006 0.249 0.006 0.522 0.009 9.0e-01 imp 0.138 0.006 0.135 0.005 0.276 0.007 5.7e-01 neur 0.069 0.007 0.055 0.004 0.115 0.007 1.9e-01 pulse 0.081 0.005 0.074 0.004 0.155 0.006 4.6e-01 quals 0.083 0.004 0.088 0.004 0.168 0.006 3.8e-01 reaction 0.036 0.004 0.038 0.004 0.075 0.005 5.1e-01 sbp 0.085 0.005 0.072 0.004 0.154 0.007 3.7e-01 snoring 0.035 0.004 0.033 0.004 0.067 0.005 4.7e-01 hyper 0.055 0.004 0.045 0.004 0.100 0.006 5.0e-01 Note: p-values are for testing whether the sum of ‘left’ and ‘right’ heritability estimates are greater than the heritability estimate based on the whole genome. p-values &lt;= Bonferroni corrected alpha (i.e., 0.05/14) are highlighted 2.4 Control GWAS Code for this GWAS can be found in section 9. In short, we performed GWASs that serve as the control for the good versus bad GWASs comparison. This to ascertain that the observed inflation of bad GWAS test statistics is due to population stratification not random errors. We used a total of 100k that included 93,528 unrelated white British (also included in the bad and good GWAS) and 6,472 unrelated white British that were neither included in the good GWASs nor bad GWASs. 2.4.1 ldsc &amp; sumher Table 2.7: Control GWASs: LDSC regression line intercept estimates (SE) using ldsc and sumher ldsc sumher-gcta sumher-ldak-thin trait est se wald_p est se wald_p est se wald_p awake 0.996 0.006 5.4e-01 0.992 0.008 3.6e-01 0.994 0.008 4.5e-01 bmi 1.014 0.009 1.1e-01 0.991 0.010 3.9e-01 0.991 0.010 3.6e-01 chron 1.009 0.008 2.2e-01 1.008 0.009 3.4e-01 1.011 0.009 2.0e-01 ever 0.999 0.007 9.2e-01 0.996 0.009 6.4e-01 0.993 0.009 4.0e-01 fvc 1.034 0.010 5.1e-04 1.015 0.010 1.3e-01 1.007 0.010 4.6e-01 height 1.097 0.017 7.0e-09 1.019 0.012 1.1e-01 1.032 0.012 6.5e-03 hyper 1.017 0.010 7.9e-02 1.011 0.009 2.3e-01 1.000 0.009 9.6e-01 imp 1.012 0.011 2.8e-01 0.983 0.010 9.5e-02 0.988 0.010 2.1e-01 neur 1.001 0.009 9.4e-01 0.995 0.009 6.0e-01 0.997 0.009 6.9e-01 pulse 1.028 0.009 2.8e-03 1.012 0.009 1.8e-01 1.015 0.009 9.9e-02 quals 1.020 0.008 1.8e-02 1.014 0.009 1.5e-01 1.012 0.009 2.2e-01 reaction 1.013 0.007 7.4e-02 1.008 0.009 3.4e-01 1.006 0.009 4.7e-01 sbp 1.010 0.009 2.7e-01 1.000 0.009 9.8e-01 0.999 0.009 9.2e-01 snoring 1.010 0.007 1.7e-01 1.007 0.008 4.3e-01 1.008 0.009 3.8e-01 Note: p-values are based on the wald test that compares the ldsc regression line intercept against 1. p-values &lt;= Bonferroni corrected alpha (i.e., 0.05/14) are highlighted 2.4.2 Haseman Elston Regression Table 2.8: Control GWASs: Heritability estimates (SE) using Haseman Elston regression under assumed heritability models trait right_est right_sd left_est left_sd all_est all_sd p_inflation under gcta awake 0.034 0.004 0.030 0.003 0.062 0.005 3.7e-01 bmi 0.135 0.005 0.124 0.005 0.251 0.007 1.9e-01 chron 0.061 0.005 0.048 0.004 0.104 0.006 3.0e-01 ever 0.034 0.004 0.040 0.004 0.071 0.005 3.9e-01 fvc 0.098 0.005 0.103 0.005 0.194 0.007 2.4e-01 height 0.274 0.007 0.264 0.006 0.522 0.009 8.7e-02 imp 0.142 0.005 0.142 0.005 0.276 0.007 1.9e-01 neur 0.064 0.006 0.055 0.005 0.115 0.007 3.3e-01 pulse 0.084 0.005 0.077 0.004 0.155 0.006 2.5e-01 quals 0.084 0.004 0.089 0.004 0.168 0.006 2.4e-01 reaction 0.037 0.004 0.040 0.004 0.075 0.005 3.7e-01 sbp 0.086 0.005 0.073 0.004 0.154 0.007 2.8e-01 snoring 0.038 0.004 0.032 0.004 0.067 0.005 3.7e-01 hyper 0.057 0.004 0.046 0.004 0.100 0.006 3.2e-01 under ldak-thin awake 0.033 0.004 0.031 0.003 0.062 0.005 4.2e-01 bmi 0.134 0.006 0.122 0.005 0.251 0.007 3.0e-01 chron 0.059 0.005 0.047 0.004 0.104 0.006 4.0e-01 ever 0.032 0.004 0.039 0.004 0.071 0.005 5.0e-01 fvc 0.094 0.005 0.101 0.005 0.194 0.007 4.3e-01 height 0.257 0.006 0.249 0.006 0.522 0.009 9.0e-01 imp 0.138 0.006 0.135 0.005 0.276 0.007 5.7e-01 neur 0.069 0.007 0.055 0.004 0.115 0.007 1.9e-01 pulse 0.081 0.005 0.074 0.004 0.155 0.006 4.6e-01 quals 0.083 0.004 0.088 0.004 0.168 0.006 3.8e-01 reaction 0.036 0.004 0.038 0.004 0.075 0.005 5.1e-01 sbp 0.085 0.005 0.072 0.004 0.154 0.007 3.7e-01 snoring 0.035 0.004 0.033 0.004 0.067 0.005 4.7e-01 hyper 0.055 0.004 0.045 0.004 0.100 0.006 5.0e-01 Note: p-values are for testing whether the sum of ‘left’ and ‘right’ heritability estimates are greater than the heritability estimate based on the whole genome. p-values &lt;= Bonferroni corrected alpha (i.e., 0.05/14) are highlighted "],["good-vs-bad-gwas.html", "3 Good VS Bad GWAS 3.1 test statistics ~ LD score 3.2 New models? 3.3 LD scores based on individual level data 3.4 Test the new model 3.5 predictors of inflation? 3.6 regress bad chisq ~ mean r^2_j", " 3 Good VS Bad GWAS Here we investigate the inflation in test statistics from the bad GWASs. We want to find out 1) if the inflation is constant; 2) if it can be predicted in some way. 3.1 test statistics ~ LD score The inflation in GWAS test statistics due to confouding is not always constant, as assumed by LDSC. Below we plotted the chi-square test statistics from the bad (colored in red), good (orange), and control (gray) GWASs as a function of LD score ( Fig 3.1 ). The linear model assumed by LDSC is only appropriate for four traits, namely chron, pulse, quals, and snoring. For these traits, LDSC accounts for the inflation due to confounding (i.e., intercept) and the inflation due to polygenity (i.e., slope). However, LDSC is inadequate for other traits, where the inflation is non-linear. More specifically, for these traits, the test statistics for SNPs with a low LD score are much more inflated than would be expected by LDSC. Thus, although LDSC can detect the inflation in GWAS test statistics due to confounding, it cannot be used to correct the inflation for some traits. Figure 3.1: Test statistics by LD score for good, bad and control GWASs. 3.2 New models? \\(S_{j} = 1 + n_{j}a + n_{j}\\sum_{i}^{m}(r_{ji}^2 \\ q_{i}/Q) h^2_{snp} + \\epsilon_{j}\\) under GCTA: \\(q_{i}=1, Q=\\sum_{i}^{m}q_i=m\\) under LDAK-thin: \\(q_{i}=I_{i}[f_{i}(1-f_{i})]^{0.75}\\) \\(S_{j} = 1 + n_{j}a + n_{j}\\sum_{i}^{k}(r_{ji}^2 \\ q_{i}/Q) h^2_{snp} + n_j \\sum ()h + \\epsilon_{j}\\) under GCTA: \\(q_{i}=1, Q=\\sum_{i}^{m}q_i=m\\) under LDAK-thin: \\(q_{i}=I_{i}[f_{i}(1-f_{i})]^{0.75}\\) 3.3 LD scores based on individual level data mkdir ldsc/ldscore-individual-data mkdir gen/snps-unrel-inds-by-chrom # divide snp list by chrom for i in {1..22}; do awk -v i=$i &#39;{split($0, a , &quot;:&quot;)} (a[1]==i) {print $0}&#39; gen/snps-unrel-inds.use &gt; gen/snps-unrel-inds-by-chrom/snps-unrel-inds-$i done # compute LD scores for i in {1..22}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 80G #SBATCH -c 2 #SBATCH -t 10:0:0 .././ldsc.py \\ --bfile ../../gen/geno-mix \\ --extract ../../gen/snps-unrel-inds-by-chrom/snps-unrel-inds-$i \\ --keep ../../mix-pop-gwas.id \\ --l2 \\ --ld-wind-cm 1 \\ --out ../ldscore-individual-data/ldsc-mix-$i &quot;&gt; sh_script/compute-ldsc-$i.sh done for i in {1..22}; do sbatch -A snpher ../sh_script/compute-ldsc-$i.sh done &gt; ../../job-records/compute-ldsc-mix # check job completion file=job-records/compute-ldsc-mix jobs=`awk &#39;{print $4}&#39; $file` mkdir $file-tmp for i in $jobs; do jobinfo $i | awk -F &quot;:&quot; -v i=$i &#39;$1~/Name/ {print i, $2}&#39; &gt;&gt; $file-tmp/name.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/State/ {print$2}&#39; &gt;&gt; $file-tmp/state.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Cores/ {print$2}&#39; &gt;&gt; $file-tmp/cores.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Used walltime/ {print $2 &quot;:&quot; $3 &quot;:&quot; $4}&#39; &gt;&gt; $file-tmp/time.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Max Mem/ {split($2,a,/[(]/ ); print a[1]}&#39; &gt;&gt; $file-tmp/mem.tmp done paste $file-tmp/name.tmp \\ $file-tmp/state.tmp \\ $file-tmp/cores.tmp \\ $file-tmp/time.tmp \\ $file-tmp/mem.tmp \\ | awk &#39;BEGIN{print &quot;ID name state cores time mem&quot;}{print $0}&#39; &gt; $file.out rm -r $file-tmp 3.4 Test the new model Inflation = np^2 (h2-h2local) &lt;=np^2 extract heritability estimates from good GWASs np2h2 \\(S_{true}\\) vs \\(\\hat{S}_{ldsc}\\) vs \\(\\hat{S}_{new}\\) # extract heritability estimates h2_gcta=read.table(&#39;summary/reml-gcta-inflation-good-gwas.txt&#39;, header=T, stringsAsFactors = F) h2_ldak=read.table(&#39;summary/reml-ldak-thin-inflation-good-gwas.txt&#39;, header=T, stringsAsFactors = F) # average r_ij^2 r2_good=read.table(&quot;inflation/summary/ave-r2-1k-snps-goodgwas&quot;, header=F) r2_bad=read.table(&quot;inflation/summary/ave-r2-1k-snps-badgwas&quot;, header=F) r2_good=mean(r2_good$V1) r2_bad=mean(r2_bad$V1) # ldsc intercept estimates ldsc_bad=read.table(&quot;summary/ldsc-mix&quot;, header=F, stringsAsFactors = F) # GWAS test stats &amp; LD scores require(&quot;vroom&quot;) traits=c(&quot;awake&quot;,&quot;bmi&quot;,&quot;chron&quot;,&quot;ever&quot;, &quot;neur&quot;,&quot;pulse&quot;,&quot;quals&quot;, &quot;reaction&quot;,&quot;sbp&quot;,&quot;snoring&quot;,&quot;hyper&quot;) # c(&quot;fcv&quot;, &quot;height&quot;,&quot;imp&quot;) png(paste0(&quot;fig/predcited-chisq-by-ldscbin.png&quot;), width =40, height = 30, units = &quot;cm&quot;, res=600) par(mfrow=c(3,4)) for(i in 1:length(traits)){ n=100000 trait=traits[i] ldsc_intercept=ldsc_bad$V2[ldsc_bad$V1==trait] h2=h2_ldak$all_est[h2_ldak$code==trait] dat=vroom(paste0(&quot;summary/&quot;,trait,&quot;-gwas-test-stats-compare2.txt&quot;), col_names=T) dat$chisq_ldsc=dat$good_chisq+ldsc_intercept-1 dat$chisq_new=dat$good_chisq+n*r2_bad*h2 out=data.frame(ave_ldscore=tapply(dat$ldsc_ref,INDEX=dat$ldsc_ref_bin, mean), ave_chisq_ldsc=tapply(dat$chisq_ldsc,INDEX=dat$ldsc_ref_bin, mean), ave_chisq_new=tapply(dat$chisq_new,INDEX=dat$ldsc_ref_bin, mean), ave_good_chisq=tapply(dat$good_chisq,INDEX=dat$ldsc_ref_bin, mean), ave_bad_chisq=tapply(dat$bad_chisq,INDEX=dat$ldsc_ref_bin, mean)) end=round(max(c(out[,2], out[,3], out[,4]), out[,5]),0) start=round(min(c(out[,2], out[,3], out[,4]), out[,5]),0) plot(out$ave_ldscore, out$ave_bad_chisq, xlab=&quot;ldscore bin&quot;, ylab=&quot;mean chisquare&quot;, ylim=c(start, end), main=trait, las=1, cex = 1.5, pch=21, bg=&quot;grey&quot;, col=&quot;white&quot;, lwd=0.5) points(out$ave_ldscore, out$ave_chisq_new, cex = 1.5, pch=21, col=&quot;white&quot;, bg=&quot;orange&quot;) points(out$ave_ldscore, out$ave_chisq_ldsc, cex = 1.5, pch=21, col=&quot;white&quot;, bg=&quot;red&quot;) #points(out$ave_ldscore, out$ave_good_chisq, # cex = 1.5, pch=21, col=&quot;white&quot;, bg=&quot;gray&quot;) } dev.off() 3.5 predictors of inflation? Potential predictors considered: 1. MAF 2. ave r^2_ij for each j cross chromsomes [10k SNPs] # prep: convert snp labels to rs system awk &#39;(NR==FNR){a[$1]; b[$1]=$2; next}($1 in a){print b[$1], $2, $3, $5}&#39; doug/ukbb.ldsc gen/geno-unrel.stats &gt; gen/geno-unrel-rs.maf R require(&quot;vroom&quot;) # files for maf &amp; ave r2 by snp stat=vroom(&quot;gen/geno-unrel-rs.maf&quot;, col_names=F) r2_good=vroom(&quot;summary/ave-r2-by-snp-goodgwas-rs&quot;, col_names=F) r2_bad=vroom(&quot;summary/ave-r2-by-snp-badgwas-rs&quot;, col_names=F) # compute inflation in chisq (good vs. bad) by trait traits=c(&quot;awake&quot;,&quot;bmi&quot;,&quot;chron&quot;,&quot;ever&quot;, &quot;neur&quot;,&quot;pulse&quot;,&quot;quals&quot;, &quot;fvc&quot;, &quot;height&quot;,&quot;imp&quot;, &quot;reaction&quot;,&quot;sbp&quot;,&quot;snoring&quot;,&quot;hyper&quot;) for(i in 1:length(traits)){ trait=traits[i] dat=vroom(paste0(&quot;summary/&quot;,trait,&quot;-gwas-test-stats-compare2.txt&quot;), col_names=T) inflation=data.frame(snp=dat$SNP, inflation=dat$bad_chisq-dat$good_chisq, bad_chisq=dat$bad_chisq, good_chisq=dat$good_chisq, stringsAsFactors = F) m1=match(inflation$snp, stat$X1) m2=match(inflation$snp,r2_good$X1) m3=match(inflation$snp,r2_bad$X1) out=data.frame(inflation, maf=stat$X4[m1], r2_good=r2_good$X2[m2], r2_bad=r2_bad$X2[m2], stringsAsFactors = F) # bin maf &amp; r2_bad according to quantiles cutoff1=quantile(out$maf, probs = seq(0, 1, 0.005), na.rm=T) cutoff2=quantile(out$r2_bad, probs = seq(0, 1, 0.005), na.rm=T) out$maf_bin=cut(out$maf, breaks=cutoff1, labels=1:(length(cutoff1)-1)) out$r2_bad_bin=cut(out$r2_bad, breaks=cutoff2, labels=1:(length(cutoff2)-1)) write.table(out,paste0(&quot;inflation/summary/&quot;,trait,&quot;-inflation-by-maf-r2&quot;), col.names=T, row.names=F, quote=F) } # plot by maf require(vroom) traits=c(&quot;awake&quot;,&quot;bmi&quot;,&quot;chron&quot;,&quot;ever&quot;, &quot;neur&quot;,&quot;pulse&quot;,&quot;quals&quot;, &quot;reaction&quot;,&quot;sbp&quot;,&quot;snoring&quot;,&quot;hyper&quot;) # &quot;fcv&quot;, &quot;height&quot;,&quot;imp&quot;, png(paste0(&quot;fig/inflation-by-mafbin.png&quot;), width =40, height = 30, units = &quot;cm&quot;, res=600) par(mfrow=c(3,4)) for(i in 1:length(traits)){ trait=traits[i] dat=vroom(paste0(&quot;inflation/summary/&quot;,trait,&quot;-inflation-by-maf-r2&quot;), col_names=T) sel=dat[,c(&quot;snp&quot;,&quot;inflation&quot;,&quot;maf&quot;,&quot;maf_bin&quot;)] sel=sel[complete.cases(sel),] out=data.frame(inflation=tapply(sel$inflation,INDEX=sel$maf_bin, mean)) out$maf_bin=1:dim(out)[1] out$maf_bin_val=tapply(sel$maf,INDEX=sel$maf_bin, mean) plot(out$maf_bin_val, out$inflation, xlab=&quot;maf bin&quot;, ylab=&quot;mean inflation&quot;, main=trait, las=1, cex = 1.5, pch=21, bg=&quot;grey&quot;, col=&quot;white&quot;, lwd=0.5) } dev.off() # plot by r2_bad bin require(vroom) traits=c(&quot;awake&quot;,&quot;bmi&quot;,&quot;chron&quot;,&quot;ever&quot;, &quot;neur&quot;,&quot;pulse&quot;,&quot;quals&quot;, &quot;reaction&quot;,&quot;sbp&quot;,&quot;snoring&quot;,&quot;hyper&quot;) # &quot;fcv&quot;, &quot;height&quot;,&quot;imp&quot;, png(paste0(&quot;fig/inflation-by-aver2.png&quot;), width =40, height = 30, units = &quot;cm&quot;, res=600) par(mfrow=c(3,4)) for(i in 1:length(traits)){ trait=traits[i] dat=vroom(paste0(&quot;inflation/summary/&quot;,trait,&quot;-inflation-by-maf-r2&quot;), col_names=T) sel=dat[,c(&quot;snp&quot;,&quot;inflation&quot;,&quot;r2_bad&quot;,&quot;r2_bad_bin&quot;)] sel=sel[complete.cases(sel),] out=data.frame(inflation=tapply(sel$inflation,INDEX=sel$r2_bad_bin, mean)) out$r2_bad_bin=1:dim(out)[1] out$r2_bad_bin_val=tapply(sel$r2_bad,INDEX=sel$r2_bad_bin, mean) plot(out$r2_bad_bin_val, out$inflation, xlab=&quot;ave r2 bin&quot;, ylab=&quot;mean inflation&quot;, main=trait, las=1, cex = 1.5, pch=21, bg=&quot;grey&quot;, col=&quot;white&quot;, lwd=0.5) } dev.off() ## inflation by raw ave r2 require(vroom) traits=c(&quot;awake&quot;,&quot;bmi&quot;,&quot;chron&quot;,&quot;ever&quot;, &quot;neur&quot;,&quot;pulse&quot;,&quot;quals&quot;, &quot;reaction&quot;,&quot;sbp&quot;,&quot;snoring&quot;,&quot;hyper&quot;) # &quot;fvc&quot;, &quot;height&quot;,&quot;imp&quot;, png(paste0(&quot;fig/inflation-by-aver2-raw.png&quot;), width =40, height = 30, units = &quot;cm&quot;, res=600) par(mfrow=c(3,4)) for(i in 1:length(traits)){ trait=traits[i] dat=vroom(paste0(&quot;inflation/summary/&quot;,trait,&quot;-inflation-by-maf-r2&quot;), col_names=T) sel=dat[,c(&quot;snp&quot;,&quot;inflation&quot;,&quot;r2_bad&quot;)] sel=sel[complete.cases(sel),] plot(sel$r2_bad, sel$inflation, xlab=&quot;ave r2&quot;, ylab=&quot;inflation&quot;, main=trait, las=1, cex = 1.5, pch=21, bg=&quot;grey&quot;, col=&quot;white&quot;, lwd=0.5) } dev.off() ### require(vroom) traits=c(&quot;awake&quot;,&quot;bmi&quot;,&quot;chron&quot;,&quot;ever&quot;, &quot;neur&quot;,&quot;pulse&quot;,&quot;quals&quot;, &quot;reaction&quot;,&quot;sbp&quot;,&quot;snoring&quot;,&quot;hyper&quot;) # &quot;fcv&quot;, &quot;height&quot;,&quot;imp&quot;, png(paste0(&quot;fig/inflation-by-aver2-goodgwas-raw.png&quot;), width =40, height = 30, units = &quot;cm&quot;, res=600) par(mfrow=c(3,4)) for(i in 1:length(traits)){ trait=traits[i] dat=vroom(paste0(&quot;inflation/summary/&quot;,trait,&quot;-inflation-by-maf-r2&quot;), col_names=T) sel=dat[,c(&quot;snp&quot;,&quot;inflation&quot;,&quot;r2_good&quot;)] sel=sel[complete.cases(sel),] plot(sel$r2_good, sel$inflation, xlab=&quot;ave r2&quot;, ylab=&quot;inflation&quot;, main=trait, las=1, cex = 1.5, pch=21, bg=&quot;grey&quot;, col=&quot;white&quot;, lwd=0.5) } dev.off() ## histogram traits=c(&quot;awake&quot;,&quot;bmi&quot;,&quot;chron&quot;,&quot;ever&quot;, &quot;neur&quot;,&quot;pulse&quot;,&quot;quals&quot;, &quot;reaction&quot;,&quot;sbp&quot;,&quot;snoring&quot;,&quot;hyper&quot;) # &quot;fcv&quot;, &quot;height&quot;,&quot;imp&quot;, png(paste0(&quot;fig/hist-aver2-goodgwas.png&quot;), width =40, height = 30, units = &quot;cm&quot;, res=600) par(mfrow=c(3,4)) for(i in 1:length(traits)){ trait=traits[i] dat=vroom(paste0(&quot;inflation/summary/&quot;,trait,&quot;-inflation-by-maf-r2&quot;), col_names=T) sel=dat[,c(&quot;snp&quot;,&quot;inflation&quot;,&quot;r2_good&quot;)] sel=sel[complete.cases(sel),] hist(sel$r2_good, breaks=100, main=trait) } dev.off() 3.6 regress bad chisq ~ mean r^2_j THIS IS NEW #:::::::::::::::::::::: # organize data #:::::::::::::::::::::: # bad gwas----------------------------------------------------------------------- mkdir gwas-mix-out for trait in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do gwas=gwas-mix/$trait-linear.summaries aver2=summary/ave-r2-by-snp-badgwas out=gwas-mix-out/$trait.out awk &#39;NR&gt;1 {print $1, $5}&#39; $gwas &gt; tmp/gwas.tmp awk &#39;NR==FNR {a[$1]; b[$1]=$2; next} {if ($1 in a) print b[$1]; else print &quot;NA&quot; }&#39; $aver2 tmp/gwas.tmp &gt; tmp/aver2.tmp # put info together paste tmp/gwas.tmp \\ tmp/aver2.tmp \\ | awk &#39;BEGIN{OFS=&quot;;&quot; ; print &quot;snp;chisq;aver2&quot;} {$1=$1}1&#39; &gt; $out done # good gwas----------------------------------------------------------------------- mkdir unrelated/gwas-good-out for trait in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do gwas=unrelated/gwas-good/$trait-linear.summaries aver2=summary/ave-r2-by-snp-goodgwas out=unrelated/gwas-good-out/$trait.out awk &#39;NR&gt;1 {print $1, $5}&#39; $gwas &gt; tmp/gwas.tmp awk &#39;NR==FNR {a[$1]; b[$1]=$2; next} {if ($1 in a) print b[$1]; else print &quot;NA&quot; }&#39; $aver2 tmp/gwas.tmp &gt; tmp/aver2.tmp # put info together paste tmp/gwas.tmp \\ tmp/aver2.tmp \\ | awk &#39;BEGIN{OFS=&quot;;&quot; ; print &quot;snp;chisq;aver2&quot;} {$1=$1}1&#39; &gt; $out done # :::::::::::::::::::::::::::::::::::::::::::::: # estimate slope: bad chisq ~ aver2_j &amp; correct the test statistics #:::::::::::::::::::::::::::::::::::::::::::::: require(vroom) traits=c(&quot;awake&quot;,&quot;bmi&quot;,&quot;chron&quot;,&quot;ever&quot;, &quot;neur&quot;,&quot;pulse&quot;,&quot;quals&quot;, &quot;fvc&quot;, &quot;height&quot;,&quot;imp&quot;, &quot;reaction&quot;,&quot;sbp&quot;,&quot;snoring&quot;,&quot;hyper&quot;) for(i in 1:length(traits)){ trait=traits[i] file=paste0(&quot;gwas-mix-out/&quot;,trait,&quot;.out&quot;) dat=vroom(file, col_names=T, delim=&quot;;&quot;) dat=dat[complete.cases(dat),] mod=lm(chisq ~ aver2,data=dat) # correct inflation cor=dat$chisq-dat$aver2*coef(mod)[2] out=cbind(dat,cor) write.table(out,paste0(&quot;gwas-mix-out/&quot;,trait,&quot;-corrected.out&quot;), col.names=T, row.names=F, quote=F) # collect slope slope0=data.frame(trait=trait, slope_aver2=coef(mod)[2], p_aver2=summary(mod)$coefficients[,4][2], stringsAsFactors = F) if(i==1){slope=slope0} else {slope=rbind(slope,slope0)} } # :::::::::::::::::::::::::::::::::::::::::::::: # corrected chisq VS good chisq vs. control chisq #:::::::::::::::::::::::::::::::::::::::::::::: require(vroom) traits=c(&quot;awake&quot;,&quot;bmi&quot;,&quot;chron&quot;,&quot;ever&quot;, &quot;neur&quot;,&quot;pulse&quot;,&quot;quals&quot;, &quot;fvc&quot;, &quot;height&quot;,&quot;imp&quot;, &quot;reaction&quot;,&quot;sbp&quot;,&quot;snoring&quot;,&quot;hyper&quot;) png(&quot;fig/good-vs-corrected-chisq.png&quot;, res=600, width=50, height=30, units=&quot;cm&quot;) par(mfrow=c(3,5), pty=&quot;s&quot;) for(i in 1:length(traits)){ trait=traits[i] good=vroom(paste0(&quot;unrelated/gwas-good-out/&quot;,trait,&quot;.out&quot;), col_names=T) good=good[complete.cases(good),] cor=vroom(paste0(&quot;gwas-mix-out/&quot;,trait,&quot;-corrected.out&quot;), col_names=T) m=match(good$snp, cor$snp) dat=data.frame(snp=good$snp, good=good$chisq, cor=cor$cor[m]) start=min(dat$good,dat$cor) end=max(dat$good,dat$cor) plot(dat$good, dat$cor, xlim=c(start,end), ylim=c(start, end), xlab=&quot;good chisq&quot;, ylab=&quot;corrected chisq&quot;, main=trait, las=1, cex = 1.5, pch=21, bg=&quot;darkgray&quot;, col=&quot;white&quot;, lwd=0.5) abline(0, 1, col=&quot;darkgray&quot;, lwd=1.5, lty=1) } dev.off() Below is the OLD cod. #:::::::: # by binned ave r2 #::::::: # bad chisq by binned ave r2 require(vroom) traits=c(&quot;awake&quot;,&quot;bmi&quot;,&quot;chron&quot;,&quot;ever&quot;, &quot;neur&quot;,&quot;pulse&quot;,&quot;quals&quot;, &quot;fvc&quot;, &quot;height&quot;,&quot;imp&quot;, &quot;reaction&quot;,&quot;sbp&quot;,&quot;snoring&quot;,&quot;hyper&quot;) png(paste0(&quot;fig/badgwas-chisq-by-aver2-bin.png&quot;), width = 50, height = 30, units = &quot;cm&quot;, res=600) par(mfrow=c(3,5)) for(i in 1:length(traits)){ trait=traits[i] dat=vroom(paste0(&quot;inflation/summary/&quot;,trait,&quot;-inflation-by-maf-r2&quot;), col_names=T) sel=dat[,c(&quot;snp&quot;,&quot;bad_chisq&quot;,&quot;r2_bad&quot;,&quot;r2_bad_bin&quot;)] sel=sel[complete.cases(sel),] out=data.frame(bad_chisq=tapply(sel$bad_chisq,INDEX=sel$r2_bad_bin, mean)) out$r2_bad_bin=1:dim(out)[1] out$r2_bad_bin_val=tapply(sel$r2_bad,INDEX=sel$r2_bad_bin, mean) plot(out$r2_bad_bin_val, out$bad_chisq, xlab=&quot;ave r2&quot;, ylab=&quot;chisq test stat&quot;, main=trait, las=1, cex = 1.5, pch=21, bg=&quot;grey&quot;, col=&quot;white&quot;, lwd=0.5) } dev.off() #:::::::: # by raw ave r2 #::::::: # bad chisq by raw ave r2 require(vroom) traits=c(&quot;awake&quot;,&quot;bmi&quot;,&quot;chron&quot;,&quot;ever&quot;, &quot;neur&quot;,&quot;pulse&quot;,&quot;quals&quot;, &quot;fvc&quot;, &quot;height&quot;,&quot;imp&quot;, &quot;reaction&quot;,&quot;sbp&quot;,&quot;snoring&quot;,&quot;hyper&quot;) png(paste0(&quot;fig/badgwas-chisq-by-aver2.png&quot;), width =50, height = 30, units = &quot;cm&quot;, res=600) par(mfrow=c(3,5)) for(i in 1:length(traits)){ trait=traits[i] dat=vroom(paste0(&quot;inflation/summary/&quot;,trait,&quot;-inflation-by-maf-r2&quot;), col_names=T) sel=dat[,c(&quot;snp&quot;,&quot;bad_chisq&quot;,&quot;r2_bad&quot;)] sel=sel[complete.cases(sel),] plot(sel$r2_bad, sel$bad_chisq, xlab=&quot;ave r2&quot;, ylab=&quot;chisq test stat&quot;, main=trait, las=1, cex = 1.5, pch=21, bg=&quot;grey&quot;, col=&quot;white&quot;, lwd=0.5) } dev.off() # good chisq by raw ave r2 require(vroom) traits=c(&quot;awake&quot;,&quot;bmi&quot;,&quot;chron&quot;,&quot;ever&quot;, &quot;neur&quot;,&quot;pulse&quot;,&quot;quals&quot;, &quot;fvc&quot;, &quot;height&quot;,&quot;imp&quot;, &quot;reaction&quot;,&quot;sbp&quot;,&quot;snoring&quot;,&quot;hyper&quot;) png(paste0(&quot;fig/goodgwas-chisq-by-aver2.png&quot;), width =50, height = 30, units = &quot;cm&quot;, res=600) par(mfrow=c(3,5)) for(i in 1:length(traits)){ trait=traits[i] dat=vroom(paste0(&quot;inflation/summary/&quot;,trait,&quot;-inflation-by-maf-r2&quot;), col_names=T) sel=dat[,c(&quot;snp&quot;,&quot;good_chisq&quot;,&quot;r2_good&quot;)] sel=sel[complete.cases(sel),] plot(sel$r2_good, sel$good_chisq, xlab=&quot;ave r2&quot;, ylab=&quot;chisq test stat&quot;, main=trait, las=1, cex = 1.5, pch=21, bg=&quot;grey&quot;, col=&quot;white&quot;, lwd=0.5) } dev.off() # regression: chisq test stats ~ ave r^2_j -------------------------------------- require(vroom) traits=c(&quot;awake&quot;,&quot;bmi&quot;,&quot;chron&quot;,&quot;ever&quot;, &quot;neur&quot;,&quot;pulse&quot;,&quot;quals&quot;, &quot;fvc&quot;, &quot;height&quot;,&quot;imp&quot;, &quot;reaction&quot;,&quot;sbp&quot;,&quot;snoring&quot;,&quot;hyper&quot;) for(i in 1:length(traits)){ trait=traits[i] dat=vroom(paste0(&quot;inflation/summary/&quot;,trait,&quot;-inflation-by-maf-r2&quot;), col_names=T) sel=dat[,c(&quot;snp&quot;,&quot;bad_chisq&quot;,&quot;good_chisq&quot;,&quot;r2_bad&quot;, &quot;r2_good&quot;, &quot;maf&quot;)] sel=sel[complete.cases(sel),] sel$maf2=sel$maf^2 mod1=lm(sel$bad_chisq~sel$r2_bad) #mod1.1=lm(sel$bad_chisq~sel$maf) #mod1.2=lm(sel$bad_chisq~ sel$maf + sel$maf2) #mod1.3=lm(sel$bad_chisq~sel$r2_bad+sel$maf) #mod1.4=lm(sel$bad_chisq~sel$r2_bad+sel$maf+sel$maf2) mod2=lm(sel$good_chisq~sel$r2_good) slope0=data.frame(trait=trait, slope_bad=coef(mod1)[2], p_bad=summary(mod1)$coefficients[,4][2], slope_good=coef(mod2)[2], p_good=summary(mod2)$coefficients[,4][2], stringsAsFactors = F) if(i==1){slope=slope0} else {slope=rbind(slope,slope0)} } slope$good_div_n=slope$slope_good/100000 slope$bad_div_n=slope$slope_bad/100000 # heritability estimates h2_gcta=read.table(&#39;summary/reml-gcta-inflation-good-gwas.txt&#39;, header=T, stringsAsFactors = F) h2_ldak=read.table(&#39;summary/reml-ldak-thin-inflation-good-gwas.txt&#39;, header=T, stringsAsFactors = F) h2=data.frame(trait=h2_gcta$code,gcta=h2_gcta$all_est, ldak=h2_ldak$all_est) # together m=match(slope$trait,h2$trait) all=cbind(slope,h2[m,-1]) "],["mathematical-details.html", "4 Mathematical Details 4.1 \\(tr(K_{right}K_{left})\\) 4.2 verification", " 4 Mathematical Details Here we detail the mathematics behind the project. 4.1 \\(tr(K_{right}K_{left})\\) 4.2 verification Here we want to verify the followings: \\(r^2_{i,j} \\overset{H_0}{\\sim} beta (\\alpha=(k-1)/2, \\beta=(n-k)/2)\\), where k= # of regressors including the intercept (so for an univariate regression, k=2), and n = sample size. \\(E[r^2_{i,j}]=\\alpha/(\\alpha + \\beta)\\) \\(var[r^2_{i,j}]=\\alpha \\beta/[(\\alpha+\\beta)^2(\\alpha+\\beta+1)]\\) \\(T = \\sum_{i,j}^{m_1,m_2} r^2_{i,j} \\overset{H_0}{\\sim} N(1/n, var[r^2_{i,j}])\\) To do so, we computed \\(r^2_{i,j}=cor(x_i, x_j)^2\\) for \\(n = 1k , m_1=m_2=1k\\) in following ways. simulated data: \\(x \\sim N(0,1)\\) real genotype data: \\(x\\) from two chromosomes. We expect to see: \\(r^2_{i,j} \\overset{H_0}{\\sim} beta (\\alpha=0.5, \\beta=499)\\) \\(T \\overset{H_0}{\\sim} N(1/1000, var[r^2_{i,j}])\\) #:: # verify distribution of r^2 #:: n=100000 k=2 alpha=(k-1)/2 beta=(n-k)/2 m=1000 for(i in 1:m){ x1=rnorm(n) x2=rnorm(n) y=cor(x1,x2)^2 if(i==1){out=y} else {out=c(out,y)} } x=seq(0.00000001,0.0015,0.000001) density=dbeta(x, alpha, beta) options(scipen=0) hist(out, breaks=100, freq=F, main=&quot;&quot;, col=&quot;lightgray&quot;, border=&quot;lightgray&quot;, xlab=&quot;r^2&quot;, las=1) lines(x, density, col=&quot;red&quot;) #mean(out) #1/n exp=alpha/(alpha+beta) var=alpha*beta/(((alpha+beta)^2)*(alpha+beta+1)) exp var exp*n var*n using real data "],["chi-square-overliner2_j.html", "5 chi square ~ \\(\\overline{r^2_j}\\) 5.1 \\(\\overline{r^2_j}\\) &amp; choice of SNPs 5.2 varying levels of confouding 5.3 results summary", " 5 chi square ~ \\(\\overline{r^2_j}\\) New measure of inflation, \\(\\overline{r^2_j}\\) - average correlation between SNP j and distant SNPs. Check if the maths in ldak function is correct. Use –make-snps to generate clean data, and check estimates of average r2j are not significant. We did 10 runs and results are non-significant. echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 20G #SBATCH -c 10 #SBATCH -t 5:00:0 for i in {1..10}; do dir=../inflation/random-snps # simulate random snps ------------------------------------------------------- ./ldak5.1 --make-snps \\$dir/20k-snps-100k-inds --num-samples 100000 --num-snps 20000 # create snp lists ----------------------------------------------------------- awk &#39;NR &lt;= 10000 {print \\$2}&#39; \\$dir/20k-snps-100k-inds.bim &gt; \\$dir/lista awk &#39;NR &gt; 10000 {print \\$2}&#39; \\$dir/20k-snps-100k-inds.bim &gt; \\$dir/listb # compute r_ij -------------------------------------------------------------- ./ldak5.2 --max-threads 10 \\ --calc-inflation \\$dir/out/20k-random-snps-100k-inds \\ --bfile \\$dir/20k-snps-100k-inds \\ --lista \\$dir/lista \\ --listb \\$dir/listb done &quot;&gt;sh_script/calc-ave-r2j # submit the job sbatch -A snpher ../sh_script/calc-ave-r2j &gt;../job-records/calc-ave-r2j-random-snps # results grep &quot;Average squared correlation&quot; sh_out/calc-ave-r2j-60721312.out &gt; inflation/random-snps/out/ave-r2j.out 5.1 \\(\\overline{r^2_j}\\) &amp; choice of SNPs 5.1.1 number of SNPs Ideally, we show \\(\\overline{r^2_j}\\) is robust - e.g., it is not sensitive to choice of SNPs (e.g., randomly pick 1000, then a different 1000). It is not sensitive to MAF threshold (e.g., if you restrict to MAF&gt;.1, MAF&gt;.01, MAF&gt;.001). To test the robustness of \\(\\overline{r^2_j}\\), we randomly chose 1k SNPs from chromosomes 1-7 and computed the \\(\\overline{r^2_j}\\) for these SNPs using 1k, 5k, 10k and 20k SNPs chosen randomly from chromosomes 8-22. We resampled the SNPs and repeated the calculation for 100 times. So we want to test if \\(\\overline{r^2_j}\\) is sensitive to * the choice of SNPs? var(r^2_j) for a given j. * the number of SNPs? 1k, 5k, 10k, 20k * the MAF threshold? MAF &gt; .1, MAF &gt; 0.01, MAF &gt; 0.001 For MAF &gt; 0.01, \\(\\overline{r^2_j}\\) is not sensitive to the choice of SNPs and slightly sensitive to the number of SNPs. Based on different set of SNPs, \\(\\overline{r^2_j}\\) align well. The alignment is better for m &gt; 10k than for m &lt; 10k. #::: # define a R function to compute ave r_j^2 for each i # To be used below #::: options(stringsAsFactors=FALSE) ip&lt;-commandArgs(trailingOnly=TRUE) options(warn=1) compute_ave_r2=function(m,nm,maf){ m=as.numeric(m) nm=as.character(nm) maf=as.character(maf) dir=paste0(&quot;../inflation/sensitivity/maf&quot;,maf) require(vroom) names=c(&quot;good&quot;, &quot;bad&quot;) for(i in 1:length(names)){ gwas=names[i] dat=vroom(paste0(dir,&quot;/out/&quot;, nm,&quot;-maf&quot;,maf,&quot;-snps-&quot;, gwas,&quot;.pairwise&quot;), col_names=F) dat=dat[,-c(m+1)]^2 out=t(data.frame(ave_r2=apply(dat,1, mean))) write.table(out,paste0(dir,&quot;/ave-r2-&quot;,nm,&quot;-&quot;,gwas), col.names=F, row.names=F, quote=F, append=T) } } compute_ave_r2(ip[1],ip[2],ip[3]) #::: # 0. compute r^2 #::: # lista: 1k from chrom1-7. This is list is fixed for all conditions dir=inflation/sensitivity maf=.01 awk &#39;{split($1, a, &quot;:&quot;); if (a[1]&lt;8) print $1 }&#39; gen/snps-unrel-inds.use | shuf | head -n 1000 &gt;$dir/lista-maf$maf #:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: # m=1k &amp; maf = .01 #:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: # to change nm=1k maf=.01 echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 2G #SBATCH -c 10 #SBATCH -t 20:00:0 #::: # 0. define vars &amp; create snp lists #::: for i in {1..100}; do # to change use=../gen/snps-unrel-inds.use m=1000 nm=1k maf=.01 lista=../inflation/sensitivity/lista-maf\\$maf dir=../inflation/sensitivity/maf\\$maf listb=\\$dir/listb-\\$nm-maf\\$maf #:: # 1. select list b [to be recycled] #:: awk &#39;{split(\\$1, a, \\&quot;:\\&quot;); if (a[1]&gt;=8) print \\$1 }&#39; \\$use | shuf | head -n \\$m &gt;\\$listb #:: # 2. good gwas #:: id=../unrelated/rand.100000 bfile=../gen/geno-unrel out=\\$nm-maf\\$maf-snps-good ./ldak5.2 --max-threads 10 \\ --calc-inflation \\$dir/out/\\$out \\ --bfile \\$bfile \\ --keep \\$id \\ --lista \\$lista \\ --listb \\$listb #:: # 3. bad gwas #:: id=../mix-pop-gwas.id bfile=../gen/geno-mix out=\\$nm-maf\\$maf-snps-bad ./ldak5.2 --max-threads 10 \\ --calc-inflation \\$dir/out/\\$out \\ --bfile \\$bfile \\ --keep \\$id \\ --lista \\$lista \\ --listb \\$listb #:: # 4. compute ave r2 [each column corresponds to a SNP in lista] #:: Rscript --vanilla ../inflation/sensitivity/calc-ave-r2.r \\$m \\$nm \\$maf done &quot;&gt;sh_script/calc-ave-r2-$nm-maf$maf # submit the job nm=1k maf=.01 sbatch -A snpher ../sh_script/calc-ave-r2-$nm-maf$maf &gt;../job-records/calc-ave-r2-$nm-maf$maf #:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: # m=5k &amp; maf = .01 #:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: # to change nm=5k maf=.01 echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 10G #SBATCH -c 10 #SBATCH -t 20:00:0 #::: # 0. define vars &amp; create snp lists #::: for i in {1..100}; do # to change use=../gen/snps-unrel-inds.use m=5000 nm=5k maf=.01 lista=../inflation/sensitivity/lista-maf\\$maf dir=../inflation/sensitivity/maf\\$maf listb=\\$dir/listb-\\$nm-maf\\$maf #:: # 1. select list b [to be recycled] #:: awk &#39;{split(\\$1, a, \\&quot;:\\&quot;); if (a[1]&gt;=8) print \\$1 }&#39; \\$use | shuf | head -n \\$m &gt;\\$listb #:: # 2. good gwas #:: id=../unrelated/rand.100000 bfile=../gen/geno-unrel out=\\$nm-maf\\$maf-snps-good ./ldak5.2 --max-threads 10 \\ --calc-inflation \\$dir/out/\\$out \\ --bfile \\$bfile \\ --keep \\$id \\ --lista \\$lista \\ --listb \\$listb #:: # 3. bad gwas #:: id=../mix-pop-gwas.id bfile=../gen/geno-mix out=\\$nm-maf\\$maf-snps-bad ./ldak5.2 --max-threads 10 \\ --calc-inflation \\$dir/out/\\$out \\ --bfile \\$bfile \\ --keep \\$id \\ --lista \\$lista \\ --listb \\$listb #:: # 4. compute ave r2 [each column corresponds to a SNP in lista] #:: Rscript --vanilla ../inflation/sensitivity/calc-ave-r2.r \\$m \\$nm \\$maf done &quot;&gt;sh_script/calc-ave-r2-$nm-maf$maf # submit the job nm=5k maf=.01 sbatch -A snpher ../sh_script/calc-ave-r2-$nm-maf$maf &gt;../job-records/calc-ave-r2-$nm-maf$maf #:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: # m=10k &amp; maf = .01 #:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: # to change nm=10k maf=.01 echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 20G #SBATCH -c 10 #SBATCH -t 20:00:0 #::: # 0. define vars &amp; create snp lists #::: for i in {1..100}; do # to change use=../gen/snps-unrel-inds.use m=10000 nm=10k maf=.01 lista=../inflation/sensitivity/lista-maf\\$maf dir=../inflation/sensitivity/maf\\$maf listb=\\$dir/listb-\\$nm-maf\\$maf #:: # 1. select list b [to be recycled] #:: awk &#39;{split(\\$1, a, \\&quot;:\\&quot;); if (a[1]&gt;=8) print \\$1 }&#39; \\$use | shuf | head -n \\$m &gt;\\$listb #:: # 2. good gwas #:: id=../unrelated/rand.100000 bfile=../gen/geno-unrel out=\\$nm-maf\\$maf-snps-good ./ldak5.2 --max-threads 10 \\ --calc-inflation \\$dir/out/\\$out \\ --bfile \\$bfile \\ --keep \\$id \\ --lista \\$lista \\ --listb \\$listb #:: # 3. bad gwas #:: id=../mix-pop-gwas.id bfile=../gen/geno-mix out=\\$nm-maf\\$maf-snps-bad ./ldak5.2 --max-threads 10 \\ --calc-inflation \\$dir/out/\\$out \\ --bfile \\$bfile \\ --keep \\$id \\ --lista \\$lista \\ --listb \\$listb #:: # 4. compute ave r2 [each column corresponds to a SNP in lista] #:: Rscript --vanilla ../inflation/sensitivity/calc-ave-r2.r \\$m \\$nm \\$maf done &quot;&gt;sh_script/calc-ave-r2-$nm-maf$maf # submit the job nm=10k maf=.01 sbatch -A snpher ../sh_script/calc-ave-r2-$nm-maf$maf &gt;../job-records/calc-ave-r2-$nm-maf$maf #:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: # m=20k &amp; maf = .01 #:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: # to change nm=20k maf=.01 echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 20G #SBATCH -c 10 #SBATCH -t 20:00:0 #::: # 0. define vars &amp; create snp lists #::: for i in {1..100}; do # to change use=../gen/snps-unrel-inds.use m=20000 nm=20k maf=.01 lista=../inflation/sensitivity/lista-maf\\$maf dir=../inflation/sensitivity/maf\\$maf listb=\\$dir/listb-\\$nm-maf\\$maf #:: # 1. select list b [to be recycled] #:: awk &#39;{split(\\$1, a, \\&quot;:\\&quot;); if (a[1]&gt;=8) print \\$1 }&#39; \\$use | shuf | head -n \\$m &gt;\\$listb #:: # 2. good gwas #:: id=../unrelated/rand.100000 bfile=../gen/geno-unrel out=\\$nm-maf\\$maf-snps-good ./ldak5.2 --max-threads 10 \\ --calc-inflation \\$dir/out/\\$out \\ --bfile \\$bfile \\ --keep \\$id \\ --lista \\$lista \\ --listb \\$listb #:: # 3. bad gwas #:: id=../mix-pop-gwas.id bfile=../gen/geno-mix out=\\$nm-maf\\$maf-snps-bad ./ldak5.2 --max-threads 10 \\ --calc-inflation \\$dir/out/\\$out \\ --bfile \\$bfile \\ --keep \\$id \\ --lista \\$lista \\ --listb \\$listb #:: # 4. compute ave r2 [each column corresponds to a SNP in lista] #:: Rscript --vanilla ../inflation/sensitivity/calc-ave-r2.r \\$m \\$nm \\$maf done &quot;&gt;sh_script/calc-ave-r2-$nm-maf$maf # submit the job nm=20k maf=.01 sbatch -A snpher ../sh_script/calc-ave-r2-$nm-maf$maf &gt;../job-records/calc-ave-r2-$nm-maf$maf #::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: # summary #::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: require(vroom) dir=&quot;inflation/sensitivity/maf.01/&quot; snps=read.table(paste0(dir,&quot;/out/1k-maf.01-snps-bad.predictorsa&quot;), stringsAsFactors = F, header=F) # note: the snp set for list a is constant across different m&#39;s # extract data m=c(&quot;1k&quot;,&quot;5k&quot;,&quot;10k&quot;, &quot;20k&quot;) for(i in 1:length(m)){ dat=vroom(paste0(dir,&quot;ave-r2-&quot;,m[i],&quot;-bad&quot;),col_names=F) ave0=apply(dat,2,mean) sd0=apply(dat,2,sd) if(i==1){ave=data.frame(snp=snps$V1,ave0, stringsAsFactors = F); names(ave)[i+1]=paste0(&quot;m_&quot;,m[i]) sd=data.frame(snp=snps$V1,sd0, stringsAsFactors = F); names(sd)[i+1]=paste0(&quot;m_&quot;,m[i]) } else {ave=cbind(ave,ave0); names(ave)[i+1]=paste0(&quot;m_&quot;,m[i]) sd=cbind(sd,sd0); names(sd)[i+1]=paste0(&quot;m_&quot;,m[i]) } } # organize data ord=order(ave$m_20k,decreasing=F) ave=ave[ord,] sd=sd[ord,] cutoff=quantile(ave$m_20k, probs = seq(0, 1, 0.01)) ave$quant_bin=cut(ave$m_20k, breaks=cutoff, include.lowest=T, labels=1:(length(cutoff)-1)) # check alignment of ave r^2_j for different m require(vroom) dir=&quot;inflation/sensitivity/maf.01/&quot; snps=read.table(paste0(dir,&quot;/out/1k-maf.01-snps-bad.predictorsa&quot;), stringsAsFactors = F, header=F) # note: the snp set for list a is constant across different m&#39;s # extract data png(&quot;fig/ave-r2-1st-vs-2nd-run-by-m.png&quot;, res=400 , width=40, height=10, units=&quot;cm&quot;) par(mfrow=c(1,4), pty=&quot;s&quot;) m=c(&quot;1k&quot;,&quot;5k&quot;,&quot;10k&quot;, &quot;20k&quot;) for(i in 1:length(m)){ dat=vroom(paste0(dir,&quot;ave-r2-&quot;,m[i],&quot;-bad&quot;),col_names=F) sel=t(dat[c(5,20),]) start=min(c(sel[,1],sel[,2])) end=max(c(sel[,1],sel[,2])) plot(sel[,1], sel[,2], xlim=c(start,end), ylim=c(start, end), xlab=&quot;1st run&quot;, ylab=&quot;2nd run&quot;, main=m[i], las=1, cex = 1, pch=21, bg=&quot;darkgray&quot;, col=&quot;white&quot;, lwd=0.5) abline(0, 1, col=&quot;darkgray&quot;, lwd=1.5, lty=1) } dev.off() 5.1.2 maf For a given list of SNPs, We computed their correlations with distant SNPs, i.e., \\(\\overline{r^2_j}\\), using SNPs with a MAF &lt; 0.1 and ones with a MAF &gt; 0.1. We did it in a systematic way. maf: &lt; .1 vs. &gt; .1. level of confounding: 0k, 1k, 2k, …, 6k. number of distant SNPs: 1k, 5k, 10k, 20k. 5.1.2.1 1st run #::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: # compute maf of mix pops #::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: # script file for n in {0k,1k,2k,3k,4k,5k,6k}; do if [ $n == 0k ]; then id=../rand.100000 else id=../mix-pop-gwas-$n-noneuro.id fi echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 10G #SBATCH -c 2 #SBATCH -t 5:0:0 ./ldak5.1 --calc-stats ../gen/maf/geno-mix-$n-noneuro-stats \\ --bfile ../gen/geno-mix-maf.001 \\ --keep $id &quot;&gt; sh_script/calc-maf-$n-noneuro.sh done # submit script for n in {0k,1k,2k,3k,4k,5k,6k}; do sbatch -A snpher ../sh_script/calc-maf-$n-noneuro.sh done&gt;../job-records/calc-maf #::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: # SNP lists #::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: # lista (1k): fixed for all analyses # chosen from chrom 1-7. maf &gt; 0.01 dir=inflation/sensitivity/maf.1 awk &#39;{split($1, a, &quot;:&quot;); if (a[1]&lt;8 &amp;&amp; $5&gt;0.1 &amp;&amp; $6&gt;=0.95) print $1}&#39; gen/geno-mix-maf.001.stats | shuf | head -n 1000 &gt; $dir/lista-1k # listb # this will vary depending on the mix pop dir=inflation/sensitivity/maf.1/listb m=(1000 5000 10000 20000) nm=(1k 5k 10k 20k) for n in {0k,1k,2k,3k,4k,5k,6k}; do for i in {0..3}; do infile=gen/maf/geno-mix-$n-noneuro-stats.stats # maf &gt; 0.1 awk &#39;{split($1, a, &quot;:&quot;); if (a[1]&gt;=8 &amp;&amp; $5&gt;=0.1 &amp;&amp; $6&gt;=0.95) print $1}&#39; $infile | shuf | head -n ${m[$i]} &gt; $dir/listb-maf-g.1-${nm[$i]}-snps-mix-pop-$n-noneuro # maf &lt; 0.1 awk &#39;{split($1, a, &quot;:&quot;); if (a[1]&gt;=8 &amp;&amp; $5&gt;0.01 &amp;&amp; $5&lt;0.1 &amp;&amp; $6&gt;=0.95) print $1}&#39; $infile | shuf | head -n ${m[$i]} &gt; $dir/listb-maf-l.1-${nm[$i]}-snps-mix-pop-$n-noneuro done done # actually it is easier to create pool of the right for maf &gt; .1 &amp; maf&lt;.1. # then we can choose a completely different listb for another run. So let&#39;s do that dir=inflation/sensitivity/maf.1/listb for n in {0k,1k,2k,3k,4k,5k,6k}; do infile=gen/maf/geno-mix-$n-noneuro-stats.stats # maf &gt; 0.1 awk &#39;{split($1, a, &quot;:&quot;); if (a[1]&gt;=8 &amp;&amp; $5&gt;=0.1 &amp;&amp; $6&gt;=0.95 &amp;&amp; NR &gt;1 ) print $1}&#39; $infile &gt; $dir/right-maf-g.1-mix-pop-$n-noneuro # maf &lt; 0.1 awk &#39;{split($1, a, &quot;:&quot;); if (a[1]&gt;=8 &amp;&amp; $5&gt;0.01 &amp;&amp; $5&lt;0.1 &amp;&amp; $6&gt;=0.95 &amp;&amp; NR &gt;1) print $1}&#39; $infile &gt; $dir/right-maf-l.1-mix-pop-$n-noneuro done #::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: # compute ave r^2_j #::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: # compute r_ij using ldak------------------------------------------------------- dir=../inflation/sensitivity/maf.1 bfile=../gen/geno-mix-maf.001 for n in {0k,1k,2k,3k,4k,5k,6k}; do for m in {1k,5k,10k,20k}; do for j in {g.1,l.1}; do # define vars lista=$dir/lista-1k listb=$dir/listb/listb-maf-$j-$m-snps-mix-pop-$n-noneuro out=$dir/out/maf-$j-$m-snps-mix-pop-$n-noneuro if [ $n == 0k ]; then id=../rand.100000 else id=../mix-pop-gwas-$n-noneuro.id fi echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 20G #SBATCH -c 3 #SBATCH -t 00:10:0 ./ldak5.2 --max-threads 3 \\ --calc-inflation $out \\ --bfile $bfile \\ --keep $id \\ --lista $lista \\ --listb $listb &quot;&gt;sh_script/calc-cor-maf-$j-$m-snps-mix-pop-$n-noneuro done done done # submit jobs for n in {0k,1k,2k,3k,4k,5k,6k}; do for m in {1k,5k,10k,20k}; do for j in {g.1,l.1}; do sbatch -A snpher ../sh_script/calc-cor-maf-$j-$m-snps-mix-pop-$n-noneuro done done done&gt;../job-records/calc-r-sensitivity # compute ave r^2_j using R----------------------------------------------------- R require(vroom) n=c(&quot;0k&quot;,&quot;1k&quot;, &quot;2k&quot;, &quot;3k&quot;, &quot;4k&quot;, &quot;5k&quot;, &quot;6k&quot;) m=c(&quot;1k&quot;,&quot;5k&quot;, &quot;10k&quot;, &quot;20k&quot;) m_num=c(1000,5000, 10000,20000) l=c(&quot;g.1&quot;,&quot;l.1&quot;) dir=&quot;inflation/sensitivity/maf.1/&quot; for(j in 1:length(m)){ for(k in 1:length(l)){ for(i in 1:length(n)){ nm=paste0(&quot;maf-&quot;,l[k],&quot;-&quot;,m[j],&quot;-snps-mix-pop-&quot;,n[i],&quot;-noneuro&quot;) dat=vroom(paste0(dir,&quot;out/&quot;,nm,&quot;.pairwise&quot;), col_names=F) lista=read.table(paste0(dir,&quot;out/&quot;,nm,&quot;.predictorsa&quot;), stringsAsFactors = F) listb=read.table(paste0(dir,&quot;out/&quot;,nm,&quot;.predictorsb&quot;), stringsAsFactors = F) dat=dat[,-c(m_num[j]+1)]^2 out=data.frame(predictor=lista$V1, ave_r2=apply(dat,1, mean)) write.table(out,paste0(dir,&quot;summary/ave-r2-&quot;,nm), col.names=F, row.names=F, quote=F) } } } 5.1.2.2 2st run #::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: # SNP lists #::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: # listb # we want to generate a completely different listb dir1=inflation/sensitivity/maf.1/listb dir2=inflation/sensitivity/maf.1/listb-run2 m=(1000 5000 10000 20000) nm=(1k 5k 10k 20k) for n in {0k,1k,2k,3k,4k,5k,6k}; do for i in {0..3}; do # right snp list based on dif. mix pop. i.e., our pools to draw snps pool1=$dir1/right-maf-g.1-mix-pop-$n-noneuro pool2=$dir1/right-maf-l.1-mix-pop-$n-noneuro # list b for run #1 old1=$dir1/listb-maf-g.1-${nm[$i]}-snps-mix-pop-$n-noneuro old2=$dir1/listb-maf-l.1-${nm[$i]}-snps-mix-pop-$n-noneuro # new list b for run #2 new1=$dir2/listb-maf-g.1-${nm[$i]}-snps-mix-pop-$n-noneuro new2=$dir2/listb-maf-l.1-${nm[$i]}-snps-mix-pop-$n-noneuro # maf &gt; 0.1 awk &#39;NR==FNR {a[$1]; next} !($1 in a) {print $1}&#39; $old1 $pool1 | shuf | head -n ${m[$i]} &gt; $new1 # maf &lt; 0.1 awk &#39;NR==FNR {a[$1]; next} !($1 in a) {print $1}&#39; $old2 $pool2 | shuf | head -n ${m[$i]} &gt; $new2 done done #::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: # compute ave r^2_j #::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: # compute r_ij using ldak------------------------------------------------------- dir=../inflation/sensitivity/maf.1 bfile=../gen/geno-mix-maf.001 for n in {0k,1k,2k,3k,4k,5k,6k}; do for m in {1k,5k,10k,20k}; do for j in {g.1,l.1}; do # define vars lista=$dir/lista-1k listb=$dir/listb-run2/listb-maf-$j-$m-snps-mix-pop-$n-noneuro out=$dir/out-run2/maf-$j-$m-snps-mix-pop-$n-noneuro if [ $n == 0k ]; then id=../rand.100000 else id=../mix-pop-gwas-$n-noneuro.id fi echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 20G #SBATCH -c 3 #SBATCH -t 00:10:0 ./ldak5.2 --max-threads 3 \\ --calc-inflation $out \\ --bfile $bfile \\ --keep $id \\ --lista $lista \\ --listb $listb &quot;&gt;sh_script/calc-cor-maf-$j-$m-snps-mix-pop-$n-noneuro done done done # submit jobs for n in {0k,1k,2k,3k,4k,5k,6k}; do for m in {1k,5k,10k,20k}; do for j in {g.1,l.1}; do sbatch -A snpher ../sh_script/calc-cor-maf-$j-$m-snps-mix-pop-$n-noneuro done done done&gt;../job-records/calc-r-sensitivity-run2 # compute ave r^2_j using R----------------------------------------------------- R require(vroom) n=c(&quot;0k&quot;,&quot;1k&quot;, &quot;2k&quot;, &quot;3k&quot;, &quot;4k&quot;, &quot;5k&quot;, &quot;6k&quot;) m=c(&quot;1k&quot;,&quot;5k&quot;, &quot;10k&quot;, &quot;20k&quot;) m_num=c(1000,5000, 10000,20000) l=c(&quot;g.1&quot;,&quot;l.1&quot;) dir=&quot;inflation/sensitivity/maf.1/&quot; for(j in 1:length(m)){ for(k in 1:length(l)){ for(i in 1:length(n)){ nm=paste0(&quot;maf-&quot;,l[k],&quot;-&quot;,m[j],&quot;-snps-mix-pop-&quot;,n[i],&quot;-noneuro&quot;) dat=vroom(paste0(dir,&quot;out-run2/&quot;,nm,&quot;.pairwise&quot;), col_names=F) lista=read.table(paste0(dir,&quot;out-run2/&quot;,nm,&quot;.predictorsa&quot;), stringsAsFactors = F) listb=read.table(paste0(dir,&quot;out-run2/&quot;,nm,&quot;.predictorsb&quot;), stringsAsFactors = F) dat=dat[,-c(m_num[j]+1)]^2 out=data.frame(predictor=lista$V1, ave_r2=apply(dat,1, mean)) write.table(out,paste0(dir,&quot;summary-run2/ave-r2-&quot;,nm), col.names=F, row.names=F, quote=F) } } } 5.1.3 summary Here we check the alignment between 1st and 2nd run under different settings. #::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: # 1st run vs. 2nd run #::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: n=c(&quot;0k&quot;,&quot;1k&quot;, &quot;2k&quot;, &quot;3k&quot;, &quot;4k&quot;, &quot;5k&quot;, &quot;6k&quot;) m=c(&quot;1k&quot;,&quot;5k&quot;, &quot;10k&quot;, &quot;20k&quot;) dir=&quot;inflation/sensitivity/maf.1/&quot; png(&quot;fig/ave-r2-1st-vs-2nd-run.png&quot;, res=600, width=40, height=70, units=&quot;cm&quot;) par(mfrow=c(7,4), pty=&quot;s&quot;) for(i in 1:length(n)){ for(j in 1:length(m)){ nm1=paste0(&quot;maf-g.1-&quot;,m[j],&quot;-snps-mix-pop-&quot;,n[i],&quot;-noneuro&quot;) # maf &gt; .1 nm2=paste0(&quot;maf-l.1-&quot;,m[j],&quot;-snps-mix-pop-&quot;,n[i],&quot;-noneuro&quot;) # maf &lt; .1 dat1.1=read.table(paste0(dir,&quot;summary/ave-r2-&quot;,nm1),stringsAsFactors = F) dat2.1=read.table(paste0(dir,&quot;summary-run2/ave-r2-&quot;,nm1),stringsAsFactors = F) dat1.2=read.table(paste0(dir,&quot;summary/ave-r2-&quot;,nm2),stringsAsFactors = F) dat2.2=read.table(paste0(dir,&quot;summary-run2/ave-r2-&quot;,nm2),stringsAsFactors = F) start=min(c(dat1.1$V2,dat1.2$V2,dat2.1$V2,dat2.2$V2)) end=max(c(dat1.1$V2,dat1.2$V2,dat2.1$V2,dat2.2$V2)) plot(dat1.1$V2, dat2.1$V2, xlim=c(start,end), ylim=c(start, end), xlab=&quot;1st run&quot;, ylab=&quot;2nd run&quot;, main=paste0(m[j],&quot; snps&quot;,&quot; &quot;,n[i],&quot; non-european&quot;), las=1, cex = 1.5, pch=21, bg=&quot;darkgray&quot;, col=&quot;white&quot;, lwd=0.5) points(dat1.2$V2, dat2.2$V2, cex = 1.5, pch=21, col=&quot;white&quot;, bg=&quot;orange&quot;, lwd=0.5) abline(0, 1, col=&quot;darkgray&quot;, lwd=1.5, lty=1) if(i==1 &amp; j==1) {legend(&quot;topleft&quot;, pch=19, legend=c(&quot;maf &gt; .1&quot;,&quot;maf &lt; .1&quot;), col=c(&quot;darkgray&quot;, &quot;orange&quot;), cex=1.5, box.lty=0)} } } dev.off() #::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: # maf &gt; .1 vs. maf &lt; .1 #::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: n=c(&quot;0k&quot;,&quot;1k&quot;, &quot;2k&quot;, &quot;3k&quot;, &quot;4k&quot;, &quot;5k&quot;, &quot;6k&quot;) m=c(&quot;1k&quot;,&quot;5k&quot;, &quot;10k&quot;, &quot;20k&quot;) dir=&quot;inflation/sensitivity/maf.1/&quot; png(&quot;fig/ave-r2-maf-g.1-vs-l.1.png&quot;, res=600, width=40, height=70, units=&quot;cm&quot;) par(mfrow=c(7,4), pty=&quot;s&quot;) for(i in 1:length(n)){ for(j in 1:length(m)){ nm1=paste0(&quot;maf-g.1-&quot;,m[j],&quot;-snps-mix-pop-&quot;,n[i],&quot;-noneuro&quot;) # maf &gt; .1 nm2=paste0(&quot;maf-l.1-&quot;,m[j],&quot;-snps-mix-pop-&quot;,n[i],&quot;-noneuro&quot;) # maf &lt; .1 dat1.1=read.table(paste0(dir,&quot;summary/ave-r2-&quot;,nm1),stringsAsFactors = F) dat1.2=read.table(paste0(dir,&quot;summary/ave-r2-&quot;,nm2),stringsAsFactors = F) dat2.1=read.table(paste0(dir,&quot;summary-run2/ave-r2-&quot;,nm1),stringsAsFactors = F) dat2.2=read.table(paste0(dir,&quot;summary-run2/ave-r2-&quot;,nm2),stringsAsFactors = F) start=min(c(dat1.1$V2,dat1.2$V2,dat2.1$V2,dat2.2$V2)) end=max(c(dat1.1$V2,dat1.2$V2,dat2.1$V2,dat2.2$V2)) plot(dat1.1$V2, dat1.2$V2, xlim=c(start,end), ylim=c(start, end), xlab=&quot;maf &gt; .1&quot;, ylab=&quot;maf &lt; .1&quot;, main=paste0(m[j],&quot; snps&quot;,&quot; &quot;,n[i],&quot; non-european&quot;), las=1, cex = 1.5, pch=21, bg=&quot;lightgray&quot;, col=&quot;white&quot;, lwd=0.5) points(dat2.1$V2, dat2.2$V2, cex = 1.5, pch=21, col=&quot;white&quot;, bg=&quot;orange&quot;, lwd=0.5) abline(0, 1, col=&quot;darkgray&quot;, lwd=1.5, lty=1) if(i==1 &amp; j==1) {legend(&quot;topleft&quot;, pch=19, legend=c(&quot;1st run&quot;,&quot;2nd run&quot;), col=c(&quot;lightgray&quot;, &quot;orange&quot;), cex=1.5, box.lty=0)} } } dev.off() Figure 5.1: robustness of ave r2_j: 1st run vs. 2nd run Figure 5.2: robustness of ave r2_j: maf &gt; .1 vs. maf &lt; .1 n=c(&quot;0k&quot;,&quot;1k&quot;, &quot;2k&quot;, &quot;3k&quot;, &quot;4k&quot;, &quot;5k&quot;, &quot;6k&quot;) m=c(&quot;1k&quot;,&quot;5k&quot;, &quot;10k&quot;, &quot;20k&quot;) dir=&quot;inflation/sensitivity/maf.1/&quot; png(&quot;fig/ave-r2-1st-vs-2nd-run.png&quot;, res=600, width=40, height=70, units=&quot;cm&quot;) par(mfrow=c(7,4), pty=&quot;s&quot;) for(i in 1:length(n)){ for(j in 1:length(m)){ nm1=paste0(&quot;maf-g.1-&quot;,m[j],&quot;-snps-mix-pop-&quot;,n[i],&quot;-noneuro&quot;) # maf &gt; .1 nm2=paste0(&quot;maf-l.1-&quot;,m[j],&quot;-snps-mix-pop-&quot;,n[i],&quot;-noneuro&quot;) # maf &lt; .1 dat1.1=read.table(paste0(dir,&quot;summary/ave-r2-&quot;,nm1),stringsAsFactors = F) dat2.1=read.table(paste0(dir,&quot;summary-run2/ave-r2-&quot;,nm1),stringsAsFactors = F) dat1.2=read.table(paste0(dir,&quot;summary/ave-r2-&quot;,nm2),stringsAsFactors = F) dat2.2=read.table(paste0(dir,&quot;summary-run2/ave-r2-&quot;,nm2),stringsAsFactors = F) test1=cor.test(dat1.1$V2, dat2.1$V2) test2=cor.test(dat1.2$V2, dat2.2$V2) out1.0=data.frame(maf=&quot;&gt;.1&quot;, n_noneuro=n[i], m=m[j], est=test1$estimate, low_95=test1$conf.int[1], up_95=test1$conf.int[2], stringsAsFactors = F) out2.0=data.frame(maf=&quot;&lt;.1&quot;, n_noneuro=n[i], m=m[j], est=test2$estimate, low_95=test2$conf.int[1], up_95=test2$conf.int[2], stringsAsFactors = F) if(i==1 &amp; j==1){ out1.1=out1.0; out2.1=out2.0 }else{ out1.1=rbind(out1.1,out1.0) out2.1=rbind(out2.1,out2.0) } } } 5.2 varying levels of confouding Show that estimated inflation correlates well with difference in \\(\\overline{r_j^2}\\) between bad and good GWAS. I guess it will be nice to have more variety. E.g., instead of good and bad, have good, a bit bad (e.g., 1000 non-europeans), a bit more bad (2000 non-europeans), … bad (7000 non-europeans). Would be great to know the slope of this regression. Can you estimate it by regressing \\(S_j\\) on \\(\\overline{r_j^2}\\) from the bad GWAS? But if we can, we just say the slope is less than n You showed that if you regress inflation on \\(\\overline{r_j^2}\\) and MAF, that MAF is not significant (nor if you use log(MAF) or exp(MAF) or (MAFX(1-MAF))). Can you also include info score - hopefully this is also not significant. If Maf and Info scores are redundant, this strengthens argument for using r2j So we ran the bad GWASs once again using different number of Europeans (n1) &amp; Non-europeans (n2) while keep N = n1+n2=100. We did so for different MAF. For these GWASs, we regress the chi square test statistics on \\(\\overline{r_j^2}\\), MAF &amp; info score. #::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: # create directories #::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: for i in 0k 1k 2k 3k 4k 5k 6k; do mkdir gwas-mix-$i-noneuro done # note: previously, the mixed population GWAS was based on 6,472 non-europeans for i in 0k 1k 2k 3k 4k 5k 6k; do for j in .1 .01 .001; do mkdir gwas-mix-$i-noneuro/maf$j done done #::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: # create id lists &amp; snp lists #::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: # id lists--------------------------------------------------------------------- # note we used id lists from previous bad GWAS # noneuropean id cat relatedness/asian-cut.05.keep relatedness/black-cut.05.keep &gt; noneuro-unrel.id # mixed pop id n1=(1000 2000 3000 4000 5000 6000) nm=(1k 2k 3k 4k 5k 6k) n2=(99000 98000 97000 96000 95000 94000) for i in {0..5}; do shuf noneuro-unrel.id | head -n ${n1[$i]} &gt; noneuro-unrel.rand.${n1[$i]} shuf rand.100000 | head -n ${n2[$i]} &gt; white-unrel.rand.${n2[$i]} cat white-unrel.rand.${n2[$i]} noneuro-unrel.rand.${n1[$i]} &gt; mix-pop-gwas-${nm[$i]}-noneuro.id done # snp list---------------------------------------------------------------------- # note: for the initial bad gwas, we used the snp list for good gwas # i.e., ../gen/snps-unrel-inds.use # gen/geno-unrel.stats is based on QCed genotype data of rand.100000 before maf... # ... call-rate screening # here we want to get snp list of different maf thresholds for maf in .1 .01 .001; do awk &lt; gen/geno-unrel.stats -v maf=$maf &#39;($5&gt;maf &amp;&amp; $6&gt;=0.95 &amp;&amp; NR&gt;1){print $1}&#39; &gt; gen/snps-unrel-maf$maf.use wc -l gen/snps-unrel-maf$maf.use done # maf &gt; 0.1 : 856,746 snps-unrel-maf.1.use # maf &gt; 0.01 : 1,103,209 snps-unrel-maf.01.use # maf &gt; 0.001 : 1,111,494 snps-unrel-maf.001.use #::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: # extract genotype data for mixed pop #::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: # note: previously geno-mix is based on snps-unrel-inds.use, which is a snp list... #... after filtering for maf (maf&gt;0.01) and call rate. So genotype data does not... #... contain snps with maf &lt; 0.01. So we need to extract genotype data for this... #... set of analysis using overlap-mixed-complete-cov.id and snps-unrel-maf.001.use... #...(see above for how the snp list is generated) # bfiles by chr----------------------------------------------------------------- for j in {1..22}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 20G #SBATCH -c 3 #SBATCH -t 1:0:0 ./plink2 --pfile ../gen/geno_plink/bhr$j \\ --keep ../overlap-mixed-complete-cov.id \\ --extract ../gen/snps-unrel-maf.001.use \\ --make-bed \\ --memory 20000 \\ --out ../gen/tmp/bhr$j-mix \\ --threads 3 \\ &quot;&gt; sh_script/chr$j-mix.sh done # submit script for i in {1..22}; do sbatch -A snpher ../sh_script/chr$i-mix.sh done&gt;../job-records/mkbfile-mix-pop-new # merge bfiles------------------------------------------------------------------ rm bfile-mix-new.list for j in {1..22}; do echo &quot;../gen/tmp/bhr$j-mix&quot; &gt;&gt;bfile-mix-new.list done echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 20G #SBATCH -c 3 #SBATCH -t 10:0:0 ./ldak5.1 --make-bed ../gen/geno-mix-maf.001 \\ --mbfile ../gen/bfile-mix-new.list \\ --max-threads 3 \\ --exclude-dups YES &quot;&gt; sh_script/merge-mbfiles-mix.sh # submit the script sbatch -A snpher ../sh_script/merge-mbfiles-mix.sh &gt;../job-records/merge-mbfiles-mix-pop-maf.001 #::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: # get INFO score #::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: # here we repeat the QC step for the good gwas to compute the INFO score # note: since the MAF is based on snp list after QC for rand.100000, here we compute... #...INFO based on the same list of participants. # make QCed pgen files---------------------------------------------------------- for j in {1..22}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 20G #SBATCH -c 3 #SBATCH -t 1:0:0 ./plink2 --pfile ../gen/geno_plink/bhr$j \\ --keep ../unrelated/rand.100000 \\ --extract ../doug/ukbb.ldsc \\ --hwe 0.0001 \\ --hard-call-threshold .05 \\ --mach-r2-filter 0.8 2 \\ --make-pgen \\ --memory 20000 \\ --out ../gen/tmp/bhr$j-unrel \\ --threads 3 &quot;&gt; sh_script/chr$j.sh done # submit jobs for j in {1..22}; do sbatch -A snpher ../sh_script/chr$j.sh done &gt; ../job-records/qc-unrel-pgen # compute info score------------------------------------------------------------ for j in {1..22}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 20G #SBATCH -c 3 #SBATCH -t 1:0:0 ./plink2 --pfile ../gen/tmp/bhr$j-unrel \\ --keep ../unrelated/rand.100000 \\ --threads 3 \\ --memory 20000 \\ --freq cols=chrom,ref,alt,altfreq,machr2 \\ --out ../gen/info/chr$j &quot;&gt; sh_script/info-chr$j.sh done # submit file for j in {1..22}; do sbatch -A snpher ../sh_script/info-chr$j.sh done &gt; ../job-records/compute-info-score # combine files dir=gen/info rm $dir/rand.100000-qced-afreq for i in {1..22}; do if [ $i == 1 ]; then awk &#39;{print $0}&#39; $dir/chr$i.afreq &gt; $dir/rand.100000-qced.afreq else awk &#39;NR&gt;1 {print $0}&#39; $dir/chr$i.afreq &gt;&gt; $dir/rand.100000-qced.afreq fi done #::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: # GWASs #::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: ## NOTE: for maf &gt;0.001, we will have to redo the GWAS, because geno-mix only ... #...contains snps with maf &gt; 0.01. See below # for 0k, i.e., the good gwas without PC as covariates-------------------------------------- n=0k for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do for maf in {.1,.01,.001}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 7G #SBATCH -c 2 #SBATCH -t 2:00:0 ./ldak5.1 --linear ../gwas-mix-$n-noneuro/maf$maf/$i-linear \\ --pheno ../phen/continuous-traits/$i.raw.pheno \\ --bfile ../gen/geno-mix \\ --covar ../phen/basic-covariates.use \\ --keep ../rand.100000 \\ --extract ../gen/snps-unrel-maf$maf.use \\ --max-threads 2 &quot;&gt; sh_script/$i-linear-$n-noneuro-maf-$maf.sh done done # submit files------------------------------------------------------------------ n=0k for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do for maf in {.1,.01,.001}; do sbatch -A snpher ../sh_script/$i-linear-$n-noneuro-maf-$maf.sh done done&gt;../job-records/bad-gwas-0k-noneuro # for 1k to 6k------------------------------------------------------------------ for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do for n in {1k,2k,3k,4k,5k,6k}; do for maf in {.1,.01,.001}; do #for j in {1..22}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 7G #SBATCH -c 2 #SBATCH -t 8:00:0 ./ldak5.1 --linear ../gwas-mix-$n-noneuro/maf$maf/$i-linear \\ --pheno ../phen/continuous-traits/$i.raw.pheno \\ --bfile ../gen/geno-mix \\ --covar ../phen/basic-covariates.use \\ --keep ../mix-pop-gwas-$n-noneuro.id \\ --extract ../gen/snps-unrel-maf$maf.use \\ --max-threads 2 &quot;&gt; sh_script/$i-linear-$n-noneuro-maf-$maf.sh done done done # submit files------------------------------------------------------------------ for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do for n in {1k,2k,3k,4k,5k,6k}; do for maf in {.1,.01,.001}; do #for j in {1..22}; do sbatch -A snpher ../sh_script/$i-linear-$n-noneuro-maf-$maf.sh done done done&gt;../job-records/bad-gwas # check job completion file=job-records/bad-gwas jobs=`awk &#39;{print $4}&#39; $file` mkdir $file-tmp for i in $jobs; do jobinfo $i | awk -F &quot;:&quot; -v i=$i &#39;$1~/Name/ {print i, $2}&#39; &gt;&gt; $file-tmp/name.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/State/ {print$2}&#39; &gt;&gt; $file-tmp/state.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Cores/ {print$2}&#39; &gt;&gt; $file-tmp/cores.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Used walltime/ {print $2 &quot;:&quot; $3 &quot;:&quot; $4}&#39; &gt;&gt; $file-tmp/time.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Max Mem/ {split($2,a,/[(]/ ); print a[1]}&#39; &gt;&gt; $file-tmp/mem.tmp done paste $file-tmp/name.tmp \\ $file-tmp/state.tmp \\ $file-tmp/cores.tmp \\ $file-tmp/time.tmp \\ $file-tmp/mem.tmp \\ | awk &#39;BEGIN{print &quot;ID name state cores time mem&quot;}{print $0}&#39; &gt; $file.out rm -r $file-tmp # combine results for some--------------------------------------------------- # only for .summaries &amp; .pvalues for i in {awake,bmi,chron,ever,fvc,height,imp,neur,quals,pulse,reaction,sbp,snoring,hyper}; do for j in {1..22}; do if [ $j == 1 ]; then awk &#39;{print $0}&#39; $i-linear-chr-$j.summaries &gt; $i-linear.summaries awk &#39;{print $0}&#39; $i-linear-chr-$j.pvalues &gt; $i-linear.pvalues else awk &#39;NR&gt;1 {print $0}&#39; $i-linear-chr-$j.summaries &gt;&gt; $i-linear.summaries awk &#39;NR&gt;1 {print $0}&#39; $i-linear-chr-$j.pvalues &gt;&gt; $i-linear.pvalues fi done done # repeat gwas for maf&gt;.001 ----------------------------------------------------- maf=.001 bfile=../gen/geno-mix-maf.001 n=(0k 1k 2k 3k 4k 5k 6k) for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do for j in {0..6}; do out=../gwas-mix-${n[$j]}-noneuro/maf$maf/$i-linear if [ $j == 1 ]; then id=../rand.100000 else id=../mix-pop-gwas-${n[$j]}-noneuro.id fi echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 7G #SBATCH -c 2 #SBATCH -t 01:30:0 ./ldak5.1 --linear $out \\ --pheno ../phen/continuous-traits/$i.raw.pheno \\ --bfile $bfile \\ --covar ../phen/basic-covariates.use \\ --keep $id \\ --extract ../gen/snps-unrel-maf$maf.use \\ --max-threads 2 &quot;&gt; sh_script/$i-linear-${n[$j]}-noneuro-maf-$maf.sh done done # submit files------------------------------------------------------------------ maf=.001 for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do for n in {0k,1k,2k,3k,4k,5k,6k}; do sbatch -A snpher ../sh_script/$i-linear-$n-noneuro-maf-$maf.sh done done&gt;../job-records/bad-gwas #::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: # compute ave r^2_j #::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: # create snp lists-------------------------------------------------------------- # note: we do this for three snp lists # maf &gt; 0.1 : 856,746 gen/snps-unrel-maf.1.use # maf &gt; 0.01 : 1,103,209 gen/snps-unrel-maf.01.use # maf &gt; 0.001 : 1,111,494 gen/snps-unrel-maf.001.use m=10000 nm=10k for i in {.1,.01,.001}; do # define vars infile=gen/snps-unrel-maf$i.use left=inflation/left-snps-unrel-maf$i-$nm right=inflation/right-snps-unrel-maf$i-$nm awk &#39;{split($1, a, &quot;:&quot;); if (a[1]&lt;8) print $1 }&#39; $infile | shuf | head -n $m &gt;$left awk &#39;{split($1, a, &quot;:&quot;); if (a[1]&gt;=8) print $1 }&#39; $infile | shuf | head -n $m &gt;$right done # compute r_ij using ldak ------------------------------------------------------- n=(0k 1k 2k 3k 4k 5k 6k) indir=../inflation outdir=../inflation/out bfile=../gen/geno-mix-maf.001 for j in {0..6}; do for i in {.1,.01,.001}; do # define vars lista=$indir/right-snps-unrel-maf$i-10k listb=$indir/left-snps-unrel-maf$i-10k out=$outdir/10k-snps-mix-pop-gwas-${n[$j]}-noneuro-maf$i if [ $j == 0 ]; then id=../rand.100000 else id=../mix-pop-gwas-${n[$j]}-noneuro.id fi echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 20G #SBATCH -c 10 #SBATCH -t 2:00:0 ./ldak5.2 --max-threads 10 \\ --calc-inflation $out \\ --bfile $bfile \\ --keep $id \\ --lista $lista \\ --listb $listb &quot;&gt;sh_script/calc-r-10k-snps-mix-pop-gwas-${n[$j]}-noneuro-maf$i done done # submit the job n=(0k 1k 2k 3k 4k 5k 6k) for j in {0..6}; do for i in {.1,.01,.001}; do sbatch -A snpher ../sh_script/calc-r-10k-snps-mix-pop-gwas-${n[$j]}-noneuro-maf$i done done&gt;../job-records/calc-r # compute ave r_j^2 for each i------------------------------------------------- R require(vroom) n=c(&quot;0k&quot;,&quot;1k&quot;, &quot;2k&quot;, &quot;3k&quot;, &quot;4k&quot;, &quot;5k&quot;, &quot;6k&quot;) maf=c(&quot;.1&quot;,&quot;.01&quot;,&quot;.001&quot;) for(j in 1:length(maf)){ for(i in 1:length(n)){ nm=paste0(&quot;10k-snps-mix-pop-gwas-&quot;,n[i],&quot;-noneuro-maf&quot;,maf[j]) dat=vroom(paste0(&quot;inflation/out/&quot;,nm,&quot;.pairwise&quot;), col_names=F) lista=read.table(paste0(&quot;inflation/out/&quot;,nm,&quot;.predictorsa&quot;), stringsAsFactors = F) listb=read.table(paste0(&quot;inflation/out/&quot;,nm,&quot;.predictorsb&quot;), stringsAsFactors = F) dat=dat[,-c(10001)]^2 outb=data.frame(predictor=listb$V1, ave_r2=apply(dat,2, mean)) outa=data.frame(predictor=lista$V1, ave_r2=apply(dat,1, mean)) out=rbind(outa,outb) write.table(out,paste0(&quot;summary/ave-r2-&quot;,nm), col.names=F, row.names=F, quote=F) } } #::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: # extract LD score #:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: # convert snp list to rs system ------------------------------------------------ infile=gen/snps-unrel-maf.001.use outfile=gen/snps-unrel-maf.001.use-rs awk &#39;(NR==FNR){a[$1]; b[$1]=$2; next} ($1 in a){print b[$1], $2}&#39; doug/ukbb.ldsc $infile &gt; $outfile # extract ld scores ----------------------------------------------------------- dir=ldsc/eur_w_ld_chr for chrom in {1..22}; do zcat $dir/$chrom.l2.ldscore.gz | awk &#39;NR&gt;1 {print $2, $6}&#39; &gt; ldscore awk &#39;(NR==FNR){a[$1];next}($1 in a){print $0}&#39; gen/snps-unrel-maf.001.use-rs ldscore &gt; temp if [ $chrom -eq 1 ] then mv temp snps-unrel-maf.001.ldscore else cat snps-unrel-maf.001.ldscore temp &gt; temp2 mv temp2 snps-unrel-maf.001.ldscore fi echo $chrom done #::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: # put info together #::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: # INFO: gen/info rand.100000-qced.afreq # maf: gen/geno-mix-maf.001.stats # chi square : trait-linear.summaries # ave r^2_j: e.g, summary/ave-r2-10k-snps-mix-pop-gwas-$i-noneuro-maf$j # ld score from ldsc ref panel: snps-unrel-maf.001.ldscore; in rs # required files maf=gen/geno-mix-maf.001.stats # use as the snp list to integrate all info info=gen/info/rand.100000-qced.afreq rs=doug/ukbb.ldsc ldsc=snps-unrel-maf.001.ldscore # temporary files awk &#39;NR &gt; 1 {print $1, $5 }&#39; $maf &gt; tmp/maf.tmp awk &#39;NR==FNR {a[$2]; b[$2]=$6; next} {if ($1 in a) print b[$1] ; else print &quot;NA&quot;}&#39; $info tmp/maf.tmp &gt; tmp/info.tmp awk &#39;NR==FNR {a[$2]; b[$2]=$1; next} ($1 in a) {print b[$1], $0}&#39; $rs $ldsc &gt; tmp/ldsc.tmp1 # here we make sure the order of the rows are the same as maf.tmp awk &#39;NR==FNR {a[$1]; b[$1]=$2; c[$1]=$3 ; next} {if ($1 in a) print b[$1], c[$1]; else print &quot;NA&quot;}&#39; tmp/ldsc.tmp1 tmp/maf.tmp &gt; tmp/ldsc.tmp for trait in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do for n in {0k,1k,2k,3k,4k,5k,6k}; do for j in {.1,.01,.001}; do # define files gwas=gwas-mix-$n-noneuro/maf$j/$trait-linear.summaries aver2=summary/ave-r2-10k-snps-mix-pop-gwas-$n-noneuro-maf$j out=gwas-mix-all-out/$trait-mix-pop-gwas-$n-noneuro-maf$j.out # create temporary files awk &#39;NR==FNR {a[$1]; b[$1]=$2; next} {if ($1 in a) print b[$1]; else print &quot;NA&quot; }&#39; $aver2 tmp/maf.tmp &gt; tmp/aver2.tmp awk &#39;NR==FNR {a[$1]; b[$1]=$5; next} {if ($1 in a) print b[$1]; else print &quot;NA&quot; }&#39; $gwas tmp/maf.tmp &gt; tmp/gwas.tmp # put info together paste tmp/maf.tmp \\ tmp/info.tmp \\ tmp/gwas.tmp \\ tmp/aver2.tmp \\ tmp/ldsc.tmp \\ | awk &#39;BEGIN{OFS=&quot;;&quot;;print &quot;snp;maf;info;chisq;aver2;rs;ldsc&quot;} {$1=$1}1&#39; &gt; $out done done done 5.3 results summary #:::::::::::::::::::::::::::::::::::::::::::::: # plot chisq ~ aver2_j #:::::::::::::::::::::::::::::::::::::::::::::: # function to plot a single trait--------------------------------------------------- make_plot=function(trait, maf, n_noneuro){ # define variables n_noneuro=n_noneuro trait=trait maf=maf # define color library(RColorBrewer) qual_col_pals = brewer.pal.info[brewer.pal.info$category == &#39;qual&#39;,] col_vector = unlist(mapply(brewer.pal, qual_col_pals$maxcolors, rownames(qual_col_pals))) set.seed(14) mycol=sample(col_vector,7) # plot for(i in length(n_noneuro):1){ n=n_noneuro[i] file=paste0(&quot;gwas-mix-all-out/&quot;,trait,&quot;-mix-pop-gwas-&quot;,n, &quot;-noneuro-maf&quot;,maf,&quot;.out&quot;) dat=vroom(file, col_names=T, delim=&quot;;&quot;) # bin a variable by quantile cutoff=quantile(dat$aver2, probs = seq(0, 1, 0.005), na.rm=T) dat$bin=cut(dat$aver2, breaks=cutoff, labels=1:(length(cutoff)-1)) # average chisq by bin values out=data.frame(chisq_ave=tapply(dat$chisq,INDEX=dat$bin, mean)) out$bin_val=tapply(dat$aver2,INDEX=dat$bin, mean) if(i==length(n_noneuro)){ plot(out$bin_val, out$chisq_ave, xlab=&quot;ave r2&quot;, ylab=&quot;ave chisq&quot;, main=trait, las=1, cex = 1.5, pch=21, bg=mycol[i], col=&quot;white&quot;, lwd=0.5) } else { points(out$bin_val, out$chisq_ave, cex = 1.5, pch=21, col=&quot;white&quot;, bg=mycol[i], lwd=0.5) } # end of conditional statement } # end of loop over n # add a legend if(trait==&quot;awake&quot;){ legend(&quot;topleft&quot;, pch=19, legend=n_noneuro, col=mycol, cex=1.5, box.lty=0)} } # end of function # make a plot ------------------------------------------------------------------ # maf = .01---------------------------- require(vroom) n_noneuro=c(&quot;0k&quot;,&quot;1k&quot;, &quot;2k&quot;, &quot;3k&quot;, &quot;4k&quot;, &quot;5k&quot;, &quot;6k&quot;) maf_threshold=c(&quot;.1&quot;,&quot;.01&quot;,&quot;.001&quot;) traits=c(&quot;awake&quot;,&quot;bmi&quot;,&quot;chron&quot;,&quot;ever&quot;, &quot;neur&quot;,&quot;pulse&quot;,&quot;quals&quot;, &quot;fvc&quot;, &quot;height&quot;,&quot;imp&quot;, &quot;reaction&quot;,&quot;sbp&quot;,&quot;snoring&quot;,&quot;hyper&quot;) maf=maf_threshold[2] png(paste0(&quot;fig/mix-pop-gwas-chisq-by-aver2-bin.png&quot;), width = 50, height = 30, units = &quot;cm&quot;, res=600) par(mfrow=c(3,5)) for(i in 1:length(traits)){ trait=traits[i] make_plot(trait, maf, n_noneuro) } dev.off() # maf = .001---------------------------- require(vroom) n_noneuro=c(&quot;0k&quot;,&quot;1k&quot;, &quot;2k&quot;, &quot;3k&quot;, &quot;4k&quot;, &quot;5k&quot;, &quot;6k&quot;) maf_threshold=c(&quot;.1&quot;,&quot;.01&quot;,&quot;.001&quot;) traits=c(&quot;awake&quot;,&quot;bmi&quot;,&quot;chron&quot;,&quot;ever&quot;, &quot;neur&quot;,&quot;pulse&quot;,&quot;quals&quot;, &quot;fvc&quot;, &quot;height&quot;,&quot;imp&quot;, &quot;reaction&quot;,&quot;sbp&quot;,&quot;snoring&quot;,&quot;hyper&quot;) maf=maf_threshold[3] png(paste0(&quot;fig/mix-pop-gwas-chisq-by-aver2-bin-maf.001.png&quot;), width = 50, height = 30, units = &quot;cm&quot;, res=600) par(mfrow=c(3,5)) for(i in 1:length(traits)){ trait=traits[i] make_plot(trait, maf, n_noneuro) } dev.off() #:::::::::::::::::::::::::::::::::::::::::::::: # estimate slope: chisq ~ aver2_j #:::::::::::::::::::::::::::::::::::::::::::::: require(vroom) n_noneuro=c(&quot;0k&quot;,&quot;1k&quot;, &quot;2k&quot;, &quot;3k&quot;, &quot;4k&quot;, &quot;5k&quot;, &quot;6k&quot;) maf_threshold=c(&quot;.1&quot;,&quot;.01&quot;,&quot;.001&quot;) traits=c(&quot;awake&quot;,&quot;bmi&quot;,&quot;chron&quot;,&quot;ever&quot;, &quot;neur&quot;,&quot;pulse&quot;,&quot;quals&quot;, &quot;fvc&quot;, &quot;height&quot;,&quot;imp&quot;, &quot;reaction&quot;,&quot;sbp&quot;,&quot;snoring&quot;,&quot;hyper&quot;) for(i in 1:length(maf_threshold)){ for(j in 1:length(n_noneuro)){ for(k in 1:length(traits)){ maf=maf_threshold[i] n=n_noneuro[j] trait=traits[k] file=paste0(&quot;gwas-mix-all-out/&quot;,trait,&quot;-mix-pop-gwas-&quot;,n, &quot;-noneuro-maf&quot;,maf,&quot;.out&quot;) dat=vroom(file, col_names=T, delim=&quot;;&quot;) mod1=lm(chisq ~ aver2,data=dat) mod2=lm(chisq ~ ldsc,data=dat) slope0=data.frame(trait=trait, maf_threshold=maf, n_noneuro=n, slope_aver2=coef(mod1)[2], p_aver2=summary(mod1)$coefficients[,4][2], slope_ldsc=coef(mod2)[2], p_ldsc=summary(mod2)$coefficients[,4][2], stringsAsFactors = F) if(i==1 &amp; j==1 &amp; k==1){slope=slope0} else {slope=rbind(slope,slope0)} } } } out=slope[order(slope$trait, slope$maf_threshold, slope$n_noneuro),] write.table(out,&quot;summary/mix-pop-gwas-slope.txt&quot;, col.names=T, row.names=F, quote=F) #:::::::::::::::::::::::::::::::::::::::::::::: # plot chisq ~ aver2_j by maf | n_noneuro #:::::::::::::::::::::::::::::::::::::::::::::: # function to plot a single trait--------------------------------------------------- make_plot=function(trait, maf_threshold, n){ # define variables n=n trait=trait maf_threshold=maf_threshold # define color library(RColorBrewer) qual_col_pals = brewer.pal.info[brewer.pal.info$category == &#39;qual&#39;,] col_vector = unlist(mapply(brewer.pal, qual_col_pals$maxcolors, rownames(qual_col_pals))) set.seed(14) mycol=sample(col_vector,length(maf_threshold)) # plot for(i in 1:length(maf_threshold)){ maf=maf_threshold[i] file=paste0(&quot;gwas-mix-all-out/&quot;,trait,&quot;-mix-pop-gwas-&quot;,n, &quot;-noneuro-maf&quot;,maf,&quot;.out&quot;) dat=vroom(file, col_names=T, delim=&quot;;&quot;) # bin a variable by quantile cutoff=quantile(dat$aver2, probs = seq(0, 1, 0.005), na.rm=T) dat$bin=cut(dat$aver2, breaks=cutoff, labels=1:(length(cutoff)-1)) # average chisq by bin values out=data.frame(chisq_ave=tapply(dat$chisq,INDEX=dat$bin, mean)) out$bin_val=tapply(dat$aver2,INDEX=dat$bin, mean) if(i==1){ plot(out$bin_val, out$chisq_ave, xlab=&quot;ave r2&quot;, ylab=&quot;ave chisq&quot;, main=paste0(trait,&quot; &quot;, n,&quot; non-european&quot;), las=1, cex = 1.5, pch=21, bg=mycol[i], col=&quot;white&quot;, lwd=0.5) } else { points(out$bin_val, out$chisq_ave, cex = 1.5, pch=21, col=&quot;white&quot;, bg=mycol[i], lwd=0.5) } # end of conditional statement } # end of loop over maf # add a legend if(trait==&quot;awake&quot;){ legend(&quot;topleft&quot;, pch=19, legend=maf_threshold, col=mycol, cex=1.5, box.lty=0)} } # end of function # make a plot ------------------------------------------------------------------ require(vroom) n_noneuro=c(&quot;0k&quot;,&quot;1k&quot;, &quot;2k&quot;, &quot;3k&quot;, &quot;4k&quot;, &quot;5k&quot;, &quot;6k&quot;) maf_threshold=c(&quot;.1&quot;,&quot;.01&quot;,&quot;.001&quot;) traits=c(&quot;awake&quot;,&quot;bmi&quot;,&quot;chron&quot;,&quot;ever&quot;, &quot;neur&quot;,&quot;pulse&quot;,&quot;quals&quot;, &quot;fvc&quot;, &quot;height&quot;,&quot;imp&quot;, &quot;reaction&quot;,&quot;sbp&quot;,&quot;snoring&quot;,&quot;hyper&quot;) for(j in 1:length(n_noneuro)){ n=n_noneuro[j] # plot give an n for non-european png(paste0(&quot;fig/mix-pop-gwas-chisq-by-aver2-bin-&quot;,n,&quot;-noneuro.png&quot;), width = 50, height = 30, units = &quot;cm&quot;, res=600) par(mfrow=c(3,5)) for(i in 1:length(traits)){ trait=traits[i] make_plot(trait, maf_threshold, n) } dev.off() } We can now report average inflation of test statistics (mean(r2j) x n x h2, which is upper bounded by mean(r2j) x n), AND we can report estimated per-SNP inflation of test statistics (r2j x n x j2) Eg., we can say that if you use UKBB recommended samples, with MAF&gt;.01, the average inflation will be less than 0.5 units, while the maximum inflation will be less than 1 unit. However, maybe we find that if you analyse rare SNPs (e.g. 0.0001 &lt; MAF &lt; .01), the maximum inflation is much higher (so people must be careful). What happens if you have a meta-analysis - how does inflation accumulate over cohorts? Possible way to write up this paper: Perform a good and bad GWAS of height Figure 1a - show that GIF performs poorly (because test statistics of good GWAS do not follow a chisq(1) distribution) Figure 1b - use test statistics of good GWAS to show that LDSC performs badly, because it assumes causal variation is constant [Do you mean the choice of heritability model affects inflation estimates? But we found for good GWASs, ldsc under gcta is OK for most traits.] Figure 1c - use difference between test statistics to show that LDSC performs badly because it assumes inflation is constant. (in supplement, can show same results for other traits). Figure 2 - show that r2j is independent of true signal (test statistics from good gwas), but predicts well inflation (difference) "],["good.html", "6 Good GWAS 6.1 QC of hp3 SNPs 6.2 extract covariates 6.3 GWAS 6.4 chisq ~ aver2_j 6.5 ldsc interce 6.6 ldsc intercept 6.7 REML 6.8 HE", " 6 Good GWAS Here we do good GWASs. We will use 1.2M hapmap3 SNPs. But sill need to do some QC to these SNPs. 6.1 QC of hp3 SNPs # select 100k unrelated individuals with no missing covariates &amp; 14 phenotypes-- # individual with complete covariates R options(scipen = 100) library(vroom) dat=vroom(&quot;phen/covariates.use&quot;, col_names=F) out=dat[complete.cases(dat),c(1,2)] write.table(out,&quot;covariates-complete-cases.id&quot;, col.names=F, row.names=F, quote=F) # overlaping individuals across 14 traits cp icd10/unrelated.inds overlap.ind # unrelated white British dir=phen/continuous-traits/ for tt in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do mv overlap.ind temp awk &#39;(NR==FNR){a[$1];next}($1 in a){print $1, $2}&#39; temp $dir/$tt.raw.pheno &gt; overlap.ind wc -l overlap.ind echo $tt done rm temp # overlapping &amp; complete covariates awk &#39;NR==FNR{a[$1]; next} ($1 in a) {print $1, $1}&#39; overlap.ind covariates-complete-cases.id &gt; overlap-complete-cases.id #randomly pick 100k of these shuf overlap-complete-cases.id | head -n 100000 &gt; rand.100000 # QC SNPs----------------------------------------------------------------------- # stating number of SNPs= 1,184,423 for j in {1..22}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 20G #SBATCH -c 3 #SBATCH -t 1:0:0 ./plink2 --pfile ../gen/geno_plink/bhr$j \\ --keep ../unrelated/rand.100000 \\ --extract ../doug/ukbb.ldsc \\ --hwe 0.0001 \\ --hard-call-threshold .05 \\ --mach-r2-filter 0.8 2 \\ --make-bed \\ --memory 20000 \\ --out ../gen/tmp/bhr$j-unrel \\ --threads 3 &quot;&gt; sh_script/chr$j.sh done # submit jobs for j in {1..22}; do sbatch -A snpher ../sh_script/chr$j.sh done &gt; ../job-records/qc-unrel # merge files rm bfile-unrel.list for j in {1..22}; do echo &quot;../gen/tmp/bhr$j-unrel&quot; &gt;&gt;bfile-unrel.list done echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 20G #SBATCH -c 3 #SBATCH -t 40:0:0 ./ldak5.1 --make-bed ../gen/geno-unrel \\ --mbfile ../gen/bfile-unrel.list \\ --max-threads 3 \\ --exclude-dups YES &quot;&gt; sh_script/mbfile-unrel.sh # submit the script sbatch -A snpher ../sh_script/mbfile-unrel.sh &gt;../job-records/mbfiles-unrel # MAF &amp; call-rate awk &lt; geno-unrel.stats &#39;($5&gt;.01 &amp;&amp; $6&gt;=0.95 &amp;&amp; NR&gt;1){print $1}&#39; &gt; snps-unrel-inds.use # m = 1,103,209 SNPs 6.2 extract covariates head=read.table(&quot;phen/ukb45861.header&quot;, sep=&quot;,&quot;, header=F, stringsAsFactors = F) # function to get the variables get=function(nm){ colnum=grep(nm,head,fixed=TRUE) out=data.frame(t(rbind(colnum, head[,colnum]))) names(out)=c(&quot;column&quot;, &quot;field&quot;) return (out) } # get the variables out=rbind(get(&#39;21022-0&#39;), # age at recruitment: 21022 get(&#39;54-0&#39;), # assessment centre: 54 get(&#39;22000-0&#39;), # genotyping batch: 22000 get(&#39;22001-0&#39;), # genetic sex: 22001 get(&#39;189-0&#39;), # townsend get(&#39;22009-0&#39;), # genotype PC: 22009 get(&#39;21000-0&#39;)) # ethnic background row.names(out)=1:dim(out)[1] # remove unwanted out=out[-c(95:100),] write.table(out,&quot;phen/covariates.colnum&quot;, col.names=F, row.names=F, sep=&quot;\\t&quot;, quote=F) # extract dat from the full data set awk -F &#39;&quot;,&quot;&#39; &#39;(NR==FNR){a[$1];next}{printf &quot;%s\\&quot;&quot;, $1;for(i in a){printf &quot; \\&quot;%s\\&quot;&quot;, $i};printf &quot;\\n&quot;}&#39; phen/covariates.colnum phen/ukb45861.csv &gt; phen/covariates.dat #-------- # organize covariates #-------- options(scipen = 100) # all covariates var=read.table(&quot;phen/covariates.dat&quot;, header=T, stringsAsFactors = F) nm=names(var) # extract covariates var1=data.frame(eid=var$eid, age=var[,grep(&#39;21022&#39;, nm, fixed=T)], # age at recruitment sex_gen=var[,grep(&#39;22001&#39;, nm, fixed=T)], # genetic sex: 0 =F; 1 = M centre=var[,grep(&#39;X54&#39;, nm, fixed=T)], # assessment centre geno_batch=var[,grep(&#39;22000&#39;, nm, fixed=T)], # genotype batch townsend=var[,grep(&#39;189&#39;, nm, fixed=T)], # townsen var[,grep(&#39;22009&#39;, nm, fixed=T)], # genotype PC ethnicity=var[,grep(&#39;21000&#39;, nm, fixed=T)], # self-reported ethnicity stringsAsFactors = F) pcnm=strsplit(nm[grep(&#39;22009&#39;, nm, fixed=T)], &quot;[.]&quot;) pcnm=paste0(&quot;pc&quot;,unlist(lapply(pcnm,function(X) X[3]))) names(var1)[7:46]=pcnm # file that contains all covariates write.table(var1,&quot;phen/covariates.phen&quot;, col.names=T, row.names=F, quote=F) # create a file to use: no col.names &amp; continuous covariates only use=var1[,c(1,1:3,6:46)] write.table(names(use),&quot;phen/covariates.use-names&quot;, col.names=F, row.names=F, quote=F) write.table(use,&quot;phen/covariates.use&quot;, col.names=F, row.names=F, quote=F) 6.3 GWAS # linear regression------------------------------------------------------------- mkdir unrelated/gwas-good for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 10G #SBATCH -c 2 #SBATCH -t 10:0:0 ./ldak5.1 --linear ../unrelated/gwas-good/$i-linear \\ --pheno ../phen/continuous-traits/$i.raw.pheno \\ --bfile ../gen/geno-unrel \\ --keep ../unrelated/rand.100000 \\ --extract ../gen/snps-unrel-inds.use \\ --covar ../phen/covariates.use \\ --max-threads 2 \\ &quot;&gt; sh_script/$i-linear.sh done # submit files------------------------------------------------------------------ for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do sbatch -A snpher ../sh_script/$i-linear.sh done&gt;../job-records/gwas-good # check job completion---------------------------------------------------------- file=job-records/gwas-good jobs=`awk &#39;{print $4}&#39; $file` mkdir $file-tmp for i in $jobs; do jobinfo $i | awk -F &quot;:&quot; -v i=$i &#39;$1~/Name/ {print i, $2}&#39; &gt;&gt; $file-tmp/name.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/State/ {print$2}&#39; &gt;&gt; $file-tmp/state.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Cores/ {print$2}&#39; &gt;&gt; $file-tmp/cores.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Used walltime/ {print $2 &quot;:&quot; $3 &quot;:&quot; $4}&#39; &gt;&gt; $file-tmp/time.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Max Mem/ {split($2,a,/[(]/ ); print a[1]}&#39; &gt;&gt; $file-tmp/mem.tmp done paste $file-tmp/name.tmp \\ $file-tmp/state.tmp \\ $file-tmp/cores.tmp \\ $file-tmp/time.tmp \\ $file-tmp/mem.tmp \\ | awk &#39;BEGIN{print &quot;ID name state cores time mem&quot;}{print $0}&#39; &gt; $file.out rm -r $file-tmp # resubmit failed/incomplete jobs----------------------------------------------- for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do for j in {1..22}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 8G #SBATCH -c 2 #SBATCH -t 5:0:0 ./ldak5.1 --linear ../unrelated/gwas-good/$i-linear-chr-$j \\ --pheno ../phen/continuous-traits/$i.raw.pheno \\ --bfile ../gen/geno-unrel \\ --keep ../unrelated/rand.100000 \\ --extract ../gen/snps-unrel-inds.use \\ --covar ../phen/covariates.use \\ --max-threads 2 \\ --chr $j &quot;&gt; sh_script/$i-linear-chr-$j.sh done done # submit files------------------------------------------------------------------ for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do for j in {1..22}; do sbatch -A snpher ../sh_script/$i-linear-chr-$j.sh done done&gt;../job-records/gwas-good-resubmission # check job completion---------------------------------------------------------- file=job-records/gwas-good-resubmission jobs=`awk &#39;{print $4}&#39; $file` mkdir $file-tmp for i in $jobs; do jobinfo $i | awk -F &quot;:&quot; -v i=$i &#39;$1~/Name/ {print i, $2}&#39; &gt;&gt; $file-tmp/name.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/State/ {print$2}&#39; &gt;&gt; $file-tmp/state.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Cores/ {print$2}&#39; &gt;&gt; $file-tmp/cores.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Used walltime/ {print $2 &quot;:&quot; $3 &quot;:&quot; $4}&#39; &gt;&gt; $file-tmp/time.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Max Mem/ {split($2,a,/[(]/ ); print a[1]}&#39; &gt;&gt; $file-tmp/mem.tmp done paste $file-tmp/name.tmp \\ $file-tmp/state.tmp \\ $file-tmp/cores.tmp \\ $file-tmp/time.tmp \\ $file-tmp/mem.tmp \\ | awk &#39;BEGIN{print &quot;ID name state cores time mem&quot;}{print $0}&#39; &gt; $file.out rm -r $file-tmp # combine results # only need .summaries &amp; .pvalues #for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,reaction,sbp,snoring,hyper}; do i=quals for j in {1..22}; do if [ $j == 1 ]; then awk &#39;{print $0}&#39; $i-linear-chr-$j.summaries &gt; $i-linear.summaries awk &#39;{print $0}&#39; $i-linear-chr-$j.pvalues &gt; $i-linear.pvalues else awk &#39;NR&gt;1 {print $0}&#39; $i-linear-chr-$j.summaries &gt;&gt; $i-linear.summaries awk &#39;NR&gt;1 {print $0}&#39; $i-linear-chr-$j.pvalues &gt;&gt; $i-linear.pvalues fi done #done 6.4 chisq ~ aver2_j Note we computed aver2_j based using geno-unrel data. see 12.5. Results are stored in summary/ave-r2-by-snp-goodgwas mkdir unrelated/gwas-good-out for trait in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do gwas=unrelated/gwas-good/$trait-linear.summaries aver2=summary/ave-r2-by-snp-goodgwas out=unrelated/gwas-good-out/$trait.out awk &#39;NR&gt;1 {print $1, $5}&#39; $gwas &gt; tmp/gwas.tmp awk &#39;NR==FNR {a[$1]; b[$1]=$2; next} {if ($1 in a) print b[$1]; else print &quot;NA&quot; }&#39; $aver2 tmp/gwas.tmp &gt; tmp/aver2.tmp # put info together paste tmp/gwas.tmp \\ tmp/aver2.tmp \\ | awk &#39;BEGIN{OFS=&quot;;&quot; ; print &quot;snp;chisq;aver2&quot;} {$1=$1}1&#39; &gt; $out done #:::::::::::::::::::::::::::::::::::::::::::::: # estimate slope: chisq ~ aver2_j #:::::::::::::::::::::::::::::::::::::::::::::: require(vroom) traits=c(&quot;awake&quot;,&quot;bmi&quot;,&quot;chron&quot;,&quot;ever&quot;, &quot;neur&quot;,&quot;pulse&quot;,&quot;quals&quot;, &quot;fvc&quot;, &quot;height&quot;,&quot;imp&quot;, &quot;reaction&quot;,&quot;sbp&quot;,&quot;snoring&quot;,&quot;hyper&quot;) for(i in 1:length(traits)){ trait=traits[i] file=paste0(&quot;unrelated/gwas-good-out/&quot;,trait,&quot;.out&quot;) dat=vroom(file, col_names=T, delim=&quot;;&quot;) mod=lm(chisq ~ aver2,data=dat) slope0=data.frame(trait=trait, slope_aver2=coef(mod)[2], p_aver2=summary(mod)$coefficients[,4][2], stringsAsFactors = F) if(i==1){slope=slope0} else {slope=rbind(slope,slope0)} } #:::::::::::::::::::::::::::::::::::::::::::::: # plot chisq ~ aver2_j #:::::::::::::::::::::::::::::::::::::::::::::: # aver2_j bin------------------------------- require(vroom) traits=c(&quot;awake&quot;,&quot;bmi&quot;,&quot;chron&quot;,&quot;ever&quot;, &quot;neur&quot;,&quot;pulse&quot;,&quot;quals&quot;, &quot;fvc&quot;, &quot;height&quot;,&quot;imp&quot;, &quot;reaction&quot;,&quot;sbp&quot;,&quot;snoring&quot;,&quot;hyper&quot;) png(paste0(&quot;fig/chisq-by-aver2-gwas-good-binned.png&quot;), width = 50, height = 30, units = &quot;cm&quot;, res=600) par(mfrow=c(3,5)) for (i in 1:length(traits)){ trait=traits[i] file=paste0(&quot;unrelated/gwas-good-out/&quot;,trait,&quot;.out&quot;) dat=vroom(file, col_names=T, delim=&quot;;&quot;) # bin a variable by quantile cutoff=quantile(dat$aver2, probs = seq(0, 1, 0.005), na.rm=T) dat$bin=cut(dat$aver2, breaks=cutoff, labels=1:(length(cutoff)-1)) # average chisq by bin values out=data.frame(chisq_ave=tapply(dat$chisq,INDEX=dat$bin, mean)) out$bin_val=tapply(dat$aver2,INDEX=dat$bin, mean) plot(out$bin_val, out$chisq_ave, xlab=&quot;ave r2&quot;, ylab=&quot;ave chisq&quot;, main=trait, las=1, cex = 1.5, pch=21, bg=&quot;orange&quot;, col=&quot;white&quot;, lwd=0.5) } dev.off() # raw aver2_j &amp; chisq------------------------------- require(vroom) traits=c(&quot;awake&quot;,&quot;bmi&quot;,&quot;chron&quot;,&quot;ever&quot;, &quot;neur&quot;,&quot;pulse&quot;,&quot;quals&quot;, &quot;fvc&quot;, &quot;height&quot;,&quot;imp&quot;, &quot;reaction&quot;,&quot;sbp&quot;,&quot;snoring&quot;,&quot;hyper&quot;) png(paste0(&quot;fig/chisq-by-aver2-gwas-good-raw.png&quot;), width = 50, height = 30, units = &quot;cm&quot;, res=600) par(mfrow=c(3,5)) for (i in 1:length(traits)){ trait=traits[i] file=paste0(&quot;unrelated/gwas-good-out/&quot;,trait,&quot;.out&quot;) dat=vroom(file, col_names=T, delim=&quot;;&quot;) out=dat[complete.cases(dat),] plot(out$aver2, out$chisq, xlab=&quot;r2&quot;, ylab=&quot;chisq&quot;, main=trait, las=1, cex = 1.5, pch=21, bg=&quot;gray&quot;, col=&quot;white&quot;, lwd=0.5) } dev.off() # plot chisq from good gwas without correcting for PC -------------------------- # based on gwas-mix-0k-noneuro, maf = 0.01 require(vroom) traits=c(&quot;awake&quot;,&quot;bmi&quot;,&quot;chron&quot;,&quot;ever&quot;, &quot;neur&quot;,&quot;pulse&quot;,&quot;quals&quot;, &quot;fvc&quot;, &quot;height&quot;,&quot;imp&quot;, &quot;reaction&quot;,&quot;sbp&quot;,&quot;snoring&quot;,&quot;hyper&quot;) png(paste0(&quot;fig/chisq-by-aver2-gwas-mix-0k-noneuro-raw.png&quot;), width = 50, height = 30, units = &quot;cm&quot;, res=600) par(mfrow=c(3,5)) for (i in 1:length(traits)){ trait=traits[i] file=paste0(&quot;gwas-mix-all-out/&quot;,trait,&quot;-mix-pop-gwas-0k-noneuro-maf.01.out&quot;) dat=vroom(file, col_names=T, delim=&quot;;&quot;) out=dat[complete.cases(dat),] plot(out$aver2, out$chisq, xlab=&quot;r2&quot;, ylab=&quot;chisq&quot;, main=trait, las=1, cex = 1.5, pch=21, bg=&quot;gray&quot;, col=&quot;white&quot;, lwd=0.5) } dev.off() 6.5 ldsc interce 6.6 ldsc intercept 6.6.1 under gcta #::::::::::::: # using original ldsc #::::::::::::: # format stats for ldsc--------------------------------------------------------- library(vroom) options(scipen = 100) rs=vroom(&quot;doug/ukbb.ldsc&quot;, col_names=F) phen=c(&quot;awake&quot;,&quot;bmi&quot;,&quot;chron&quot;,&quot;ever&quot;,&quot;fvc&quot;, &quot;height&quot;,&quot;imp&quot;,&quot;neur&quot;,&quot;pulse&quot;,&quot;quals&quot;, &quot;reaction&quot;,&quot;sbp&quot;,&quot;snoring&quot;,&quot;hyper&quot;, &quot;quals&quot;) for(i in phen){ stat=vroom(paste0(&quot;unrelated/gwas-good/&quot;,i,&quot;-linear.summaries&quot;), col_names=T) p=vroom(paste0(&quot;unrelated/gwas-good/&quot;,i,&quot;-linear.pvalues&quot;), col_names=T) m1=match(rs$X1, stat$Predictor) m2=match(rs$X1, p$Predictor) out=data.frame(SNP=rs$X2, N=stat$n[m1], Z=(sqrt(stat$Stat)*stat$Direction)[m1], A1=stat$A1[m1], A2=stat$A2[m1], pval=p$P[m2], stringsAsFactors=F) out=out[complete.cases(out),] write.table(out, paste0(&quot;unrelated/gwas-good/&quot;,i,&quot;-linear-rs.summaries&quot;), col.names=T, row.names=F, quote=F) } # perform ldsc------------------------------------------------------------------ mkdir out-good-gwas for i in {awake,bmi,chron,ever,fvc,height,quals,imp,neur,pulse,reaction,sbp,snoring,hyper}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 2G #SBATCH -c 3 #SBATCH -t 24:00:0 .././munge_sumstats.py \\ --sumstats ../../unrelated/gwas-good/$i-linear-rs.summaries \\ --out ../out-good-gwas/$i \\ --merge-alleles ../w_hm3.snplist .././ldsc.py \\ --h2 ../out-good-gwas/$i.sumstats.gz \\ --ref-ld-chr ../eur_w_ld_chr/ \\ --w-ld-chr ../eur_w_ld_chr/ \\ --out ../out-good-gwas/$i-ldsc &quot;&gt;sh_script/ldsc-$i-good-gwas.sh done # submit jobs------------------------------------------------------------------- for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,reaction,sbp,snoring,hyper,quals}; do sbatch -A snpher ../sh_script/ldsc-$i-good-gwas.sh done&gt;../../job-records/ldsc-good-gwas #::::::::::::: # using sumher #::::::::::::: # insert genetic distance into bim file----------------------------------------- head geno-unrel.fam &gt; small-unrel for j in {1..22}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --mem 8G #SBATCH -c 1 #SBATCH -t 3:00:0 #SBATCH --constraint \\&quot;s04|s05\\&quot; ./plink1.9 --bfile ../gen/geno-unrel \\ --chr $j \\ --cm-map /home/zhoux/snpher/faststorage/genetic_maps/genetic_map_chr@_combined_b37.txt \\ --make-bed \\ --out new$j \\ --keep ../gen/small-unrel &quot; &gt; sh_script/map$j done for j in {1..22}; do sbatch -A snpher ../sh_script/map$j done &gt; genetic-distance-hapmap3 cd /home/zhoux/dsmwpred/xuan/quality-control/qc-10oct/gen cat new{1..22}.bim | awk &#39;{print $2, $3}&#39; &gt; maps-hapmap3.txt rm new{1..22}.{bim,bed,fam,log} awk &#39;(NR==FNR){arr[$1]=$2;next}{print $1, $2, arr[$2], $4, $5, $6}&#39; &gt; geno-unrel.bim2 maps-hapmap3.txt geno-unrel.bim mv geno-unrel.bim geno-unrel.bim0 mv geno-unrel.bim2 geno-unrel.bim # compute tagging under gcta---------------------------------------------------- for j in {1..22}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 5G #SBATCH -c 1 #SBATCH -t 5:0:0 ./ldak5.1 --calc-tagging ../tagging/gcta-hapmap3-chr-$j \\ --bfile ../gen/geno-unrel \\ --ignore-weights YES \\ --power -1 \\ --window-cm 1 \\ --chr $j &quot;&gt; sh_script/tagging-gcta-hapmap3-chr$j done for j in {1..22}; do sbatch -A snpher ../sh_script/tagging-gcta-hapmap3-chr$j done &gt; ../job-records/tagging-gcta-hapmap3 # check job completion---------------------------------------------------------- file=job-records/tagging-gcta-hapmap3 jobs=`awk &#39;{print $4}&#39; $file` mkdir $file-tmp for i in $jobs; do jobinfo $i | awk -F &quot;:&quot; -v i=$i &#39;$1~/Name/ {print i, $2}&#39; &gt;&gt; $file-tmp/name.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/State/ {print$2}&#39; &gt;&gt; $file-tmp/state.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Cores/ {print$2}&#39; &gt;&gt; $file-tmp/cores.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Used walltime/ {print $2 &quot;:&quot; $3 &quot;:&quot; $4}&#39; &gt;&gt; $file-tmp/time.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Max Mem/ {split($2,a,/[(]/ ); print a[1]}&#39; &gt;&gt; $file-tmp/mem.tmp done paste $file-tmp/name.tmp \\ $file-tmp/state.tmp \\ $file-tmp/cores.tmp \\ $file-tmp/time.tmp \\ $file-tmp/mem.tmp \\ | awk &#39;BEGIN{print &quot;ID name state cores time mem&quot;}{print $0}&#39; &gt; $file.out rm -r $file-tmp # merge tagging files----------------------------------------------------------- rm list.txt for j in {1..22}; do echo &quot;tagging/gcta-hapmap3-chr-$j.tagging&quot; &gt;&gt; list.txt done ./ldak5.1 --join-tagging tagging/gcta-hapmap3 --taglist list.txt # ldsc intercept---------------------------------------------------------------- mkdir sumher-good for i in {awake,bmi,chron,ever,fvc,height,quals,imp,neur,pulse,reaction,sbp,snoring,hyper}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 5G #SBATCH -c 1 #SBATCH -t 5:0:0 ./ldak5.1 --sum-hers ../sumher-good/$i-sumher-gcta \\ --tagfile ../tagging/gcta-hapmap3.tagging \\ --summary ../unrelated/gwas-good/$i-linear.summaries \\ --check-sums NO \\ --intercept YES &quot;&gt; sh_script/$i-sumher-gcta-unrelated done for i in {awake,bmi,chron,ever,fvc,height,quals,imp,neur,pulse,reaction,sbp,snoring,hyper}; do sbatch -A snpher ../sh_script/$i-sumher-gcta-unrelated done&gt;../job-records/sumher-gcta-unrelated 6.6.2 under ldak-thin # get weights------------------------------------------------------------------- awk &lt; ldak-thin/ldak-thin-hapmap3.in &#39;{print $1, 1}&#39; &gt; ldak-thin/weights.ldak-thin-hapmap3 # calculate tagging under ldak-thin--------------------------------------------- for j in {1..22}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --partition normal #SBATCH --mem 40G #SBATCH -c 5 #SBATCH -t 10:0:0 #SBATCH --constraint \\&quot;s04|s05\\&quot; ./ldak5.1 --calc-tagging ../tagging/ldak-thin-hapmap3-chr-$j \\ --bfile ../gen/geno-unrel \\ --weights ../ldak-thin/weights.ldak-thin-hapmap3 \\ --power -.25 \\ --window-cm 1 \\ --chr $j \\ --save-matrix YES \\ --max-threads 5 &quot; &gt; sh_script/tagging-ldak-thin-hapmap3-chr$j.sh done # submit scripts for j in {1..22}; do sbatch -A snpher ../sh_script/tagging-ldak-thin-hapmap3-chr$j.sh done &gt; ../job-records/tagging-ldak-thin-hapmap3 # check job completion---------------------------------------------------------- file=job-records/tagging-ldak-thin-hapmap3 jobs=`awk &#39;{print $4}&#39; $file` mkdir $file-tmp for i in $jobs; do jobinfo $i | awk -F &quot;:&quot; -v i=$i &#39;$1~/Name/ {print i, $2}&#39; &gt;&gt; $file-tmp/name.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/State/ {print$2}&#39; &gt;&gt; $file-tmp/state.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Cores/ {print$2}&#39; &gt;&gt; $file-tmp/cores.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Used walltime/ {print $2 &quot;:&quot; $3 &quot;:&quot; $4}&#39; &gt;&gt; $file-tmp/time.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Max Mem/ {split($2,a,/[(]/ ); print a[1]}&#39; &gt;&gt; $file-tmp/mem.tmp done paste $file-tmp/name.tmp \\ $file-tmp/state.tmp \\ $file-tmp/cores.tmp \\ $file-tmp/time.tmp \\ $file-tmp/mem.tmp \\ | awk &#39;BEGIN{print &quot;ID name state cores time mem&quot;}{print $0}&#39; &gt; $file.out rm -r $file-tmp # merge tagging files----------------------------------------------------------- rm list.txt rm matlist.txt for j in {1..22}; do echo &quot;tagging/ldak-thin-hapmap3-chr-$j.tagging&quot; &gt;&gt; list.txt echo &quot;tagging/ldak-thin-hapmap3-chr-$j.matrix&quot; &gt;&gt; matlist.txt done ./ldak5.1 --join-tagging tagging/ldak-thin-hapmap3 --taglist list.txt --matlist matlist.txt # ldsc intercept---------------------------------------------------------------- for i in {awake,bmi,chron,ever,fvc,height,quals,imp,neur,pulse,reaction,sbp,snoring,hyper}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 5G #SBATCH -c 1 #SBATCH -t 00:30:0 ./ldak5.1 --sum-hers ../sumher-good/$i-sumher-ldak-thin \\ --tagfile ../tagging/ldak-thin-hapmap3.tagging \\ --summary ../unrelated/gwas-good/$i-linear.summaries \\ --check-sums NO \\ --intercept YES &quot;&gt; sh_script/$i-sumher-ldak-thin-unrelated done for i in {awake,bmi,chron,ever,fvc,height,quals,imp,neur,pulse,reaction,sbp,snoring,hyper}; do sbatch -A snpher ../sh_script/$i-sumher-ldak-thin-unrelated done&gt;../job-records/sumher-ldak-thin-unrelated 6.6.3 summary # original ldsc grep Intercept *ldsc.log | awk &#39;{split($1, a, /[-]/); split($3, b, /[()]/); print a[1], $2, b[2]}&#39; &gt; ../../summary/ldsc-good # sumher under gcta grep Intercept_Estimate *gcta.extra | awk &#39;{ split($1, a, /[-]/); print a[1], $2}&#39; &gt;../summary/sumher-gcta-good-est grep Intercept_SD *gcta.extra | awk &#39;{ split($1, a, /[-]/); print a[1], $2}&#39; &gt;../summary/sumher-gcta-good-sd cd ../summary/ paste sumher-gcta-good-est sumher-gcta-good-sd | awk &#39;{print $1, $2, $4}&#39; &gt; sumber-gcta-good # submer under ldak-thin grep Intercept_Estimate *ldak-thin.extra | awk &#39;{ split($1, a, /[-]/); print a[1], $2}&#39; &gt;../summary/sumher-ldak-thin-good-est grep Intercept_SD *ldak-thin.extra | awk &#39;{ split($1, a, /[-]/); print a[1], $2}&#39; &gt;../summary/sumher-ldak-thin-good-sd cd ../summary/ paste sumher-ldak-thin-good-est sumher-ldak-thin-good-sd | awk &#39;{print $1, $2, $4}&#39; &gt; sumher-ldak-thin-good 6.7 REML 6.7.1 making grms # making grm ------------------------------------------------------------------- #::: # under gcta #::: # all snps echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --partition normal #SBATCH --mem 60G #SBATCH -c 10 #SBATCH -t 20:0:0 #SBATCH --constraint \\&quot;s04|s05\\&quot; ./ldak5.1 --max-threads 10 \\ --calc-kins-direct ../kinship/gcta-all-unrel \\ --bfile ../gen/geno-unrel \\ --power -1 \\ --ignore-weights YES \\ --single YES &quot; &gt; sh_script/grm-all-snps-unrel sbatch -A snpher ../sh_script/grm-all-snps-unrel &gt; ../job-records/grm-all-snps-unrel # grm by snp blocks: right vs. left awk &#39;$1&lt;8 {print $2}&#39; geno-unrel.bim &gt; left-hapmap3.snps awk &#39;$1&gt;=8 {print $2}&#39; geno-unrel.bim &gt; right-hapmap3.snps for i in left right; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --partition normal #SBATCH --mem 60G #SBATCH -c 10 #SBATCH -t 20:0:0 #SBATCH --constraint \\&quot;s04|s05\\&quot; ./ldak5.1 --max-threads 10 \\ --calc-kins-direct ../kinship/gcta-$i-unrel \\ --bfile ../gen/geno-unrel \\ --extract ../gen/$i-hapmap3.snps \\ --power -1 \\ --ignore-weights YES \\ --single YES &quot; &gt; sh_script/grm-gcta-$i-unrel done for i in left right; do sbatch -A snpher ../sh_script/grm-gcta-$i-unrel done &gt; ../job-records/grm-gcta-by-snps-unrel #::: # under ldak-thin #::: #----------- # 1. thin snps #----------- for j in {1..22}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --partition normal #SBATCH --mem 10G #SBATCH -c 4 #SBATCH -t 4:0:0 #SBATCH --constraint \\&quot;s04|s05\\&quot; ./ldak5.1 --max-threads 4 \\ --window-prune 0.98 \\ --window-kb 100 \\ --extract ../gen/snps-unrel-inds.use \\ --bfile ../gen/geno-unrel \\ --thin ../ldak-thin/chr$j-hapmap3 \\ --chr $j &quot; &gt; sh_script/ldak-thin$j-hapmap3 done # submit script for j in {1..22}; do sbatch -A snpher ../sh_script/ldak-thin$j-hapmap3 done &gt; ../job-records/ldak-thin-hapmap3 # check job completion--- file=job-records/ldak-thin-hapmap3 jobs=`awk &#39;{print $4}&#39; $file` mkdir $file-tmp for i in $jobs; do jobinfo $i | awk -F &quot;:&quot; -v i=$i &#39;$1~/Name/ {print i, $2}&#39; &gt;&gt; $file-tmp/name.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/State/ {print$2}&#39; &gt;&gt; $file-tmp/state.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Cores/ {print$2}&#39; &gt;&gt; $file-tmp/cores.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Used walltime/ {print $2 &quot;:&quot; $3 &quot;:&quot; $4}&#39; &gt;&gt; $file-tmp/time.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Max Mem/ {split($2,a,/[(]/ ); print a[1]}&#39; &gt;&gt; $file-tmp/mem.tmp done paste $file-tmp/name.tmp \\ $file-tmp/state.tmp \\ $file-tmp/cores.tmp \\ $file-tmp/time.tmp \\ $file-tmp/mem.tmp \\ | awk &#39;BEGIN{print &quot;ID name state cores time mem&quot;}{print $0}&#39; &gt; $file.out rm -r $file-tmp # combine snp list cat ldak-thin/chr{1..22}-hapmap3.in &gt; ldak-thin/ldak-thin-hapmap3.in #---------------------- # 2. kinship matrix under ldak-thin #------------------------ echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --partition normal #SBATCH --mem 60G #SBATCH -c 10 #SBATCH -t 20:0:0 #SBATCH --constraint \\&quot;s04|s05\\&quot; ./ldak5.1 --max-threads 10 \\ --calc-kins-direct ../kinship/ldak-thin-all-unrel \\ --bfile ../gen/geno-unrel \\ --extract ../ldak-thin/ldak-thin-hapmap3.in \\ --power -0.25 \\ --ignore-weights YES \\ --single YES &quot; &gt; sh_script/ldak-thin-grm-all-snps-unrel sbatch -A snpher ../sh_script/ldak-thin-grm-all-snps-unrel &gt; ../job-records/ldak-thin-grm-all-snps-unrel # grm by snp blocks: right vs. left awk &#39;{split($1, a, /[:]/); if (a[1]&lt;8) print $1}&#39; \\ ldak-thin/ldak-thin-hapmap3.in &gt; gen/left-ldak-thin-hapmap3.snps awk &#39;{split($1, a, /[:]/); if (a[1]&gt;=8) print $1}&#39; \\ ldak-thin/ldak-thin-hapmap3.in &gt; gen/right-ldak-thin-hapmap3.snps for i in left right; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --partition normal #SBATCH --mem 60G #SBATCH -c 10 #SBATCH -t 20:0:0 #SBATCH --constraint \\&quot;s04|s05\\&quot; ./ldak5.1 --max-threads 10 \\ --calc-kins-direct ../kinship/ldak-thin-$i-unrel \\ --bfile ../gen/geno-unrel \\ --extract ../gen/$i-ldak-thin-hapmap3.snps \\ --power -0.25 \\ --ignore-weights YES \\ --single YES &quot; &gt; sh_script/ldak-thin-grm-$i-unrel done for i in left right; do sbatch -A snpher ../sh_script/ldak-thin-grm-$i-unrel done &gt; ../job-records/grm-ldak-thin-by-snps-unrel 6.7.2 fast-reml #::: # under gcta #::: # make script files------------------------------------------------------------- mkdir reml-good for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do for k in all left right; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 100G #SBATCH -c 2 #SBATCH -t 5:0:0 ./ldak5.1 --fast-reml ../reml-good/$i-gcta-$k \\ --repetitions 20 \\ --pheno ../phen/continuous-traits/$i.raw.pheno \\ --keep ../unrelated/rand.100000 \\ --covar ../phen/covariates.use \\ --grm ../kinship/gcta-$k-unrel \\ --max-threads 2 \\ --single YES &quot;&gt; sh_script/$i-reml-good-gcta-$k-snps done done # submit script files----------------------------------------------------------- for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do for k in all left right; do sbatch -A snpher ../sh_script/$i-reml-good-gcta-$k-snps done done&gt;../job-records/reml-good-gcta # check job completion---------------------------------------------------------- file=job-records/reml-good-gcta jobs=`awk &#39;{print $4}&#39; $file` mkdir $file-tmp for i in $jobs; do jobinfo $i | awk -F &quot;:&quot; -v i=$i &#39;$1~/Name/ {print i, $2}&#39; &gt;&gt; $file-tmp/name.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/State/ {print$2}&#39; &gt;&gt; $file-tmp/state.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Cores/ {print$2}&#39; &gt;&gt; $file-tmp/cores.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Used walltime/ {print $2 &quot;:&quot; $3 &quot;:&quot; $4}&#39; &gt;&gt; $file-tmp/time.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Max Mem/ {split($2,a,/[(]/ ); print a[1]}&#39; &gt;&gt; $file-tmp/mem.tmp done paste $file-tmp/name.tmp \\ $file-tmp/state.tmp \\ $file-tmp/cores.tmp \\ $file-tmp/time.tmp \\ $file-tmp/mem.tmp \\ | awk &#39;BEGIN{print &quot;ID name state cores time mem&quot;}{print $0}&#39; &gt; $file.out rm -r $file-tmp #::: # under ldak-thin #::: # make script files------------------------------------------------------------- for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do for k in all left right; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 100G #SBATCH -c 2 #SBATCH -t 5:0:0 ./ldak5.1 --fast-reml ../reml-good/$i-ldak-thin-$k \\ --repetitions 20 \\ --pheno ../phen/continuous-traits/$i.raw.pheno \\ --keep ../unrelated/rand.100000 \\ --covar ../phen/covariates.use \\ --grm ../kinship/ldak-thin-$k-unrel \\ --max-threads 2 \\ --single YES &quot;&gt; sh_script/$i-reml-good-ldak-thin-$k-snps done done # submit script files----------------------------------------------------------- for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do for k in all left right; do sbatch -A snpher ../sh_script/$i-reml-good-ldak-thin-$k-snps done done &gt;../job-records/reml-good-ldak-thin # check job completion---------------------------------------------------------- file=job-records/reml-good-ldak-thin jobs=`awk &#39;{print $4}&#39; $file` mkdir $file-tmp for i in $jobs; do jobinfo $i | awk -F &quot;:&quot; -v i=$i &#39;$1~/Name/ {print i, $2}&#39; &gt;&gt; $file-tmp/name.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/State/ {print$2}&#39; &gt;&gt; $file-tmp/state.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Cores/ {print$2}&#39; &gt;&gt; $file-tmp/cores.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Used walltime/ {print $2 &quot;:&quot; $3 &quot;:&quot; $4}&#39; &gt;&gt; $file-tmp/time.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Max Mem/ {split($2,a,/[(]/ ); print a[1]}&#39; &gt;&gt; $file-tmp/mem.tmp done paste $file-tmp/name.tmp \\ $file-tmp/state.tmp \\ $file-tmp/cores.tmp \\ $file-tmp/time.tmp \\ $file-tmp/mem.tmp \\ | awk &#39;BEGIN{print &quot;ID name state cores time mem&quot;}{print $0}&#39; &gt; $file.out rm -r $file-tmp 6.7.3 inflation test #:::::::::::: # under gcta #:::::::::::: # extract h2 estimates --------------------------------------------------------- # right for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do outfile=reml-good/$i-gcta-right.reml awk -v i=$i &#39;$1==&quot;Her_All&quot; {print i, $2, $3}&#39; $outfile &gt;&gt; summary/est.tmp awk &#39;$1==&quot;Converged&quot; {print$2}&#39; $outfile &gt;&gt; summary/converge.tmp done paste summary/est.tmp \\ summary/converge.tmp \\ | awk &#39;BEGIN{print &quot;code h2 se converge&quot;}{print i, $0}&#39; \\ &gt; summary/reml-gcta-good.right rm summary/est.tmp summary/converge.tmp # left for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do outfile=reml-good/$i-gcta-left.reml awk -v i=$i &#39;$1==&quot;Her_All&quot; {print i, $2, $3}&#39; $outfile &gt;&gt; summary/est.tmp awk &#39;$1==&quot;Converged&quot; {print$2}&#39; $outfile &gt;&gt; summary/converge.tmp done paste summary/est.tmp \\ summary/converge.tmp \\ | awk &#39;BEGIN{print &quot;code h2 se converge&quot;}{print i, $0}&#39; \\ &gt; summary/reml-gcta-good.left rm summary/est.tmp summary/converge.tmp # all for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do outfile=reml-good/$i-gcta-all.reml awk -v i=$i &#39;$1==&quot;Her_All&quot; {print i, $2, $3}&#39; $outfile &gt;&gt; summary/est.tmp awk &#39;$1==&quot;Converged&quot; {print$2}&#39; $outfile &gt;&gt; summary/converge.tmp done paste summary/est.tmp \\ summary/converge.tmp \\ | awk &#39;BEGIN{print &quot;code h2 se converge&quot;}{print i, $0}&#39; \\ &gt; summary/reml-gcta-good.all rm summary/est.tmp summary/converge.tmp # inflation test---------------------------------------------------------------- R full=read.table(paste0(&quot;summary/reml-gcta-good.all&quot;), header=T) left=read.table(paste0(&quot;summary/reml-gcta-good.left&quot;), header=T) right=read.table(paste0(&quot;summary/reml-gcta-good.right&quot;), header=T) # some analyses did not complete --&gt; match dataframes dim(full);dim(left);dim(right) common=intersect(full$code, left$code) common=intersect(common, right$code) m1=match(common, right$code) m2=match(common, full$code) m3=match(common, left$code) right=right[m1,] full=full[m2,] left=left[m3,] for(i in 1:dim(full)[1]){ est1=left$h2[i] sd1=left$se[i] est2=right$h2[i] sd2=right$se[i] est=full$h2[i] sd=full$se[i] N=100000 d1=rnorm(N,est1,sd1) d2=rnorm(N,est2,sd2) d=rnorm(N,est,sd) p=1-mean(d1+d2-d&gt;=0) out0=data.frame(code=full$code[i], right_est=est2, right_sd=sd2, left_est=est1, left_sd=sd1, all_est=est, all_sd=sd, p_inflation=p) if(i==1){out=out0}else{out=rbind(out,out0)} } write.table(out, paste0(&quot;summary/reml-gcta-inflation-good-gwas.txt&quot;), col.names=T, row.names=F, quote=F) #:::::::::::: # under ldak-thin #:::::::::::: # extract h2 estimates --------------------------------------------------------- # right for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do outfile=reml-good/$i-ldak-thin-right.reml awk -v i=$i &#39;$1==&quot;Her_All&quot; {print i, $2, $3}&#39; $outfile &gt;&gt; summary/est.tmp awk &#39;$1==&quot;Converged&quot; {print$2}&#39; $outfile &gt;&gt; summary/converge.tmp done paste summary/est.tmp \\ summary/converge.tmp \\ | awk &#39;BEGIN{print &quot;code h2 se converge&quot;}{print i, $0}&#39; \\ &gt; summary/reml-ldak-thin-good.right rm summary/est.tmp summary/converge.tmp # left for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do outfile=reml-good/$i-ldak-thin-left.reml awk -v i=$i &#39;$1==&quot;Her_All&quot; {print i, $2, $3}&#39; $outfile &gt;&gt; summary/est.tmp awk &#39;$1==&quot;Converged&quot; {print$2}&#39; $outfile &gt;&gt; summary/converge.tmp done paste summary/est.tmp \\ summary/converge.tmp \\ | awk &#39;BEGIN{print &quot;code h2 se converge&quot;}{print i, $0}&#39; \\ &gt; summary/reml-ldak-thin-good.left rm summary/est.tmp summary/converge.tmp # all for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do outfile=reml-good/$i-ldak-thin-all.reml awk -v i=$i &#39;$1==&quot;Her_All&quot; {print i, $2, $3}&#39; $outfile &gt;&gt; summary/est.tmp awk &#39;$1==&quot;Converged&quot; {print$2}&#39; $outfile &gt;&gt; summary/converge.tmp done paste summary/est.tmp \\ summary/converge.tmp \\ | awk &#39;BEGIN{print &quot;code h2 se converge&quot;}{print i, $0}&#39; \\ &gt; summary/reml-ldak-thin-good.all rm summary/est.tmp summary/converge.tmp # inflation test---------------------------------------------------------------- R full=read.table(paste0(&quot;summary/reml-ldak-thin-good.all&quot;), header=T) left=read.table(paste0(&quot;summary/reml-ldak-thin-good.left&quot;), header=T) right=read.table(paste0(&quot;summary/reml-ldak-thin-good.right&quot;), header=T) # some analyses did not complete --&gt; match dataframes dim(full);dim(left);dim(right) common=intersect(full$code, left$code) common=intersect(common, right$code) m1=match(common, right$code) m2=match(common, full$code) m3=match(common, left$code) right=right[m1,] full=full[m2,] left=left[m3,] for(i in 1:dim(full)[1]){ est1=left$h2[i] sd1=left$se[i] est2=right$h2[i] sd2=right$se[i] est=full$h2[i] sd=full$se[i] N=100000 d1=rnorm(N,est1,sd1) d2=rnorm(N,est2,sd2) d=rnorm(N,est,sd) p=1-mean(d1+d2-d&gt;=0) out0=data.frame(code=full$code[i], right_est=est2, right_sd=sd2, left_est=est1, left_sd=sd1, all_est=est, all_sd=sd, p_inflation=p) if(i==1){out=out0}else{out=rbind(out,out0)} } write.table(out, paste0(&quot;summary/reml-ldak-thin-inflation.txt&quot;), col.names=T, row.names=F, quote=F) 6.8 HE 6.8.1 estimation # regress grm on covariates----------------------------------------------------- for grm in gcta-all-unrel gcta-left-unrel gcta-right-unrel ldak-thin-all-unrel ldak-thin-left-unrel ldak-thin-right-unrel; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 50G #SBATCH -c 5 #SBATCH -t 10:0:0 ./ldak5.1 --adjust-grm ../kinship/$grm.covar \\ --grm ../kinship/$grm \\ --covar ../phen/covariates.use \\ --max-threads 5 &quot;&gt; sh_script/$grm-adjust-unrel.sh done # submit jobs for grm in gcta-all-unrel gcta-left-unrel gcta-right-unrel ldak-thin-all-unrel ldak-thin-left-unrel ldak-thin-right-unrel; do sbatch -A snpher ../sh_script/$grm-adjust-unrel.sh done &gt; ../job-records/grm-unrel-adjust-for-HE # check job completion---------------------------------------------------------- file=job-records/grm-unrel-adjust-for-HE jobs=`awk &#39;{print $4}&#39; $file` mkdir $file-tmp for i in $jobs; do jobinfo $i | awk -F &quot;:&quot; -v i=$i &#39;$1~/Name/ {print i, $2}&#39; &gt;&gt; $file-tmp/name.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/State/ {print$2}&#39; &gt;&gt; $file-tmp/state.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Cores/ {print$2}&#39; &gt;&gt; $file-tmp/cores.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Used walltime/ {print $2 &quot;:&quot; $3 &quot;:&quot; $4}&#39; &gt;&gt; $file-tmp/time.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Max Mem/ {split($2,a,/[(]/ ); print a[1]}&#39; &gt;&gt; $file-tmp/mem.tmp done paste $file-tmp/name.tmp \\ $file-tmp/state.tmp \\ $file-tmp/cores.tmp \\ $file-tmp/time.tmp \\ $file-tmp/mem.tmp \\ | awk &#39;BEGIN{print &quot;ID name state cores time mem&quot;}{print $0}&#39; &gt; $file.out rm -r $file-tmp # HE under gcta----------------------------------------------------------------- for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do for k in all left right; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 2G #SBATCH -c 1 #SBATCH -t 00:30:0 ./ldak5.1 --he ../he-good/$i-he-gcta-$k \\ --pheno ../phen/continuous-traits/$i.raw.pheno \\ --grm ../kinship/gcta-$k-unrel.covar \\ --kinship-details NO \\ --check-root NO \\ --covar ../phen/covariates.use \\ --max-threads 1 \\ --memory-save YES &quot;&gt; sh_script/$i-he-good-gcta-$k-snps.sh done done # submit files------------------------------------------------------------------ for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do for k in all left right; do sbatch -A snpher ../sh_script/$i-he-good-gcta-$k-snps.sh done done &gt; ../job-records/he-good-gcta # HE under ldak-thin------------------------------------------------------------ for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do for k in all left right; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 2G #SBATCH -c 1 #SBATCH -t 0:30:0 ./ldak5.1 --he ../he-good/$i-he-ldak-thin-$k \\ --pheno ../phen/continuous-traits/$i.raw.pheno \\ --grm ../kinship/ldak-thin-$k-unrel.covar \\ --kinship-details NO \\ --check-root NO \\ --covar ../phen/covariates.use \\ --max-threads 1 \\ --memory-save YES &quot;&gt; sh_script/$i-he-good-ldak-thin-$k-snps.sh done done # submit files------------------------------------------------------------------ for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do for k in all left right; do sbatch -A snpher ../sh_script/$i-he-good-ldak-thin-$k-snps.sh done done &gt; ../job-records/he-good-ldak-thin 6.8.2 summary #:::::::::::: # under gcta #:::::::::::: # extract h2 estimates --------------------------------------------------------- # right rm summary/he-gcta-unrel.right for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do outfile=he-good/$i-he-gcta-right.he awk -v i=$i &#39;$1==&quot;Her_All&quot; {print i, $2, $3}&#39; $outfile &gt;&gt; summary/he-gcta-unrel.right done # left rm summary/he-gcta-unrel.left for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do outfile=he-good/$i-he-gcta-left.he awk -v i=$i &#39;$1==&quot;Her_All&quot; {print i, $2, $3}&#39; $outfile &gt;&gt; summary/he-gcta-unrel.left done # all rm summary/he-gcta-unrel.all for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do outfile=he-good/$i-he-gcta-all.he awk -v i=$i &#39;$1==&quot;Her_All&quot; {print i, $2, $3}&#39; $outfile &gt;&gt; summary/he-gcta-unrel.all done # inflation test---------------------------------------------------------------- R full=read.table(paste0(&quot;summary/he-gcta-unrel.all&quot;), header=F) left=read.table(paste0(&quot;summary/he-gcta-unrel.left&quot;), header=F) right=read.table(paste0(&quot;summary/he-gcta-unrel.right&quot;), header=F) names(full)=names(left)=names(right)=c(&quot;code&quot;,&quot;h2&quot;,&quot;se&quot;) # some analyses did not complete --&gt; match dataframes dim(full);dim(left);dim(right) common=intersect(full$code, left$code) common=intersect(common, right$code) m1=match(common, right$code) m2=match(common, full$code) m3=match(common, left$code) right=right[m1,] full=full[m2,] left=left[m3,] for(i in 1:dim(full)[1]){ est1=left$h2[i] sd1=left$se[i] est2=right$h2[i] sd2=right$se[i] est=full$h2[i] sd=full$se[i] N=100000 d1=rnorm(N,est1,sd1) d2=rnorm(N,est2,sd2) d=rnorm(N,est,sd) p=1-mean(d1+d2-d&gt;=0) out0=data.frame(code=full$code[i], right_est=est2, right_sd=sd2, left_est=est1, left_sd=sd1, all_est=est, all_sd=sd, p_inflation=p) if(i==1){out=out0}else{out=rbind(out,out0)} } write.table(out, paste0(&quot;summary/he-gcta-inflation-unrel-gwas.txt&quot;), col.names=T, row.names=F, quote=F) #:::::::::::: # under ldak-thin #:::::::::::: # extract h2 estimates --------------------------------------------------------- # right rm summary/he-ldak-thin-unrel.right for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do outfile=he-good/$i-he-ldak-thin-right.he awk -v i=$i &#39;$1==&quot;Her_All&quot; {print i, $2, $3}&#39; $outfile &gt;&gt; summary/he-ldak-thin-unrel.right done # left rm summary/he-ldak-thin-unrel.left for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do outfile=he-good/$i-he-ldak-thin-left.he awk -v i=$i &#39;$1==&quot;Her_All&quot; {print i, $2, $3}&#39; $outfile &gt;&gt; summary/he-ldak-thin-unrel.left done # all rm summary/he-ldak-thin-unrel.all for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do outfile=he-good/$i-he-ldak-thin-all.he awk -v i=$i &#39;$1==&quot;Her_All&quot; {print i, $2, $3}&#39; $outfile &gt;&gt; summary/he-ldak-thin-unrel.all done # inflation test---------------------------------------------------------------- R full=read.table(paste0(&quot;summary/he-ldak-thin-unrel.all&quot;), header=F) left=read.table(paste0(&quot;summary/he-ldak-thin-unrel.left&quot;), header=F) right=read.table(paste0(&quot;summary/he-ldak-thin-unrel.right&quot;), header=F) names(full)=names(left)=names(right)=c(&quot;code&quot;,&quot;h2&quot;,&quot;se&quot;) # some analyses did not complete --&gt; match dataframes dim(full);dim(left);dim(right) common=intersect(full$code, left$code) common=intersect(common, right$code) m1=match(common, right$code) m2=match(common, full$code) m3=match(common, left$code) right=right[m1,] full=full[m2,] left=left[m3,] for(i in 1:dim(full)[1]){ est1=left$h2[i] sd1=left$se[i] est2=right$h2[i] sd2=right$se[i] est=full$h2[i] sd=full$se[i] N=100000 d1=rnorm(N,est1,sd1) d2=rnorm(N,est2,sd2) d=rnorm(N,est,sd) p=1-mean(d1+d2-d&gt;=0) out0=data.frame(code=full$code[i], right_est=est2, right_sd=sd2, left_est=est1, left_sd=sd1, all_est=est, all_sd=sd, p_inflation=p) if(i==1){out=out0}else{out=rbind(out,out0)} } write.table(out, paste0(&quot;summary/he-ldak-thin-inflation-unrel-gwas.txt&quot;), col.names=T, row.names=F, quote=F) "],["bad.html", "7 Bad GWAS 7.1 ID list 7.2 GWAS-lm 7.3 GWAS-bolt-lmm 7.4 chisq ~ aver2_j 7.5 ldsc intercept 7.6 REML 7.7 HE", " 7 Bad GWAS 7.1 ID list 7.1.1 initial selection Randomly select participants with complete data and use the SNP list as for unrelated. # extract white, asian &amp; black from ukbb---------------------------------------- R dat=read.table(&quot;phen/covariates.phen&quot;, header=T, stringsAsFactors = F) # White: British(1001) # Asian or Asian British: Indian(3001)+Pakistani(3002)+Bangladeshi(3003)+other Asian backgroud(3004) # Black: Caribbean(4001)+African(4002)+other Black Background(4003) dat=dat[complete.cases(dat),] white=1001 asian=3001:3004 black=4001:4003 out1=dat[dat$ethnicity%in%white,] out2=dat[dat$ethnicity%in%asian,] out3=dat[dat$ethnicity%in%black,] write.table(out1[,&quot;eid&quot;], &quot;white-complete-cov.id&quot;, col.names=F, row.names=F, quote=F) write.table(out2[,&quot;eid&quot;], &quot;asian-complete-cov.id&quot;, col.names=F, row.names=F, quote=F) write.table(out3[,&quot;eid&quot;], &quot;black-complete-cov.id&quot;, col.names=F, row.names=F, quote=F) # overlapping UNRELATED WHITE across 14 traits---------------------------------- # overlapping = no missing data for the 14 traits cp icd10/unrelated.inds overlap.ind # unrelated white British dir=phen/continuous-traits/ for tt in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do mv overlap.ind temp awk &#39;(NR==FNR){a[$1];next}($1 in a){print $1, $2}&#39; temp $dir/$tt.raw.pheno &gt; overlap.ind wc -l overlap.ind echo $tt done rm temp # overlapping + complete data for covariates + unrelated awk &#39;NR==FNR{a[$1]; next} ($1 in a) {print $1, $1}&#39; unrelated/overlap.ind white-complete-cov.id &gt; overlap-white-complete-cov.id # N = 147,008 # overlapping UNRELATED ASIAN across 14 traits---------------------------------- cp asian-complete-cov.id overlap-asian-complete-cov.id dir=phen/continuous-traits/ for tt in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do mv overlap-asian-complete-cov.id temp awk &#39;(NR==FNR){a[$1];next}($1 in a){print $1, $2}&#39; temp $dir/$tt.raw.pheno &gt; overlap-asian-complete-cov.id wc -l overlap-asian-complete-cov.id # N = 4,052 echo $tt done rm temp # relatedness filtering # see below # overlapping UNRELATED BLACK across 14 traits---------------------------------- cp black-complete-cov.id overlap-black-complete-cov.id dir=phen/continuous-traits/ for tt in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do mv overlap-black-complete-cov.id temp awk &#39;(NR==FNR){a[$1];next}($1 in a){print $1, $2}&#39; temp $dir/$tt.raw.pheno &gt; overlap-black-complete-cov.id wc -l overlap-black-complete-cov.id # N = 3,583 echo $tt done rm temp # relatedness filtering # see below 7.1.2 relatedness filtering For black and Asian people only. #------------- # 0. make bfiles #------------ # id lists overlap-white-complete-cov.id # N=147,008 overlap-black-complete-cov.id # N=3,583 overlap-asian-complete-cov.id # N=4,052 awk &#39;{print $0}&#39; overlap-white-complete-cov.id overlap-black-complete-cov.id overlap-asian-complete-cov.id &gt; overlap-mixed-complete-cov.id # 154,643 # bfiles by chr for j in {1..22}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 20G #SBATCH -c 3 #SBATCH -t 1:0:0 ./plink2 --pfile ../gen/geno_plink/bhr$j \\ --keep ../overlap-mixed-complete-cov.id \\ --extract ../gen/snps-unrel-inds.use \\ --make-bed \\ --memory 20000 \\ --out ../gen/tmp/bhr$j-mix \\ --threads 3 \\ &quot;&gt; sh_script/chr$j-mix.sh done # submit script for i in {1..22}; do sbatch -A snpher ../sh_script/chr$i-mix.sh done&gt;../job-records/mkbfile-mix-pop # merge bfiles rm bfile-mix.list for j in {1..22}; do echo &quot;../gen/tmp/bhr$j-mix&quot; &gt;&gt;bfile-mix.list done echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 20G #SBATCH -c 3 #SBATCH -t 10:0:0 ./ldak5.1 --make-bed ../gen/geno-mix \\ --mbfile ../gen/bfile-mix.list \\ --max-threads 3 \\ --exclude-dups YES &quot;&gt; sh_script/merge-mbfiles-mix-pop.sh # submit the script sbatch -A snpher ../sh_script/merge-mbfiles-mix-pop.sh &gt;../job-records/merge-mbfiles-mix #------- # 1. prune SNPs #------- for j in {1..22}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --partition normal #SBATCH --mem 10G #SBATCH -c 4 #SBATCH -t 5:0:0 #SBATCH --constraint \\&quot;s04|s05\\&quot; ./ldak5.1 --max-threads 4 \\ --window-prune 0.05 \\ --window-kb 1000 \\ --bfile ../gen/geno-mix \\ --chr $j \\ --thin ../thin/thin-chr$j &quot; &gt; sh_script/thin$j done for j in {1..22}; do sbatch -A snpher ../sh_script/thin$j done &gt; ../job-records/thin-snps #------------- # 2. kinship matrix under GCTA #------------- for pop in {black,asian}; do for j in {1..22}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --partition normal #SBATCH --mem 20G #SBATCH -c 3 #SBATCH -t 1:0:0 #SBATCH --constraint \\&quot;s04|s05\\&quot; ./ldak5.1 --max-threads 3 \\ --calc-kins-direct ../kinship/$pop-gcta-thin$j \\ --bfile ../gen/geno-mix \\ --keep ../overlap-$pop-complete-cov.id\\ --extract ../thin/thin-chr$j.in \\ --chr $j \\ --power -1 \\ --ignore-weights YES \\ --single YES &quot; &gt; sh_script/$pop-grm$j done done # submit files for pop in {black,asian}; do for j in {1..22}; do sbatch -A snpher ../sh_script/$pop-grm$j done done &gt; ../job-records/grm-pops # merge grms for pop in {black,asian}; do rm $pop-grm.list for j in {1..22} do echo &quot;../kinship/$pop-gcta-thin$j&quot; &gt;&gt; $pop-grm.list done done for pop in {black,asian}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 80G #SBATCH -c 10 #SBATCH -t 12:0:0 ./ldak5.1 --add-grm ../kinship/$pop-gcta-thin --mgrm ../$pop-grm.list &quot;&gt; sh_script/$pop-grm.sh done for pop in {black,asian}; do sbatch -A snpher ../sh_script/$pop-grm.sh done &gt; ../job-records/grm-merge #can now delete per-chr files #rm *gcta-thin{1..22}.* #----------------------- # 3. Relatedness filtering #------------------------ # relatedness filtering for pop in {asian,black};do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 20G #SBATCH -c 3 #SBATCH -t 2:0:0 ./ldak5.1 --filter ../relatedness/$pop-cut.05 \\ --grm ../kinship/$pop-gcta-thin \\ --max-rel 0.05 \\ --max-threads 3 &quot;&gt; sh_script/$pop-rel-cut.05.sh done # submit script for pop in {asian,black};do sbatch -A snpher ../sh_script/$pop-rel-cut.05.sh done &gt; ../job-records/relatedness-filtering # remaining individuals # asian-cut.05.keep N = 3,448 # black-cut.05.keep N = 3,024 # sum = 6,472 7.1.3 final list To match the good GWAS, we will have N = 100k in total and replace 6,472 whites with Asians and Blacks. # select shuf rand.100000 | head -n 93528 &gt; white.rand.93528 cat white.rand.93528 relatedness/asian-cut.05.keep relatedness/black-cut.05.keep &gt; mix-pop-gwas.id 7.2 GWAS-lm 7.2.1 basic cov We use basic covariates only: age, sex and townsend. # covariates-------------------------------------------------------------------- awk &#39;{print $1, $2, $3, $4, $5}&#39; covariates.use &gt; basic-covariates.use awk &#39;NR&lt;=5{print $0}&#39; covariates.use-names &gt; basic-covariates.use # gwas for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do for j in {1..22}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 8G #SBATCH -c 2 #SBATCH -t 5:0:0 ./ldak5.1 --linear ../gwas-mix/$i-linear-chr-$j \\ --pheno ../phen/continuous-traits/$i.raw.pheno \\ --bfile ../gen/geno-mix \\ --covar ../phen/basic-covariates.use \\ --keep ../mix-pop-gwas.id \\ --extract ../gen/snps-unrel-inds.use \\ --max-threads 2 \\ --chr $j &quot;&gt; sh_script/$i-linear-chr-$j.sh done done # --covar ../phen/covariates.use # submit files------------------------------------------------------------------ for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do for j in {1..22}; do sbatch -A snpher ../sh_script/$i-linear-chr-$j.sh done done&gt;../job-records/gwas-mix-pop # check job completion---------------------------------------------------------- file=job-records/gwas-mix-pop jobs=`awk &#39;{print $4}&#39; $file` mkdir $file-tmp for i in $jobs; do jobinfo $i | awk -F &quot;:&quot; -v i=$i &#39;$1~/Name/ {print i, $2}&#39; &gt;&gt; $file-tmp/name.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/State/ {print$2}&#39; &gt;&gt; $file-tmp/state.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Cores/ {print$2}&#39; &gt;&gt; $file-tmp/cores.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Used walltime/ {print $2 &quot;:&quot; $3 &quot;:&quot; $4}&#39; &gt;&gt; $file-tmp/time.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Max Mem/ {split($2,a,/[(]/ ); print a[1]}&#39; &gt;&gt; $file-tmp/mem.tmp done paste $file-tmp/name.tmp \\ $file-tmp/state.tmp \\ $file-tmp/cores.tmp \\ $file-tmp/time.tmp \\ $file-tmp/mem.tmp \\ | awk &#39;BEGIN{print &quot;ID name state cores time mem&quot;}{print $0}&#39; &gt; $file.out rm -r $file-tmp # combine results # only need .summaries &amp; .pvalues for i in {awake,bmi,quals,chron,ever,fvc,height,imp,neur,pulse,reaction,sbp,snoring,hyper}; do for j in {1..22}; do if [ $j == 1 ]; then awk &#39;{print $0}&#39; $i-linear-chr-$j.summaries &gt; $i-linear.summaries awk &#39;{print $0}&#39; $i-linear-chr-$j.pvalues &gt; $i-linear.pvalues else awk &#39;NR&gt;1 {print $0}&#39; $i-linear-chr-$j.summaries &gt;&gt; $i-linear.summaries awk &#39;NR&gt;1 {print $0}&#39; $i-linear-chr-$j.pvalues &gt;&gt; $i-linear.pvalues fi done done 7.2.2 basic cov + PC Here we add PC one at a time until the tenth as covariates and conduct GWAS # covariates-------------------------------------------------------------------- R options(scipen = 999) require(vroom) cov=vroom(&quot;phen/covariates.phen&quot;, col_names=T) nm=c(&quot;eid&quot;,&quot;age&quot;,&quot;sex_gen&quot;, &quot;townsend&quot;, paste0(&quot;pc&quot;,1:40)) cov=cov[,nm] for(i in 1:10){ sel=c(&quot;eid&quot;,&quot;eid&quot;,&quot;age&quot;,&quot;sex_gen&quot;, &quot;townsend&quot;, paste0(&quot;pc&quot;, 1:i)) out=cov[,sel] file1=paste0(&quot;phen/covariates-basic-&quot;,i,&quot;PC.use&quot;) file2=paste0(&quot;phen/covariates-basic-&quot;,i,&quot;PC.use-names&quot;) write.table(out,file1, col.names=F, row.names=F,quote=F) write.table(names(out),file2, col.names=F, row.names=F,quote=F) } # gwas-------------------------------------------------------------------------- for j in {1..10}; do mkdir gwas-mix-$j&#39;PC&#39; for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do out=../gwas-mix-$j&#39;PC&#39;/$i-linear cov=../phen/covariates-basic-$j&#39;PC&#39;.use echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 6G #SBATCH -c 2 #SBATCH -t 6:0:0 ./ldak5.1 --linear $out \\ --pheno ../phen/continuous-traits/$i.raw.pheno \\ --bfile ../gen/geno-mix \\ --covar $cov \\ --keep ../mix-pop-gwas.id \\ --extract ../gen/snps-unrel-inds.use \\ --max-threads 2 \\ &quot;&gt; sh_script/$i-linear-$j&#39;PC&#39;.sh done done # submit files------------------------------------------------------------------ for j in {1..10}; do for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do sbatch -A snpher ../sh_script/$i-linear-$j&#39;PC&#39;.sh done done&gt;../job-records/gwas-mix-pc # check job completion---------------------------------------------------------- file=job-records/gwas-mix-pc jobs=`awk &#39;{print $4}&#39; $file` mkdir $file-tmp for i in $jobs; do jobinfo $i | awk -F &quot;:&quot; -v i=$i &#39;$1~/Name/ {print i, $2}&#39; &gt;&gt; $file-tmp/name.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/State/ {print$2}&#39; &gt;&gt; $file-tmp/state.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Cores/ {print$2}&#39; &gt;&gt; $file-tmp/cores.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Used walltime/ {print $2 &quot;:&quot; $3 &quot;:&quot; $4}&#39; &gt;&gt; $file-tmp/time.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Max Mem/ {split($2,a,/[(]/ ); print a[1]}&#39; &gt;&gt; $file-tmp/mem.tmp done paste $file-tmp/name.tmp \\ $file-tmp/state.tmp \\ $file-tmp/cores.tmp \\ $file-tmp/time.tmp \\ $file-tmp/mem.tmp \\ | awk &#39;BEGIN{print &quot;ID name state cores time mem&quot;}{print $0}&#39; &gt; $file.out rm -r $file-tmp 7.3 GWAS-bolt-lmm Here we used linear mixed-effects models to test the association between genetic variants and phenotypes. The argument for the use of linear mixed-effects models is that it can account for the confounding effects from population stratification (check the rationale behind BLOT-LMM). Here we check if there is evidence of inflation in the chi-square test statistics from BOLT-LMM. As shown below, the slopes are sig. different from zero, but they are negative, indicating that chi-square test statistics decreases as aver2_j increases. Based on the plots (chisq ~ aver2_j), it seems that most large signals (i.e., large chisq test statistics) have an aver2_j close to zero, indicating that aver2_j (or fake tagging) does not drive the GWAS signals. However, how aver2_j relates to chisq of bolt-lmm seems different from how aver2_j relates to chisq of good gwas. # make filter files------------------------------------------------------------- fam=gen/geno-mix.fam bim=gen/geno-mix.bim id=mix-pop-gwas.id snp=gen/snps-unrel-inds.use id_remove=BOLT-LMM_v2.3.5/mix-pop-gwas-id.exclude snp_exclude=BOLT-LMM_v2.3.5/snps-unrel-inds.remove awk &#39;NR==FNR {a[$1];next} !($2 in a) {print $2}&#39; $snp $bim &gt; $snp_exclude # note the list is empty because $snp &amp; $bim contain the same list awk &#39;NR==FNR {a[$1];next} !($1 in a) {print $0}&#39; $id $fam &gt; $id_remove # organize phenotype files------------------------------------------------------ R options(scipen = 999) require(vroom) # covariate file cov=vroom(&quot;phen/covariates.phen&quot;, col_names=T) nm=c(&quot;age&quot;,&quot;sex_gen&quot;, &quot;townsend&quot; ,paste0(&quot;pc&quot;,1:40)) traits=c(&quot;awake&quot;,&quot;bmi&quot;,&quot;chron&quot;,&quot;ever&quot;, &quot;neur&quot;,&quot;pulse&quot;,&quot;quals&quot;, &quot;fvc&quot;, &quot;height&quot;,&quot;imp&quot;, &quot;reaction&quot;,&quot;sbp&quot;,&quot;snoring&quot;,&quot;hyper&quot;) for(i in 1:length(traits)){ trait=traits[i] dat=vroom(paste0(&quot;phen/continuous-traits/&quot;,trait,&quot;.raw.pheno&quot;), col_names=F) m=match(dat$X1,cov$eid) out=data.frame(FID=dat$X1, IID=dat$X2, PHENO=dat$X3, cov[m,nm]) old=names(out) new=c(names(out)[1:3], paste0(&quot;COV&quot;,1:43)) names(out)=new write.table(out,paste0(&quot;BOLT-LMM_v2.3.5/dat/&quot;,trait,&quot;.dat&quot;), col.names=T, row.names=F, quote=F) if(i==1){ out.nm=data.frame(name=new,true_name=old, stringsAsFactors=F) write.table(out.nm,&quot;BOLT-LMM_v2.3.5/dat/cov-names&quot;, col.names=T, row.names=F, quote=F) } } # model SNPs-------------------------------------------------------------------- # subset snps used in GRM for BOLT-LMM # we previously thinned SNPs: see &#39;relatedness filtering&#39; section of bad GWAS # Now we just merge them across chromsomes out=thin/geno-mix-thin-snps rm $out for i in {1..22}; do awk &#39;{print $0}&#39; thin/thin-chr$i.in &gt;&gt; $out done # run BOLT-LMM------------------------------------------------------------------ for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do dir=../gwas-bad echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 5G #SBATCH -c 10 #SBATCH -t 5:0:0 ../bolt --bfile=../gen/geno-mix \\ --phenoFile=../dat/$i.dat \\ --phenoCol=PHENO \\ --remove=../mix-pop-gwas-id.exclude\\ --lmm \\ --LDscoresFile=../tables/LDSCORE.1000G_EUR.tab.gz \\ --LDscoresMatchBp \\ --covarFile=../dat/$i.dat \\ --qCovarCol=COV{1:3}\\ --modelSnps=../geno-mix-thin-snps \\ --maxMissingPerSnp=1 \\ --maxMissingPerIndiv=1 \\ --statsFile=$dir/$i.out \\ --numThreads=10 \\ 2&gt;&amp;1 | tee $dir/$i.log &quot;&gt; sh_script/$i-bolt-lmm.sh done # submit scripts for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do sbatch -A snpher ../sh_script/$i-bolt-lmm.sh done&gt;../job-records/bolt-lmm-bad # check job completion---------------------------------------------------------- file=job-records/bolt-lmm-bad jobs=`awk &#39;{print $4}&#39; $file` mkdir $file-tmp for i in $jobs; do jobinfo $i | awk -F &quot;:&quot; -v i=$i &#39;$1~/Name/ {print i, $2}&#39; &gt;&gt; $file-tmp/name.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/State/ {print$2}&#39; &gt;&gt; $file-tmp/state.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Cores/ {print$2}&#39; &gt;&gt; $file-tmp/cores.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Used walltime/ {print $2 &quot;:&quot; $3 &quot;:&quot; $4}&#39; &gt;&gt; $file-tmp/time.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Max Mem/ {split($2,a,/[(]/ ); print a[1]}&#39; &gt;&gt; $file-tmp/mem.tmp done paste $file-tmp/name.tmp \\ $file-tmp/state.tmp \\ $file-tmp/cores.tmp \\ $file-tmp/time.tmp \\ $file-tmp/mem.tmp \\ | awk &#39;BEGIN{print &quot;ID name state cores time mem&quot;}{print $0}&#39; &gt; $file.out rm -r $file-tmp # organize results ------------------------------------------------------------- mkdir gwas-norm-337k-out for trait in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do gwas=gwas-norm-337k/$trait-linear.summaries aver2=summary/ave-r2-10k-snps-ukbb-norm out=gwas-norm-337k-out/$trait.out awk &#39;NR&gt;1 {print $1, $5}&#39; $gwas &gt; tmp/gwas.tmp awk &#39;NR==FNR {a[$1]; b[$1]=$2; next} {if ($1 in a) print b[$1]; else print &quot;NA&quot; }&#39; $aver2 tmp/gwas.tmp &gt; tmp/aver2.tmp # put info together paste tmp/gwas.tmp \\ tmp/aver2.tmp \\ | awk &#39;BEGIN{OFS=&quot;;&quot; ; print &quot;snp;chisq;aver2&quot;} {$1=$1}1&#39; &gt; $out done 7.4 chisq ~ aver2_j 7.4.1 calc aver2_j Note we previously computed aver2_j based using geno-mix data. see 12.5. Results are stored in summary/ave-r2-by-snp-badgwas 7.4.2 bolt-lmm # organize data ---------------------------------------------------------------- mkdir gwas-bolt-lmm-out for trait in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do gwas=BOLT-LMM_v2.3.5/gwas-bad/$trait.out aver2=summary/ave-r2-by-snp-badgwas out=gwas-bolt-lmm-out/$trait.out awk &#39;NR&gt;1 {print $1, ($9/$10)^2 }&#39; $gwas &gt; tmp/gwas.tmp awk &#39;NR==FNR {a[$1]; b[$1]=$2; next} {if ($1 in a) print b[$1]; else print &quot;NA&quot; }&#39; $aver2 tmp/gwas.tmp &gt; tmp/aver2.tmp # put info together paste tmp/gwas.tmp \\ tmp/aver2.tmp \\ | awk &#39;BEGIN{OFS=&quot;;&quot; ; print &quot;snp;chisq;aver2&quot;} {$1=$1}1&#39; &gt; $out done #:::::::::::::::::::::::::::::::::::::::::::::: # estimate slope: chisq ~ aver2_j #:::::::::::::::::::::::::::::::::::::::::::::: require(vroom) traits=c(&quot;awake&quot;,&quot;bmi&quot;,&quot;chron&quot;,&quot;ever&quot;, &quot;neur&quot;,&quot;pulse&quot;,&quot;quals&quot;, &quot;fvc&quot;, &quot;height&quot;,&quot;imp&quot;, &quot;reaction&quot;,&quot;sbp&quot;,&quot;snoring&quot;,&quot;hyper&quot;) for(i in 1:length(traits)){ trait=traits[i] file=paste0(&quot;gwas-bolt-lmm-out/&quot;,trait,&quot;.out&quot;) dat=vroom(file, col_names=T, delim=&quot;;&quot;) mod=lm(chisq ~ aver2,data=dat) slope0=data.frame(trait=trait, slope_aver2=coef(mod)[2], p_aver2=summary(mod)$coefficients[,4][2], stringsAsFactors = F) if(i==1){slope=slope0} else {slope=rbind(slope,slope0)} } #:::::::::::::::::::::::::::::::::::::::::::::: # plot chisq ~ aver2_j #:::::::::::::::::::::::::::::::::::::::::::::: # aver2_j bin------------------------------- require(vroom) traits=c(&quot;awake&quot;,&quot;bmi&quot;,&quot;chron&quot;,&quot;ever&quot;, &quot;neur&quot;,&quot;pulse&quot;,&quot;quals&quot;, &quot;fvc&quot;, &quot;height&quot;,&quot;imp&quot;, &quot;reaction&quot;,&quot;sbp&quot;,&quot;snoring&quot;,&quot;hyper&quot;) png(paste0(&quot;fig/chisq-by-aver2-bin-gwas-mix-bold-lmm.png&quot;), width = 50, height = 30, units = &quot;cm&quot;, res=600) par(mfrow=c(3,5)) for (i in 1:length(traits)){ trait=traits[i] file=paste0(&quot;gwas-bolt-lmm-out/&quot;,trait,&quot;.out&quot;) dat=vroom(file, col_names=T, delim=&quot;;&quot;) # bin a variable by quantile cutoff=quantile(dat$aver2, probs = seq(0, 1, 0.005), na.rm=T) dat$bin=cut(dat$aver2, breaks=cutoff, labels=1:(length(cutoff)-1)) # average chisq by bin values out=data.frame(chisq_ave=tapply(dat$chisq,INDEX=dat$bin, mean)) out$bin_val=tapply(dat$aver2,INDEX=dat$bin, mean) plot(out$bin_val, out$chisq_ave, xlab=&quot;ave r2&quot;, ylab=&quot;ave chisq&quot;, main=trait, las=1, cex = 1.5, pch=21, bg=&quot;orange&quot;, col=&quot;white&quot;, lwd=0.5) } dev.off() # raw aver2_j &amp; chisq------------------------------- require(vroom) traits=c(&quot;awake&quot;,&quot;bmi&quot;,&quot;chron&quot;,&quot;ever&quot;, &quot;neur&quot;,&quot;pulse&quot;,&quot;quals&quot;, &quot;fvc&quot;, &quot;height&quot;,&quot;imp&quot;, &quot;reaction&quot;,&quot;sbp&quot;,&quot;snoring&quot;,&quot;hyper&quot;) png(paste0(&quot;fig/chisq-by-aver2-bin-gwas-mix-bold-lmm-raw.png&quot;), width = 50, height = 30, units = &quot;cm&quot;, res=600) par(mfrow=c(3,5)) for (i in 1:length(traits)){ trait=traits[i] file=paste0(&quot;gwas-bolt-lmm-out/&quot;,trait,&quot;.out&quot;) dat=vroom(file, col_names=T, delim=&quot;;&quot;) out=dat[complete.cases(dat),] plot(out$aver2, out$chisq, xlab=&quot;r2&quot;, ylab=&quot;chisq&quot;, main=trait, las=1, cex = 1.5, pch=21, bg=&quot;gray&quot;, col=&quot;white&quot;, lwd=0.5) } dev.off() 7.4.3 basic cov + PC mkdir gwas-mix-pc-out for j in {1..10}; do for trait in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do gwas=gwas-mix-$j&#39;PC&#39;/$trait-linear.summaries aver2=summary/ave-r2-by-snp-badgwas out=gwas-mix-pc-out/$trait-$j&#39;PC&#39;.out awk &#39;NR&gt;1 {print $1, $5}&#39; $gwas &gt; tmp/gwas.tmp awk &#39;NR==FNR {a[$1]; b[$1]=$2; next} {if ($1 in a) print b[$1]; else print &quot;NA&quot; }&#39; $aver2 tmp/gwas.tmp &gt; tmp/aver2.tmp # put info together paste tmp/gwas.tmp \\ tmp/aver2.tmp \\ | awk &#39;BEGIN{OFS=&quot;;&quot; ; print &quot;snp;chisq;aver2&quot;} {$1=$1}1&#39; &gt; $out done done #:::::::::::::::::::::::::::::::::::::::::::::: # estimate slope: chisq ~ aver2_j #:::::::::::::::::::::::::::::::::::::::::::::: require(vroom) traits=c(&quot;awake&quot;,&quot;bmi&quot;,&quot;chron&quot;,&quot;ever&quot;, &quot;neur&quot;,&quot;pulse&quot;,&quot;quals&quot;, &quot;fvc&quot;, &quot;height&quot;,&quot;imp&quot;, &quot;reaction&quot;,&quot;sbp&quot;,&quot;snoring&quot;,&quot;hyper&quot;) for(j in 1:10){ for(i in 1:length(traits)){ trait=traits[i] file=paste0(&quot;gwas-mix-pc-out/&quot;,trait,&quot;-&quot;,j,&quot;PC.out&quot;) dat=vroom(file, col_names=T, delim=&quot;;&quot;) mod=lm(chisq ~ aver2,data=dat) slope0=data.frame(trait=trait, pc_up_to=j, slope_aver2=coef(mod)[2], p_aver2=summary(mod)$coefficients[,4][2], stringsAsFactors = F) if(i==1 &amp; j==1){slope=slope0} else {slope=rbind(slope,slope0)} } } #:::::::::::::::::::::::::::::::::::::::::::::: # plot chisq ~ aver2_j #:::::::::::::::::::::::::::::::::::::::::::::: # binned data------------------------------------------------------------------- require(vroom) traits=c(&quot;awake&quot;,&quot;bmi&quot;,&quot;chron&quot;,&quot;ever&quot;, &quot;neur&quot;,&quot;pulse&quot;,&quot;quals&quot;, &quot;fvc&quot;, &quot;height&quot;,&quot;imp&quot;, &quot;reaction&quot;,&quot;sbp&quot;,&quot;snoring&quot;,&quot;hyper&quot;) for(j in 1:10){ png(paste0(&quot;fig/chisq-by-aver2-bin-gwas-mix-&quot;,j,&quot;PC.png&quot;), width = 50, height = 30, units = &quot;cm&quot;, res=600) par(mfrow=c(3,5)) for (i in 1:length(traits)){ trait=traits[i] file=paste0(&quot;gwas-mix-pc-out/&quot;,trait,&quot;-&quot;,j,&quot;PC.out&quot;) dat=vroom(file, col_names=T, delim=&quot;;&quot;) # bin a variable by quantile cutoff=quantile(dat$aver2, probs = seq(0, 1, 0.005), na.rm=T) dat$bin=cut(dat$aver2, breaks=cutoff, labels=1:(length(cutoff)-1)) # average chisq by bin values out=data.frame(chisq_ave=tapply(dat$chisq,INDEX=dat$bin, mean)) out$bin_val=tapply(dat$aver2,INDEX=dat$bin, mean) plot(out$bin_val, out$chisq_ave, xlab=&quot;ave r2&quot;, ylab=&quot;ave chisq&quot;, main=trait, las=1, cex = 1.5, pch=21, bg=&quot;orange&quot;, col=&quot;white&quot;, lwd=0.5) } dev.off() } # raw data------------------------------------------------------------------- require(vroom) traits=c(&quot;awake&quot;,&quot;bmi&quot;,&quot;chron&quot;,&quot;ever&quot;, &quot;neur&quot;,&quot;pulse&quot;,&quot;quals&quot;, &quot;fvc&quot;, &quot;height&quot;,&quot;imp&quot;, &quot;reaction&quot;,&quot;sbp&quot;,&quot;snoring&quot;,&quot;hyper&quot;) for(j in 1:10){ png(paste0(&quot;fig/chisq-by-aver2-gwas-mix-&quot;,j,&quot;PC-raw.png&quot;), width = 50, height = 30, units = &quot;cm&quot;, res=600) par(mfrow=c(3,5)) for (i in 1:length(traits)){ trait=traits[i] file=paste0(&quot;gwas-mix-pc-out/&quot;,trait,&quot;-&quot;,j,&quot;PC.out&quot;) dat=vroom(file, col_names=T, delim=&quot;;&quot;) out=dat[complete.cases(dat),] plot(out$aver2, out$chisq, xlab=&quot;ave r2&quot;, ylab=&quot;ave chisq&quot;, main=trait, las=1, cex = 1.5, pch=21, bg=&quot;orange&quot;, col=&quot;white&quot;, lwd=0.5) } dev.off() } 7.5 ldsc intercept 7.5.1 under gcta #::::::::::::: # using original ldsc #::::::::::::: # format stats for ldsc--------------------------------------------------------- library(vroom) options(scipen = 100) rs=vroom(&quot;doug/ukbb.ldsc&quot;, col_names=F) phen=c(&quot;awake&quot;,&quot;bmi&quot;,&quot;chron&quot;,&quot;ever&quot;,&quot;fvc&quot;, &quot;height&quot;,&quot;imp&quot;,&quot;neur&quot;,&quot;pulse&quot;,&quot;quals&quot;, &quot;reaction&quot;,&quot;sbp&quot;,&quot;snoring&quot;,&quot;hyper&quot;, &quot;quals&quot;) for(i in phen){ stat=vroom(paste0(&quot;gwas-mix/&quot;,i,&quot;-linear.summaries&quot;), col_names=T) p=vroom(paste0(&quot;gwas-mix/&quot;,i,&quot;-linear.pvalues&quot;), col_names=T) m1=match(rs$X1, stat$Predictor) m2=match(rs$X1, p$Predictor) out=data.frame(SNP=rs$X2, N=stat$n[m1], Z=(sqrt(stat$Stat)*stat$Direction)[m1], A1=stat$A1[m1], A2=stat$A2[m1], pval=p$P[m2], stringsAsFactors=F) out=out[complete.cases(out),] write.table(out, paste0(&quot;gwas-mix/&quot;,i,&quot;-linear-rs.summaries&quot;), col.names=T, row.names=F, quote=F) } # perform ldsc------------------------------------------------------------------ mkdir out-mix-pop for i in {awake,bmi,chron,ever,fvc,height,quals,imp,neur,pulse,reaction,sbp,snoring,hyper}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 2G #SBATCH -c 3 #SBATCH -t 08:00:0 .././munge_sumstats.py \\ --sumstats ../../gwas-mix/$i-linear-rs.summaries \\ --out ../out-mix-pop/$i \\ --merge-alleles ../w_hm3.snplist .././ldsc.py \\ --h2 ../out-mix-pop/$i.sumstats.gz \\ --ref-ld-chr ../eur_w_ld_chr/ \\ --w-ld-chr ../eur_w_ld_chr/ \\ --out ../out-mix-pop/$i-ldsc &quot;&gt;sh_script/ldsc-$i-mix-pop.sh done # submit jobs------------------------------------------------------------------- for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,reaction,sbp,snoring,hyper,quals}; do sbatch -A snpher ../sh_script/ldsc-$i-mix-pop.sh done&gt;../../job-records/ldsc-mix-pop # check job completion---------------------------------------------------------- file=job-records/ldsc-mix-pop jobs=`awk &#39;{print $4}&#39; $file` mkdir $file-tmp for i in $jobs; do jobinfo $i | awk -F &quot;:&quot; -v i=$i &#39;$1~/Name/ {print i, $2}&#39; &gt;&gt; $file-tmp/name.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/State/ {print$2}&#39; &gt;&gt; $file-tmp/state.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Cores/ {print$2}&#39; &gt;&gt; $file-tmp/cores.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Used walltime/ {print $2 &quot;:&quot; $3 &quot;:&quot; $4}&#39; &gt;&gt; $file-tmp/time.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Max Mem/ {split($2,a,/[(]/ ); print a[1]}&#39; &gt;&gt; $file-tmp/mem.tmp done paste $file-tmp/name.tmp \\ $file-tmp/state.tmp \\ $file-tmp/cores.tmp \\ $file-tmp/time.tmp \\ $file-tmp/mem.tmp \\ | awk &#39;BEGIN{print &quot;ID name state cores time mem&quot;}{print $0}&#39; &gt; $file.out rm -r $file-tmp #::::::::::::: # using sumher #::::::::::::: # insert genetic distance into bim file----------------------------------------- # here we want to use the same genetic distance as for unrelated individuals, i.e., good GWAS R dat=read.table(&quot;gen/geno-mix.bim&quot;, header=F, stringsAsFactors=F) ref=read.table(&quot;gen/geno-unrel.bim&quot;, header=F, stringsAsFactors=F) m=match(dat$V2,ref$V2) out=data.frame(dat$V1, dat$V2, ref$V3[m], dat$V4, dat$V5, dat$V6, stringsAsFactors=F) write.table(out,&quot;gen/geno-mix.bim2&quot;, col.names=F, row.names=F, quote=F) mv geno-mix.bim geno-mix.bim0 mv geno-mix.bim2 geno-mix.bim # compute tagging under gcta---------------------------------------------------- for j in {1..22}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 5G #SBATCH -c 1 #SBATCH -t 5:0:0 ./ldak5.1 --calc-tagging ../tagging-mix-pop/gcta-hapmap3-chr-$j \\ --bfile ../gen/geno-mix \\ --ignore-weights YES \\ --power -1 \\ --window-cm 1 \\ --chr $j &quot;&gt; sh_script/tagging-gcta-hapmap3-chr$j done for j in {1..22}; do sbatch -A snpher ../sh_script/tagging-gcta-hapmap3-chr$j done &gt; ../job-records/tagging-gcta-hadmap3-mix-pop # check job completion---------------------------------------------------------- file=job-records/tagging-gcta-hadmap3-mix-pop jobs=`awk &#39;{print $4}&#39; $file` mkdir $file-tmp for i in $jobs; do jobinfo $i | awk -F &quot;:&quot; -v i=$i &#39;$1~/Name/ {print i, $2}&#39; &gt;&gt; $file-tmp/name.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/State/ {print$2}&#39; &gt;&gt; $file-tmp/state.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Cores/ {print$2}&#39; &gt;&gt; $file-tmp/cores.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Used walltime/ {print $2 &quot;:&quot; $3 &quot;:&quot; $4}&#39; &gt;&gt; $file-tmp/time.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Max Mem/ {split($2,a,/[(]/ ); print a[1]}&#39; &gt;&gt; $file-tmp/mem.tmp done paste $file-tmp/name.tmp \\ $file-tmp/state.tmp \\ $file-tmp/cores.tmp \\ $file-tmp/time.tmp \\ $file-tmp/mem.tmp \\ | awk &#39;BEGIN{print &quot;ID name state cores time mem&quot;}{print $0}&#39; &gt; $file.out rm -r $file-tmp # merge tagging files----------------------------------------------------------- rm list.txt for j in {1..22}; do echo &quot;tagging-mix-pop/gcta-hapmap3-chr-$j.tagging&quot; &gt;&gt; list.txt done ./ldak5.1 --join-tagging tagging-mix-pop/gcta-hapmap3 --taglist list.txt # ldsc intercept---------------------------------------------------------------- mkdir sumher-mix for i in {awake,bmi,chron,ever,fvc,height,quals,imp,neur,pulse,reaction,sbp,snoring,hyper}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 5G #SBATCH -c 1 #SBATCH -t 5:0:0 ./ldak5.1 --sum-hers ../sumher-mix/$i-sumher-gcta \\ --tagfile ../tagging-mix-pop/gcta-hapmap3.tagging \\ --summary ../gwas-mix/$i-linear.summaries \\ --check-sums NO \\ --intercept YES &quot;&gt; sh_script/$i-sumher-gcta-mix-pop done for i in {awake,bmi,chron,ever,fvc,height,quals,imp,neur,pulse,reaction,sbp,snoring,hyper}; do sbatch -A snpher ../sh_script/$i-sumher-gcta-mix-pop done&gt;../job-records/sumher-gcta-mix-pop # check job completion---------------------------------------------------------- file=job-records/sumher-gcta-mix-pop jobs=`awk &#39;{print $4}&#39; $file` mkdir $file-tmp for i in $jobs; do jobinfo $i | awk -F &quot;:&quot; -v i=$i &#39;$1~/Name/ {print i, $2}&#39; &gt;&gt; $file-tmp/name.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/State/ {print$2}&#39; &gt;&gt; $file-tmp/state.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Cores/ {print$2}&#39; &gt;&gt; $file-tmp/cores.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Used walltime/ {print $2 &quot;:&quot; $3 &quot;:&quot; $4}&#39; &gt;&gt; $file-tmp/time.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Max Mem/ {split($2,a,/[(]/ ); print a[1]}&#39; &gt;&gt; $file-tmp/mem.tmp done paste $file-tmp/name.tmp \\ $file-tmp/state.tmp \\ $file-tmp/cores.tmp \\ $file-tmp/time.tmp \\ $file-tmp/mem.tmp \\ | awk &#39;BEGIN{print &quot;ID name state cores time mem&quot;}{print $0}&#39; &gt; $file.out rm -r $file-tmp 7.5.2 under ldak-thin # get weights------------------------------------------------------------------- awk &lt; ldak-thin/ldak-thin-hapmap3.in &#39;{print $1, 1}&#39; &gt; ldak-thin/weights.ldak-thin-hapmap3 # calculate tagging under ldak-thin--------------------------------------------- for j in {1..22}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --partition normal #SBATCH --mem 40G #SBATCH -c 5 #SBATCH -t 10:0:0 #SBATCH --constraint \\&quot;s04|s05\\&quot; ./ldak5.1 --calc-tagging ../tagging-mix-pop/ldak-thin-hapmap3-chr-$j \\ --bfile ../gen/geno-mix \\ --weights ../ldak-thin/weights.ldak-thin-hapmap3 \\ --power -.25 \\ --window-cm 1 \\ --chr $j \\ --save-matrix YES \\ --max-threads 5 &quot; &gt; sh_script/tagging-ldak-thin-hapmap3-chr$j.sh done # submit scripts for j in {1..22}; do sbatch -A snpher ../sh_script/tagging-ldak-thin-hapmap3-chr$j.sh done &gt; ../job-records/tagging-ldak-thin-hapmap3 # check job completion---------------------------------------------------------- file=job-records/tagging-ldak-thin-hapmap3 jobs=`awk &#39;{print $4}&#39; $file` mkdir $file-tmp for i in $jobs; do jobinfo $i | awk -F &quot;:&quot; -v i=$i &#39;$1~/Name/ {print i, $2}&#39; &gt;&gt; $file-tmp/name.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/State/ {print$2}&#39; &gt;&gt; $file-tmp/state.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Cores/ {print$2}&#39; &gt;&gt; $file-tmp/cores.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Used walltime/ {print $2 &quot;:&quot; $3 &quot;:&quot; $4}&#39; &gt;&gt; $file-tmp/time.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Max Mem/ {split($2,a,/[(]/ ); print a[1]}&#39; &gt;&gt; $file-tmp/mem.tmp done paste $file-tmp/name.tmp \\ $file-tmp/state.tmp \\ $file-tmp/cores.tmp \\ $file-tmp/time.tmp \\ $file-tmp/mem.tmp \\ | awk &#39;BEGIN{print &quot;ID name state cores time mem&quot;}{print $0}&#39; &gt; $file.out rm -r $file-tmp # merge tagging files----------------------------------------------------------- rm list.txt rm matlist.txt for j in {1..22}; do echo &quot;tagging-mix-pop/ldak-thin-hapmap3-chr-$j.tagging&quot; &gt;&gt; list.txt echo &quot;tagging-mix-pop/ldak-thin-hapmap3-chr-$j.matrix&quot; &gt;&gt; matlist.txt done ./ldak5.1 --join-tagging tagging-mix-pop/ldak-thin-hapmap3 --taglist list.txt --matlist matlist.txt # ldsc intercept---------------------------------------------------------------- for i in {awake,bmi,chron,ever,fvc,height,quals,imp,neur,pulse,reaction,sbp,snoring,hyper}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 5G #SBATCH -c 1 #SBATCH -t 00:30:0 ./ldak5.1 --sum-hers ../sumher-mix/$i-sumher-ldak-thin \\ --tagfile ../tagging-mix-pop/ldak-thin-hapmap3.tagging \\ --summary ../gwas-mix/$i-linear.summaries \\ --check-sums NO \\ --intercept YES &quot;&gt; sh_script/$i-sumher-ldak-thin-mix done for i in {awake,bmi,chron,ever,fvc,height,quals,imp,neur,pulse,reaction,sbp,snoring,hyper}; do sbatch -A snpher ../sh_script/$i-sumher-ldak-thin-mix done&gt;../job-records/sumher-ldak-thin-mix # check job-completion file=job-records/sumher-ldak-thin-mix jobs=`awk &#39;{print $4}&#39; $file` mkdir $file-tmp for i in $jobs; do jobinfo $i | awk -F &quot;:&quot; -v i=$i &#39;$1~/Name/ {print i, $2}&#39; &gt;&gt; $file-tmp/name.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/State/ {print$2}&#39; &gt;&gt; $file-tmp/state.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Cores/ {print$2}&#39; &gt;&gt; $file-tmp/cores.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Used walltime/ {print $2 &quot;:&quot; $3 &quot;:&quot; $4}&#39; &gt;&gt; $file-tmp/time.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Max Mem/ {split($2,a,/[(]/ ); print a[1]}&#39; &gt;&gt; $file-tmp/mem.tmp done paste $file-tmp/name.tmp \\ $file-tmp/state.tmp \\ $file-tmp/cores.tmp \\ $file-tmp/time.tmp \\ $file-tmp/mem.tmp \\ | awk &#39;BEGIN{print &quot;ID name state cores time mem&quot;}{print $0}&#39; &gt; $file.out rm -r $file-tmp 7.5.3 summary # without 40 PCs---------------------------------------------------------------------- # original ldsc grep Intercept *ldsc.log | awk &#39;{split($1, a, /[-]/); split($3, b, /[()]/); print a[1], $2, b[2]}&#39; &gt; ../../summary/ldsc-mix # sumher under gcta grep Intercept_Estimate *gcta.extra | awk &#39;{ split($1, a, /[-]/); print a[1], $2}&#39; &gt;../summary/sumher-gcta-mix-est grep Intercept_SD *gcta.extra | awk &#39;{ split($1, a, /[-]/); print a[1], $2}&#39; &gt;../summary/sumher-gcta-mix-sd cd ../summary/ paste sumher-gcta-mix-est sumher-gcta-mix-sd | awk &#39;{print $1, $2, $4}&#39; &gt; sumher-gcta-mix rm sumher-gcta-mix-sd sumher-gcta-mix-est # suhmer under ldak-thin grep Intercept_Estimate *ldak-thin.extra | awk &#39;{ split($1, a, /[-]/); print a[1], $2}&#39; &gt;../summary/sumher-ldak-thin-mix-est grep Intercept_SD *ldak-thin.extra | awk &#39;{ split($1, a, /[-]/); print a[1], $2}&#39; &gt;../summary/sumher-ldak-thin-mix-sd cd ../summary/ paste sumher-ldak-thin-mix-est sumher-ldak-thin-mix-sd | awk &#39;{print $1, $2, $4}&#39; &gt; sumher-ldak-thin-mix rm sumher-ldak-thin-mix-sd sumher-ldak-thin-mix-est # with covariates (i.e., including all 40 PCs)------------------------------------------- # original ldsc grep Intercept *ldsc.log | awk &#39;{split($1, a, /[-]/); split($3, b, /[()]/); print a[1], $2, b[2]}&#39; &gt; ../../summary/ldsc-mix-with-cov # sumher under gcta grep Intercept_Estimate *gcta.extra | awk &#39;{ split($1, a, /[-]/); print a[1], $2}&#39; &gt;../summary/sumher-gcta-mix-est grep Intercept_SD *gcta.extra | awk &#39;{ split($1, a, /[-]/); print a[1], $2}&#39; &gt;../summary/sumher-gcta-mix-sd cd ../summary/ paste sumher-gcta-mix-est sumher-gcta-mix-sd | awk &#39;{print $1, $2, $4}&#39; &gt; sumher-gcta-mix-with-cov rm sumher-gcta-mix-sd sumher-gcta-mix-est # suhmer under ldak-thin grep Intercept_Estimate *ldak-thin.extra | awk &#39;{ split($1, a, /[-]/); print a[1], $2}&#39; &gt;../summary/sumher-ldak-thin-mix-est grep Intercept_SD *ldak-thin.extra | awk &#39;{ split($1, a, /[-]/); print a[1], $2}&#39; &gt;../summary/sumher-ldak-thin-mix-sd cd ../summary/ paste sumher-ldak-thin-mix-est sumher-ldak-thin-mix-sd | awk &#39;{print $1, $2, $4}&#39; &gt; sumher-ldak-thin-mix-with-cov rm sumher-ldak-thin-mix-sd sumher-ldak-thin-mix-est 7.6 REML 7.6.1 making grms # making grm ------------------------------------------------------------------- #::: # under gcta #::: # all snps echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --partition normal #SBATCH --mem 120G #SBATCH -c 10 #SBATCH -t 20:0:0 #SBATCH --constraint \\&quot;s04|s05\\&quot; ./ldak5.1 --max-threads 10 \\ --calc-kins-direct ../kinship/gcta-all-mix \\ --bfile ../gen/geno-mix \\ --keep ../mix-pop-gwas.id \\ --power -1 \\ --ignore-weights YES \\ --single YES &quot; &gt; sh_script/grm-all-snps-mix sbatch -A snpher ../sh_script/grm-all-snps-mix &gt; ../job-records/grm-all-snps-mix # grm by snp blocks: right vs. left awk &#39;$1&lt;8 {print $2}&#39; geno-mix.bim &gt; left-mix-pop.snps awk &#39;$1&gt;=8 {print $2}&#39; geno-mix.bim &gt; right-mix-pop.snps for i in left right; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --partition normal #SBATCH --mem 100G #SBATCH -c 10 #SBATCH -t 20:0:0 #SBATCH --constraint \\&quot;s04|s05\\&quot; ./ldak5.1 --max-threads 10 \\ --calc-kins-direct ../kinship/gcta-$i-mix \\ --bfile ../gen/geno-mix \\ --keep ../mix-pop-gwas.id \\ --extract ../gen/$i-mix-pop.snps \\ --power -1 \\ --ignore-weights YES \\ --single YES &quot; &gt; sh_script/grm-gcta-$i-mix done for i in left right; do sbatch -A snpher ../sh_script/grm-gcta-$i-mix done &gt; ../job-records/grm-gcta-by-snps-mix # check job completion---------------------------------------------------------- file=job-records/grm-gcta-by-snps-mix jobs=`awk &#39;{print $4}&#39; $file` mkdir $file-tmp for i in $jobs; do jobinfo $i | awk -F &quot;:&quot; -v i=$i &#39;$1~/Name/ {print i, $2}&#39; &gt;&gt; $file-tmp/name.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/State/ {print$2}&#39; &gt;&gt; $file-tmp/state.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Cores/ {print$2}&#39; &gt;&gt; $file-tmp/cores.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Used walltime/ {print $2 &quot;:&quot; $3 &quot;:&quot; $4}&#39; &gt;&gt; $file-tmp/time.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Max Mem/ {split($2,a,/[(]/ ); print a[1]}&#39; &gt;&gt; $file-tmp/mem.tmp done paste $file-tmp/name.tmp \\ $file-tmp/state.tmp \\ $file-tmp/cores.tmp \\ $file-tmp/time.tmp \\ $file-tmp/mem.tmp \\ | awk &#39;BEGIN{print &quot;ID name state cores time mem&quot;}{print $0}&#39; &gt; $file.out rm -r $file-tmp #::: # under ldak-thin #::: #----------- # 1. thin snps #----------- # we omit this step and use ldak-thin/ldak-thin-hapmap3.in, which was created previously # using geno-unrel bfiles. See above. #---------------------- # 2. kinship matrix under ldak-thin #------------------------ echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --partition normal #SBATCH --mem 100G #SBATCH -c 10 #SBATCH -t 20:0:0 #SBATCH --constraint \\&quot;s04|s05\\&quot; ./ldak5.1 --max-threads 10 \\ --calc-kins-direct ../kinship/ldak-thin-all-mix \\ --bfile ../gen/geno-mix \\ --keep ../mix-pop-gwas.id \\ --extract ../ldak-thin/ldak-thin-hapmap3.in \\ --power -0.25 \\ --ignore-weights YES \\ --single YES &quot; &gt; sh_script/ldak-thin-grm-all-snps-mix sbatch -A snpher ../sh_script/ldak-thin-grm-all-snps-mix&gt; ../job-records/ldak-thin-grm-all-snps-mix # grm by snp blocks: right vs. left awk &#39;{split($1, a, /[:]/); if (a[1]&lt;8) print $1}&#39; \\ ldak-thin/ldak-thin-hapmap3.in &gt; gen/left-ldak-thin-hapmap3.snps awk &#39;{split($1, a, /[:]/); if (a[1]&gt;=8) print $1}&#39; \\ ldak-thin/ldak-thin-hapmap3.in &gt; gen/right-ldak-thin-hapmap3.snps for i in left right; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --partition normal #SBATCH --mem 100G #SBATCH -c 10 #SBATCH -t 20:0:0 #SBATCH --constraint \\&quot;s04|s05\\&quot; ./ldak5.1 --max-threads 10 \\ --calc-kins-direct ../kinship/ldak-thin-$i-mix \\ --bfile ../gen/geno-mix \\ --keep ../mix-pop-gwas.id \\ --extract ../gen/$i-ldak-thin-hapmap3.snps \\ --power -0.25 \\ --ignore-weights YES \\ --single YES &quot; &gt; sh_script/ldak-thin-grm-$i-mix done for i in left right; do sbatch -A snpher ../sh_script/ldak-thin-grm-$i-mix done &gt; ../job-records/grm-ldak-thin-by-snps-mix # check job completion---------------------------------------------------------- file=job-records/grm-ldak-thin-by-snps-mix jobs=`awk &#39;{print $4}&#39; $file` mkdir $file-tmp for i in $jobs; do jobinfo $i | awk -F &quot;:&quot; -v i=$i &#39;$1~/Name/ {print i, $2}&#39; &gt;&gt; $file-tmp/name.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/State/ {print$2}&#39; &gt;&gt; $file-tmp/state.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Cores/ {print$2}&#39; &gt;&gt; $file-tmp/cores.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Used walltime/ {print $2 &quot;:&quot; $3 &quot;:&quot; $4}&#39; &gt;&gt; $file-tmp/time.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Max Mem/ {split($2,a,/[(]/ ); print a[1]}&#39; &gt;&gt; $file-tmp/mem.tmp done paste $file-tmp/name.tmp \\ $file-tmp/state.tmp \\ $file-tmp/cores.tmp \\ $file-tmp/time.tmp \\ $file-tmp/mem.tmp \\ | awk &#39;BEGIN{print &quot;ID name state cores time mem&quot;}{print $0}&#39; &gt; $file.out rm -r $file-tmp 7.6.2 fast-reml #::: # under gcta #::: # make script files------------------------------------------------------------- mkdir reml-mix for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do for k in all left right; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 100G #SBATCH -c 2 #SBATCH -t 5:0:0 ./ldak5.1 --fast-reml ../reml-mix/$i-gcta-$k \\ --repetitions 20 \\ --pheno ../phen/continuous-traits/$i.raw.pheno \\ --covar ../phen/basic-covariates.use \\ --grm ../kinship/gcta-$k-mix \\ --max-threads 2 \\ --single YES &quot;&gt; sh_script/$i-reml-mix-gcta-$k-snps done done # submit script files----------------------------------------------------------- for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do for k in all left right; do sbatch -A snpher ../sh_script/$i-reml-mix-gcta-$k-snps done done&gt;../job-records/reml-mix-gcta # check job completion---------------------------------------------------------- file=job-records/reml-mix-gcta jobs=`awk &#39;{print $4}&#39; $file` mkdir $file-tmp for i in $jobs; do jobinfo $i | awk -F &quot;:&quot; -v i=$i &#39;$1~/Name/ {print i, $2}&#39; &gt;&gt; $file-tmp/name.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/State/ {print$2}&#39; &gt;&gt; $file-tmp/state.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Cores/ {print$2}&#39; &gt;&gt; $file-tmp/cores.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Used walltime/ {print $2 &quot;:&quot; $3 &quot;:&quot; $4}&#39; &gt;&gt; $file-tmp/time.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Max Mem/ {split($2,a,/[(]/ ); print a[1]}&#39; &gt;&gt; $file-tmp/mem.tmp done paste $file-tmp/name.tmp \\ $file-tmp/state.tmp \\ $file-tmp/cores.tmp \\ $file-tmp/time.tmp \\ $file-tmp/mem.tmp \\ | awk &#39;BEGIN{print &quot;ID name state cores time mem&quot;}{print $0}&#39; &gt; $file.out rm -r $file-tmp # cancel jobs for i in {1..14}; do job=`awk -v i=$i &#39;NR==i{print $0}&#39; kill-jobs` scancel $job done #::: # under ldak-thin #::: # make script files------------------------------------------------------------- for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do for k in all left right; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 100G #SBATCH -c 2 #SBATCH -t 5:0:0 ./ldak5.1 --fast-reml ../reml-mix/$i-ldak-thin-$k \\ --repetitions 20 \\ --pheno ../phen/continuous-traits/$i.raw.pheno \\ --covar ../phen/basic-covariates.use \\ --grm ../kinship/ldak-thin-$k-mix \\ --max-threads 2 \\ --single YES &quot;&gt; sh_script/$i-reml-mix-ldak-thin-$k-snps done done # submit script files----------------------------------------------------------- for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do for k in all left right; do sbatch -A snpher ../sh_script/$i-reml-mix-ldak-thin-$k-snps done done &gt;../job-records/reml-mix-ldak-thin # check job completion---------------------------------------------------------- file=job-records/reml-mix-ldak-thin jobs=`awk &#39;{print $4}&#39; $file` mkdir $file-tmp for i in $jobs; do jobinfo $i | awk -F &quot;:&quot; -v i=$i &#39;$1~/Name/ {print i, $2}&#39; &gt;&gt; $file-tmp/name.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/State/ {print$2}&#39; &gt;&gt; $file-tmp/state.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Cores/ {print$2}&#39; &gt;&gt; $file-tmp/cores.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Used walltime/ {print $2 &quot;:&quot; $3 &quot;:&quot; $4}&#39; &gt;&gt; $file-tmp/time.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Max Mem/ {split($2,a,/[(]/ ); print a[1]}&#39; &gt;&gt; $file-tmp/mem.tmp done paste $file-tmp/name.tmp \\ $file-tmp/state.tmp \\ $file-tmp/cores.tmp \\ $file-tmp/time.tmp \\ $file-tmp/mem.tmp \\ | awk &#39;BEGIN{print &quot;ID name state cores time mem&quot;}{print $0}&#39; &gt; $file.out rm -r $file-tmp 7.6.3 inflation test #:::::::::::: # under gcta #:::::::::::: # extract h2 estimates --------------------------------------------------------- # right for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do outfile=reml-mix/$i-gcta-right.reml awk -v i=$i &#39;$1==&quot;Her_All&quot; {print i, $2, $3}&#39; $outfile &gt;&gt; summary/est.tmp awk &#39;$1==&quot;Converged&quot; {print$2}&#39; $outfile &gt;&gt; summary/converge.tmp done paste summary/est.tmp \\ summary/converge.tmp \\ | awk &#39;BEGIN{print &quot;code h2 se converge&quot;}{print i, $0}&#39; \\ &gt; summary/reml-gcta-mix.right rm summary/est.tmp summary/converge.tmp # left for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do outfile=reml-mix/$i-gcta-left.reml awk -v i=$i &#39;$1==&quot;Her_All&quot; {print i, $2, $3}&#39; $outfile &gt;&gt; summary/est.tmp awk &#39;$1==&quot;Converged&quot; {print$2}&#39; $outfile &gt;&gt; summary/converge.tmp done paste summary/est.tmp \\ summary/converge.tmp \\ | awk &#39;BEGIN{print &quot;code h2 se converge&quot;}{print i, $0}&#39; \\ &gt; summary/reml-gcta-mix.left rm summary/est.tmp summary/converge.tmp # all for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do outfile=reml-mix/$i-gcta-all.reml awk -v i=$i &#39;$1==&quot;Her_All&quot; {print i, $2, $3}&#39; $outfile &gt;&gt; summary/est.tmp awk &#39;$1==&quot;Converged&quot; {print$2}&#39; $outfile &gt;&gt; summary/converge.tmp done paste summary/est.tmp \\ summary/converge.tmp \\ | awk &#39;BEGIN{print &quot;code h2 se converge&quot;}{print i, $0}&#39; \\ &gt; summary/reml-gcta-mix.all rm summary/est.tmp summary/converge.tmp # inflation test---------------------------------------------------------------- R full=read.table(paste0(&quot;summary/reml-gcta-mix.all&quot;), header=T) left=read.table(paste0(&quot;summary/reml-gcta-mix.left&quot;), header=T) right=read.table(paste0(&quot;summary/reml-gcta-mix.right&quot;), header=T) # some analyses did not complete --&gt; match dataframes dim(full);dim(left);dim(right) common=intersect(full$code, left$code) common=intersect(common, right$code) m1=match(common, right$code) m2=match(common, full$code) m3=match(common, left$code) right=right[m1,] full=full[m2,] left=left[m3,] for(i in 1:dim(full)[1]){ est1=left$h2[i] sd1=left$se[i] est2=right$h2[i] sd2=right$se[i] est=full$h2[i] sd=full$se[i] N=100000 d1=rnorm(N,est1,sd1) d2=rnorm(N,est2,sd2) d=rnorm(N,est,sd) p=1-mean(d1+d2-d&gt;=0) out0=data.frame(code=full$code[i], right_est=est2, right_sd=sd2, left_est=est1, left_sd=sd1, all_est=est, all_sd=sd, p_inflation=p) if(i==1){out=out0}else{out=rbind(out,out0)} } write.table(out, paste0(&quot;summary/reml-gcta-inflation-mix-gwas.txt&quot;), col.names=T, row.names=F, quote=F) #:::::::::::: # under ldak-thin #:::::::::::: # extract h2 estimates --------------------------------------------------------- # right for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do outfile=reml-mix/$i-ldak-thin-right.reml awk -v i=$i &#39;$1==&quot;Her_All&quot; {print i, $2, $3}&#39; $outfile &gt;&gt; summary/est.tmp awk &#39;$1==&quot;Converged&quot; {print$2}&#39; $outfile &gt;&gt; summary/converge.tmp done paste summary/est.tmp \\ summary/converge.tmp \\ | awk &#39;BEGIN{print &quot;code h2 se converge&quot;}{print i, $0}&#39; \\ &gt; summary/reml-ldak-thin-mix.right rm summary/est.tmp summary/converge.tmp # left for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do outfile=reml-mix/$i-ldak-thin-left.reml awk -v i=$i &#39;$1==&quot;Her_All&quot; {print i, $2, $3}&#39; $outfile &gt;&gt; summary/est.tmp awk &#39;$1==&quot;Converged&quot; {print$2}&#39; $outfile &gt;&gt; summary/converge.tmp done paste summary/est.tmp \\ summary/converge.tmp \\ | awk &#39;BEGIN{print &quot;code h2 se converge&quot;}{print i, $0}&#39; \\ &gt; summary/reml-ldak-thin-mix.left rm summary/est.tmp summary/converge.tmp # all for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do outfile=reml-mix/$i-ldak-thin-all.reml awk -v i=$i &#39;$1==&quot;Her_All&quot; {print i, $2, $3}&#39; $outfile &gt;&gt; summary/est.tmp awk &#39;$1==&quot;Converged&quot; {print$2}&#39; $outfile &gt;&gt; summary/converge.tmp done paste summary/est.tmp \\ summary/converge.tmp \\ | awk &#39;BEGIN{print &quot;code h2 se converge&quot;}{print i, $0}&#39; \\ &gt; summary/reml-ldak-thin-mix.all rm summary/est.tmp summary/converge.tmp # inflation test---------------------------------------------------------------- R full=read.table(paste0(&quot;summary/reml-ldak-thin-mix.all&quot;), header=T) left=read.table(paste0(&quot;summary/reml-ldak-thin-mix.left&quot;), header=T) right=read.table(paste0(&quot;summary/reml-ldak-thin-mix.right&quot;), header=T) # some analyses did not complete --&gt; match dataframes dim(full);dim(left);dim(right) common=intersect(full$code, left$code) common=intersect(common, right$code) m1=match(common, right$code) m2=match(common, full$code) m3=match(common, left$code) right=right[m1,] full=full[m2,] left=left[m3,] for(i in 1:dim(full)[1]){ est1=left$h2[i] sd1=left$se[i] est2=right$h2[i] sd2=right$se[i] est=full$h2[i] sd=full$se[i] N=100000 d1=rnorm(N,est1,sd1) d2=rnorm(N,est2,sd2) d=rnorm(N,est,sd) p=1-mean(d1+d2-d&gt;=0) out0=data.frame(code=full$code[i], right_est=est2, right_sd=sd2, left_est=est1, left_sd=sd1, all_est=est, all_sd=sd, p_inflation=p) if(i==1){out=out0}else{out=rbind(out,out0)} } write.table(out, paste0(&quot;summary/reml-ldak-thin-inflation-mix-gwas.txt&quot;), col.names=T, row.names=F, quote=F) 7.7 HE 7.7.1 estimation # regress grm on covariates----------------------------------------------------- for grm in gcta-all-mix gcta-left-mix gcta-right-mix ldak-thin-all-mix ldak-thin-left-mix ldak-thin-right-mix; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 50G #SBATCH -c 5 #SBATCH -t 10:0:0 ./ldak5.1 --adjust-grm ../kinship/$grm.covar \\ --grm ../kinship/$grm \\ --covar ../phen/basic-covariates.use \\ --max-threads 5 &quot;&gt; sh_script/$grm-adjust.sh done # submit jobs for grm in gcta-all-mix gcta-left-mix gcta-right-mix ldak-thin-all-mix ldak-thin-left-mix ldak-thin-right-mix; do sbatch -A snpher ../sh_script/$grm-adjust.sh done &gt; ../job-records/grm-adjust-for-HE # check job completion---------------------------------------------------------- file=job-records/grm-adjust-for-HE jobs=`awk &#39;{print $4}&#39; $file` mkdir $file-tmp for i in $jobs; do jobinfo $i | awk -F &quot;:&quot; -v i=$i &#39;$1~/Name/ {print i, $2}&#39; &gt;&gt; $file-tmp/name.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/State/ {print$2}&#39; &gt;&gt; $file-tmp/state.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Cores/ {print$2}&#39; &gt;&gt; $file-tmp/cores.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Used walltime/ {print $2 &quot;:&quot; $3 &quot;:&quot; $4}&#39; &gt;&gt; $file-tmp/time.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Max Mem/ {split($2,a,/[(]/ ); print a[1]}&#39; &gt;&gt; $file-tmp/mem.tmp done paste $file-tmp/name.tmp \\ $file-tmp/state.tmp \\ $file-tmp/cores.tmp \\ $file-tmp/time.tmp \\ $file-tmp/mem.tmp \\ | awk &#39;BEGIN{print &quot;ID name state cores time mem&quot;}{print $0}&#39; &gt; $file.out rm -r $file-tmp # HE under gcta----------------------------------------------------------------- for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do for k in all left right; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 2G #SBATCH -c 1 #SBATCH -t 00:30:0 ./ldak5.1 --he ../he-mix/$i-he-gcta-$k \\ --pheno ../phen/continuous-traits/$i.raw.pheno \\ --grm ../kinship/gcta-$k-mix.covar \\ --kinship-details NO \\ --check-root NO \\ --covar ../phen/basic-covariates.use \\ --max-threads 1 \\ --memory-save YES &quot;&gt; sh_script/$i-he-gcta-$k-snps.sh done done # submit files------------------------------------------------------------------ for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do for k in all left right; do sbatch -A snpher ../sh_script/$i-he-gcta-$k-snps.sh done done &gt; ../job-records/he-gcta # HE under ldak-thin------------------------------------------------------------ for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do for k in all left right; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 2G #SBATCH -c 1 #SBATCH -t 0:30:0 ./ldak5.1 --he ../he-mix/$i-he-ldak-thin-$k \\ --pheno ../phen/continuous-traits/$i.raw.pheno \\ --grm ../kinship/ldak-thin-$k-mix.covar \\ --kinship-details NO \\ --check-root NO \\ --covar ../phen/basic-covariates.use \\ --max-threads 1 \\ --memory-save YES &quot;&gt; sh_script/$i-he-ldak-thin-$k-snps.sh done done # submit files------------------------------------------------------------------ for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do for k in all left right; do sbatch -A snpher ../sh_script/$i-he-ldak-thin-$k-snps.sh done done &gt; ../job-records/he-ldak-thin 7.7.2 summary #:::::::::::: # under gcta #:::::::::::: # extract h2 estimates --------------------------------------------------------- # right rm summary/he-gcta-mix.right for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do outfile=he-mix/$i-he-gcta-right.he awk -v i=$i &#39;$1==&quot;Her_All&quot; {print i, $2, $3}&#39; $outfile &gt;&gt; summary/he-gcta-mix.right done # left rm summary/he-gcta-mix.left for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do outfile=he-mix/$i-he-gcta-left.he awk -v i=$i &#39;$1==&quot;Her_All&quot; {print i, $2, $3}&#39; $outfile &gt;&gt; summary/he-gcta-mix.left done # all rm summary/he-gcta-mix.all for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do outfile=he-mix/$i-he-gcta-all.he awk -v i=$i &#39;$1==&quot;Her_All&quot; {print i, $2, $3}&#39; $outfile &gt;&gt; summary/he-gcta-mix.all done # inflation test---------------------------------------------------------------- R full=read.table(paste0(&quot;summary/he-gcta-mix.all&quot;), header=F) left=read.table(paste0(&quot;summary/he-gcta-mix.left&quot;), header=F) right=read.table(paste0(&quot;summary/he-gcta-mix.right&quot;), header=F) names(full)=names(left)=names(right)=c(&quot;code&quot;,&quot;h2&quot;,&quot;se&quot;) # some analyses did not complete --&gt; match dataframes dim(full);dim(left);dim(right) common=intersect(full$code, left$code) common=intersect(common, right$code) m1=match(common, right$code) m2=match(common, full$code) m3=match(common, left$code) right=right[m1,] full=full[m2,] left=left[m3,] for(i in 1:dim(full)[1]){ est1=left$h2[i] sd1=left$se[i] est2=right$h2[i] sd2=right$se[i] est=full$h2[i] sd=full$se[i] N=100000 d1=rnorm(N,est1,sd1) d2=rnorm(N,est2,sd2) d=rnorm(N,est,sd) p=1-mean(d1+d2-d&gt;=0) out0=data.frame(code=full$code[i], right_est=est2, right_sd=sd2, left_est=est1, left_sd=sd1, all_est=est, all_sd=sd, p_inflation=p) if(i==1){out=out0}else{out=rbind(out,out0)} } write.table(out, paste0(&quot;summary/he-gcta-inflation-mix-gwas.txt&quot;), col.names=T, row.names=F, quote=F) #:::::::::::: # under ldak-thin #:::::::::::: # extract h2 estimates --------------------------------------------------------- # right rm summary/he-ldak-thin-mix.right for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do outfile=he-mix/$i-he-ldak-thin-right.he awk -v i=$i &#39;$1==&quot;Her_All&quot; {print i, $2, $3}&#39; $outfile &gt;&gt; summary/he-ldak-thin-mix.right done # left rm summary/he-ldak-thin-mix.left for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do outfile=he-mix/$i-he-ldak-thin-left.he awk -v i=$i &#39;$1==&quot;Her_All&quot; {print i, $2, $3}&#39; $outfile &gt;&gt; summary/he-ldak-thin-mix.left done # all rm summary/he-ldak-thin-mix.all for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do outfile=he-mix/$i-he-gcta-all.he awk -v i=$i &#39;$1==&quot;Her_All&quot; {print i, $2, $3}&#39; $outfile &gt;&gt; summary/he-ldak-thin-mix.all done # inflation test---------------------------------------------------------------- R full=read.table(paste0(&quot;summary/he-ldak-thin-mix.all&quot;), header=F) left=read.table(paste0(&quot;summary/he-ldak-thin-mix.left&quot;), header=F) right=read.table(paste0(&quot;summary/he-ldak-thin-mix.right&quot;), header=F) names(full)=names(left)=names(right)=c(&quot;code&quot;,&quot;h2&quot;,&quot;se&quot;) # some analyses did not complete --&gt; match dataframes dim(full);dim(left);dim(right) common=intersect(full$code, left$code) common=intersect(common, right$code) m1=match(common, right$code) m2=match(common, full$code) m3=match(common, left$code) right=right[m1,] full=full[m2,] left=left[m3,] for(i in 1:dim(full)[1]){ est1=left$h2[i] sd1=left$se[i] est2=right$h2[i] sd2=right$se[i] est=full$h2[i] sd=full$se[i] N=100000 d1=rnorm(N,est1,sd1) d2=rnorm(N,est2,sd2) d=rnorm(N,est,sd) p=1-mean(d1+d2-d&gt;=0) out0=data.frame(code=full$code[i], right_est=est2, right_sd=sd2, left_est=est1, left_sd=sd1, all_est=est, all_sd=sd, p_inflation=p) if(i==1){out=out0}else{out=rbind(out,out0)} } write.table(out, paste0(&quot;summary/he-ldak-thin-inflation-mix-gwas.txt&quot;), col.names=T, row.names=F, quote=F) "],["ukbb.html", "8 UKBB recommended 8.1 total N = 337k 8.2 QC of hp3 SNPs 8.3 GWAS-100k 8.4 GWAS-337k 8.5 ldsc-100k 8.6 ldsc-337k 8.7 aver2_j-337k 8.8 HE", " 8 UKBB recommended 8.1 total N = 337k Here we want to identify the unrelated white individuals recommended by the UKBB. Email from Florian: “We restrict individuals to the ones used for computing the principal components (PCs) in the UK Biobank (Field 22020). These individuals are unrelated and have passed some quality control including removing samples with a missing rate on autosomes larger than 0.02, having a mismatch between inferred sex and self-reported sex, and outliers based on heterozygosity (more details can be found in section S3 of Bycroft et al. (2018)).” And the White British are from this: https://biobank.ctsu.ox.ac.uk/crystal/field.cgi?id=22006 So required data fields: PC: 22020 White british: 22006 options(scipen = 100) # extract data head=read.table(&quot;phen/ukb45861.header&quot;, sep=&quot;,&quot;, header=F, stringsAsFactors = F) # function to get the variables get=function(nm){ colnum=grep(nm,head,fixed=TRUE) out=data.frame(t(rbind(colnum, head[,colnum]))) names(out)=c(&quot;column&quot;, &quot;field&quot;) return (out) } # get the variables out=rbind(get(&#39;22020-0&#39;), # PC get(&#39;22006-0&#39;)) # white british write.table(out,&quot;phen/vars.colnum&quot;, col.names=F, row.names=F, sep=&quot;\\t&quot;, quote=F) # extract dat awk -F &#39;&quot;,&quot;&#39; &#39;(NR==FNR){a[$1];next}{printf &quot;%s\\&quot;&quot;, $1;for(i in a){printf &quot; \\&quot;%s\\&quot;&quot;, $i};printf &quot;\\n&quot;}&#39; phen/vars.colnum phen/ukb45861.csv &gt; phen/ukbb-recommended.dat # get the id list of the intersect of the two data fields dat=read.table(&quot;phen/ukbb-recommended.dat&quot;, header=T, stringsAsFactors=F) id1=dat$eid[dat$X22020.0.0==1 &amp; !is.na(dat$X22020.0.0)] id2=dat$eid[dat$X22006.0.0==1 &amp; !is.na(dat$X22006.0.0)] out=intersect(id1,id2) # N = 337,462 write.table(out, &quot;ukbb-recommend.id&quot;, col.names=F, row.names=F, quote=F) 8.2 QC of hp3 SNPs Here we do QC to 1.2M hapmap3 SNPs for the UKBB recommended individuals. # QC SNPs----------------------------------------------------------------------- # stating number of SNPs= 1,184,423 # note: at this stage, we use all UKBB recommended IDs # we will do a random selection of IDs later. for j in {1..22}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 20G #SBATCH -c 3 #SBATCH -t 1:0:0 ./plink2 --pfile ../gen/geno_plink/bhr$j \\ --keep ../ukbb-recommend.id \\ --extract ../doug/ukbb.ldsc \\ --hwe 0.0001 \\ --hard-call-threshold .05 \\ --mach-r2-filter 0.8 2 \\ --make-bed \\ --memory 20000 \\ --out ../gen/tmp/bhr$j-norm \\ --threads 3 &quot;&gt; sh_script/chr$j.sh done # submit jobs for j in {1..22}; do sbatch -A snpher ../sh_script/chr$j.sh done &gt; ../job-records/qc-norm # merge files rm bfile-norm.list for j in {1..22}; do echo &quot;../gen/tmp/bhr$j-norm&quot; &gt;&gt;bfile-norm.list done echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 20G #SBATCH -c 3 #SBATCH -t 20:0:0 ./ldak5.1 --make-bed ../gen/geno-norm \\ --mbfile ../gen/bfile-norm.list \\ --max-threads 3 \\ --exclude-dups YES &quot;&gt; sh_script/mbfile-norm.sh # submit the script sbatch -A snpher ../sh_script/mbfile-norm.sh &gt;../job-records/mbfiles-norm # randomly select 100k individuals shuf ukbb-recommend.id | head -n 100000 &gt; ukbb-recommned-rand.100000 # make bfile for these individuals echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 20G #SBATCH -c 3 #SBATCH -t 20:0:0 ./ldak5.1 --make-bed ../gen/geno-norm-100k \\ --bfile ../gen/geno-norm \\ --keep ../ukbb-recommned-rand.100000 \\ --max-threads 3 \\ --exclude-dups YES &quot;&gt; sh_script/mbfile-norm-100k.sh # submit the script sbatch -A snpher ../sh_script/mbfile-norm-100k.sh &gt;../job-records/mbfiles-norm-100k # MAF &amp; call-rate awk &lt; geno-norm-100k.stats &#39;($5&gt;.01 &amp;&amp; $6&gt;=0.95 &amp;&amp; NR&gt;1){print $1}&#39; &gt; snps-norm-100k.use # m = 1,100,799 SNPs 8.3 GWAS-100k # linear regression------------------------------------------------------------- mkdir gwas-norm for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 10G #SBATCH -c 2 #SBATCH -t 10:0:0 ./ldak5.1 --linear ../gwas-norm/$i-linear \\ --pheno ../phen/continuous-traits/$i.raw.pheno \\ --bfile ../gen/geno-norm-100k \\ --keep ../ukbb-recommned-rand.100000 \\ --extract ../gen/snps-norm-100k.use \\ --covar ../phen/covariates.use \\ --max-threads 2 \\ &quot;&gt; sh_script/$i-linear.sh done # submit files------------------------------------------------------------------ for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do sbatch -A snpher ../sh_script/$i-linear.sh done&gt;../job-records/gwas-norm # check job completion---------------------------------------------------------- file=job-records/gwas-norm jobs=`awk &#39;{print $4}&#39; $file` mkdir $file-tmp for i in $jobs; do jobinfo $i | awk -F &quot;:&quot; -v i=$i &#39;$1~/Name/ {print i, $2}&#39; &gt;&gt; $file-tmp/name.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/State/ {print$2}&#39; &gt;&gt; $file-tmp/state.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Cores/ {print$2}&#39; &gt;&gt; $file-tmp/cores.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Used walltime/ {print $2 &quot;:&quot; $3 &quot;:&quot; $4}&#39; &gt;&gt; $file-tmp/time.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Max Mem/ {split($2,a,/[(]/ ); print a[1]}&#39; &gt;&gt; $file-tmp/mem.tmp done paste $file-tmp/name.tmp \\ $file-tmp/state.tmp \\ $file-tmp/cores.tmp \\ $file-tmp/time.tmp \\ $file-tmp/mem.tmp \\ | awk &#39;BEGIN{print &quot;ID name state cores time mem&quot;}{print $0}&#39; &gt; $file.out rm -r $file-tmp 8.4 GWAS-337k Here we do gwas for all recommended individuals. Previously we made a bfile for all these individuals. bfile (after QC) gen/geno-norm id list ukbb-recommend.id # snp list---------------------------------------------------------------------- # MAF &amp; call rate filtering awk &lt; gen/geno-norm.stats &#39;($5&gt;.01 &amp;&amp; $6&gt;=0.95 &amp;&amp; NR&gt;1){print $1}&#39; &gt; gen/snps-norm.use #1,100,715 snps # GWAS ------------------------------------------------------------------------- mkdir gwas-norm-337k for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 20G #SBATCH -c 3 #SBATCH -t 10:0:0 ./ldak5.1 --linear ../gwas-norm-337k/$i-linear \\ --pheno ../phen/continuous-traits/$i.raw.pheno \\ --bfile ../gen/geno-norm \\ --keep ../ukbb-recommend.id \\ --extract ../gen/snps-norm.use \\ --covar ../phen/covariates.use \\ --max-threads 3 \\ &quot;&gt; sh_script/$i-linear.sh done # submit files------------------------------------------------------------------ for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do sbatch -A snpher ../sh_script/$i-linear.sh done&gt;../job-records/gwas-norm-337k # check job completion---------------------------------------------------------- file=job-records/gwas-norm-337k jobs=`awk &#39;{print $4}&#39; $file` mkdir $file-tmp for i in $jobs; do jobinfo $i | awk -F &quot;:&quot; -v i=$i &#39;$1~/Name/ {print i, $2}&#39; &gt;&gt; $file-tmp/name.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/State/ {print$2}&#39; &gt;&gt; $file-tmp/state.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Cores/ {print$2}&#39; &gt;&gt; $file-tmp/cores.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Used walltime/ {print $2 &quot;:&quot; $3 &quot;:&quot; $4}&#39; &gt;&gt; $file-tmp/time.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Max Mem/ {split($2,a,/[(]/ ); print a[1]}&#39; &gt;&gt; $file-tmp/mem.tmp done paste $file-tmp/name.tmp \\ $file-tmp/state.tmp \\ $file-tmp/cores.tmp \\ $file-tmp/time.tmp \\ $file-tmp/mem.tmp \\ | awk &#39;BEGIN{print &quot;ID name state cores time mem&quot;}{print $0}&#39; &gt; $file.out rm -r $file-tmp 8.5 ldsc-100k 8.5.1 under gcta #::::::::::::: # using original ldsc #::::::::::::: # format stats for ldsc--------------------------------------------------------- library(vroom) options(scipen = 100) rs=vroom(&quot;doug/ukbb.ldsc&quot;, col_names=F) phen=c(&quot;awake&quot;,&quot;bmi&quot;,&quot;chron&quot;,&quot;ever&quot;,&quot;fvc&quot;, &quot;height&quot;,&quot;imp&quot;,&quot;neur&quot;,&quot;pulse&quot;,&quot;quals&quot;, &quot;reaction&quot;,&quot;sbp&quot;,&quot;snoring&quot;,&quot;hyper&quot;, &quot;quals&quot;) for(i in phen){ stat=vroom(paste0(&quot;gwas-norm/&quot;,i,&quot;-linear.summaries&quot;), col_names=T) p=vroom(paste0(&quot;gwas-norm/&quot;,i,&quot;-linear.pvalues&quot;), col_names=T) m1=match(rs$X1, stat$Predictor) m2=match(rs$X1, p$Predictor) out=data.frame(SNP=rs$X2, N=stat$n[m1], Z=(sqrt(stat$Stat)*stat$Direction)[m1], A1=stat$A1[m1], A2=stat$A2[m1], pval=p$P[m2], stringsAsFactors=F) out=out[complete.cases(out),] write.table(out, paste0(&quot;gwas-norm/&quot;,i,&quot;-linear-rs.summaries&quot;), col.names=T, row.names=F, quote=F) } # perform ldsc------------------------------------------------------------------ mkdir out-norm-100k for i in {awake,bmi,chron,ever,fvc,height,quals,imp,neur,pulse,reaction,sbp,snoring,hyper}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 2G #SBATCH -c 3 #SBATCH -t 24:00:0 .././munge_sumstats.py \\ --sumstats ../../gwas-norm/$i-linear-rs.summaries \\ --out ../out-norm-100k/$i \\ --merge-alleles ../w_hm3.snplist .././ldsc.py \\ --h2 ../out-norm-100k/$i.sumstats.gz \\ --ref-ld-chr ../eur_w_ld_chr/ \\ --w-ld-chr ../eur_w_ld_chr/ \\ --out ../out-norm-100k/$i-ldsc &quot;&gt;sh_script/ldsc-$i-norm-100k.sh done # submit jobs------------------------------------------------------------------- for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,reaction,sbp,snoring,hyper,quals}; do sbatch -A snpher ../sh_script/ldsc-$i-norm-100k.sh done&gt;../../job-records/ldsc-norm-100k #::::::::::::: # using sumher #::::::::::::: # insert genetic distance into bim file----------------------------------------- head geno-norm-100k.fam &gt; small-norm for j in {1..22}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --mem 8G #SBATCH -c 1 #SBATCH -t 3:00:0 #SBATCH --constraint \\&quot;s04|s05\\&quot; ./plink1.9 --bfile ../gen/geno-norm-100k \\ --chr $j \\ --cm-map /home/zhoux/snpher/faststorage/genetic_maps/genetic_map_chr@_combined_b37.txt \\ --make-bed \\ --out new$j \\ --keep ../gen/small-norm &quot; &gt; sh_script/map$j done for j in {1..22}; do sbatch -A snpher ../sh_script/map$j done &gt; genetic-distance-hapmap3 cd /home/zhoux/dsmwpred/xuan/quality-control/qc-10oct/gen cat new{1..22}.bim | awk &#39;{print $2, $3}&#39; &gt; maps-hapmap3-norm-100k.txt rm new{1..22}.{bim,bed,fam,log} awk &#39;(NR==FNR){arr[$1]=$2;next}{print $1, $2, arr[$2], $4, $5, $6}&#39; &gt; geno-norm-100k.bim2 maps-hapmap3-norm-100k.txt geno-norm-100k.bim mv geno-norm-100k.bim geno-norm-100k.bim0 mv geno-norm-100k.bim2 geno-norm-100k.bim # compute tagging under gcta---------------------------------------------------- mkdir tagging-norm-100k for j in {1..22}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 5G #SBATCH -c 1 #SBATCH -t 5:0:0 ./ldak5.1 --calc-tagging ../tagging-norm-100k/gcta-hapmap3-chr-$j \\ --bfile ../gen/geno-norm-100k \\ --ignore-weights YES \\ --power -1 \\ --window-cm 1 \\ --chr $j &quot;&gt; sh_script/tagging-gcta-hapmap3-chr$j done for j in {1..22}; do sbatch -A snpher ../sh_script/tagging-gcta-hapmap3-chr$j done &gt; ../job-records/tagging-gcta-hapmap3-norm-100k # check job completion---------------------------------------------------------- file=job-records/tagging-gcta-hapmap3-norm-100k jobs=`awk &#39;{print $4}&#39; $file` mkdir $file-tmp for i in $jobs; do jobinfo $i | awk -F &quot;:&quot; -v i=$i &#39;$1~/Name/ {print i, $2}&#39; &gt;&gt; $file-tmp/name.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/State/ {print$2}&#39; &gt;&gt; $file-tmp/state.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Cores/ {print$2}&#39; &gt;&gt; $file-tmp/cores.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Used walltime/ {print $2 &quot;:&quot; $3 &quot;:&quot; $4}&#39; &gt;&gt; $file-tmp/time.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Max Mem/ {split($2,a,/[(]/ ); print a[1]}&#39; &gt;&gt; $file-tmp/mem.tmp done paste $file-tmp/name.tmp \\ $file-tmp/state.tmp \\ $file-tmp/cores.tmp \\ $file-tmp/time.tmp \\ $file-tmp/mem.tmp \\ | awk &#39;BEGIN{print &quot;ID name state cores time mem&quot;}{print $0}&#39; &gt; $file.out rm -r $file-tmp # merge tagging files----------------------------------------------------------- rm list.txt for j in {1..22}; do echo &quot;tagging-norm-100k/gcta-hapmap3-chr-$j.tagging&quot; &gt;&gt; list.txt done ./ldak5.1 --join-tagging tagging-norm-100k/gcta-hapmap3 --taglist list.txt # ldsc intercept---------------------------------------------------------------- mkdir sumher-norm-100k dirin1=tagging-norm-100k dirin2=gwas-norm dirout=sumher-norm-100k for i in {awake,bmi,chron,ever,fvc,height,quals,imp,neur,pulse,reaction,sbp,snoring,hyper}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 5G #SBATCH -c 1 #SBATCH -t 5:0:0 ./ldak5.1 --sum-hers ../$dirout/$i-sumher-gcta \\ --tagfile ../$dirin1/gcta-hapmap3.tagging \\ --summary ../$dirin2/$i-linear.summaries \\ --check-sums NO \\ --intercept YES &quot;&gt; sh_script/$i-sumher-gcta done for i in {awake,bmi,chron,ever,fvc,height,quals,imp,neur,pulse,reaction,sbp,snoring,hyper}; do sbatch -A snpher ../sh_script/$i-sumher-gcta done&gt;../job-records/sumher-gcta-norm-100k 8.5.2 under ldak-thin # get weights------------------------------------------------------------------- awk &lt; ldak-thin/ldak-thin-norm.in &#39;{print $1, 1}&#39; &gt; ldak-thin/weights.ldak-thin-norm # calculate tagging under ldak-thin--------------------------------------------- dirout=tagging-norm-100k filein1=geno-norm-100k filein2=weights.ldak-thin-norm for j in {1..22}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --partition normal #SBATCH --mem 40G #SBATCH -c 5 #SBATCH -t 10:0:0 #SBATCH --constraint \\&quot;s04|s05\\&quot; ./ldak5.1 --calc-tagging ../$dirout/ldak-thin-hapmap3-chr-$j \\ --bfile ../gen/$filein1 \\ --weights ../ldak-thin/$filein2 \\ --power -.25 \\ --window-cm 1 \\ --chr $j \\ --save-matrix YES \\ --max-threads 5 &quot; &gt; sh_script/tagging-ldak-thin-hapmap3-chr$j.sh done # submit scripts for j in {1..22}; do sbatch -A snpher ../sh_script/tagging-ldak-thin-hapmap3-chr$j.sh done &gt; ../job-records/tagging-ldak-thin-norm-100k # check job completion---------------------------------------------------------- file=job-records/tagging-ldak-thin-norm-100k jobs=`awk &#39;{print $4}&#39; $file` mkdir $file-tmp for i in $jobs; do jobinfo $i | awk -F &quot;:&quot; -v i=$i &#39;$1~/Name/ {print i, $2}&#39; &gt;&gt; $file-tmp/name.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/State/ {print$2}&#39; &gt;&gt; $file-tmp/state.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Cores/ {print$2}&#39; &gt;&gt; $file-tmp/cores.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Used walltime/ {print $2 &quot;:&quot; $3 &quot;:&quot; $4}&#39; &gt;&gt; $file-tmp/time.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Max Mem/ {split($2,a,/[(]/ ); print a[1]}&#39; &gt;&gt; $file-tmp/mem.tmp done paste $file-tmp/name.tmp \\ $file-tmp/state.tmp \\ $file-tmp/cores.tmp \\ $file-tmp/time.tmp \\ $file-tmp/mem.tmp \\ | awk &#39;BEGIN{print &quot;ID name state cores time mem&quot;}{print $0}&#39; &gt; $file.out rm -r $file-tmp # merge tagging files----------------------------------------------------------- rm list.txt rm matlist.txt for j in {1..22}; do echo &quot;tagging-norm-100k/ldak-thin-hapmap3-chr-$j.tagging&quot; &gt;&gt; list.txt echo &quot;tagging-norm-100k/ldak-thin-hapmap3-chr-$j.matrix&quot; &gt;&gt; matlist.txt done dirout=tagging-norm-100k ./ldak5.1 --join-tagging $dirout/ldak-thin-hapmap3 --taglist list.txt --matlist matlist.txt # ldsc intercept---------------------------------------------------------------- dirin1=tagging-norm-100k dirin2=gwas-norm dirout=sumher-norm-100k for i in {awake,bmi,chron,ever,fvc,height,quals,imp,neur,pulse,reaction,sbp,snoring,hyper}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 5G #SBATCH -c 1 #SBATCH -t 00:30:0 ./ldak5.1 --sum-hers ../$dirout/$i-sumher-ldak-thin \\ --tagfile ../$dirin1/ldak-thin-hapmap3.tagging \\ --summary ../$dirin2/$i-linear.summaries \\ --check-sums NO \\ --intercept YES &quot;&gt; sh_script/$i-sumher-ldak-thin done for i in {awake,bmi,chron,ever,fvc,height,quals,imp,neur,pulse,reaction,sbp,snoring,hyper}; do sbatch -A snpher ../sh_script/$i-sumher-ldak-thin done&gt;../job-records/sumher-ldak-thin-norm-100k 8.5.3 summary # original ldsc grep Intercept *ldsc.log | awk &#39;{split($1, a, /[-]/); split($3, b, /[()]/); print a[1], $2, b[2]}&#39; &gt; ../../summary/ldsc-norm-100k # sumher under gcta grep Intercept_Estimate *gcta.extra | awk &#39;{ split($1, a, /[-]/); print a[1], $2}&#39; &gt;../summary/sumher-gcta-norm-100k-est grep Intercept_SD *gcta.extra | awk &#39;{ split($1, a, /[-]/); print a[1], $2}&#39; &gt;../summary/sumher-gcta-norm-100k-sd cd ../summary/ paste sumher-gcta-norm-100k-est sumher-gcta-norm-100k-sd | awk &#39;{print $1, $2, $4}&#39; &gt; sumher-gcta-norm-100k # suhmer under ldak-thin grep Intercept_Estimate *ldak-thin.extra | awk &#39;{ split($1, a, /[-]/); print a[1], $2}&#39; &gt;../summary/sumher-ldak-thin-norm-100k-est grep Intercept_SD *ldak-thin.extra | awk &#39;{ split($1, a, /[-]/); print a[1], $2}&#39; &gt;../summary/sumher-ldak-thin-norm-100k-sd cd ../summary/ paste sumher-ldak-thin-norm-100k-est sumher-ldak-thin-norm-100k-sd | awk &#39;{print $1, $2, $4}&#39; &gt; sumher-ldak-thin-norm-100k 8.6 ldsc-337k #::::::::::::: # using original ldsc #::::::::::::: # format stats for ldsc--------------------------------------------------------- library(vroom) options(scipen = 100) rs=vroom(&quot;doug/ukbb.ldsc&quot;, col_names=F) phen=c(&quot;awake&quot;,&quot;bmi&quot;,&quot;chron&quot;,&quot;ever&quot;,&quot;fvc&quot;, &quot;height&quot;,&quot;imp&quot;,&quot;neur&quot;,&quot;pulse&quot;,&quot;quals&quot;, &quot;reaction&quot;,&quot;sbp&quot;,&quot;snoring&quot;,&quot;hyper&quot;, &quot;quals&quot;) for(i in phen){ stat=vroom(paste0(&quot;gwas-norm-337k/&quot;,i,&quot;-linear.summaries&quot;), col_names=T) p=vroom(paste0(&quot;gwas-norm-337k/&quot;,i,&quot;-linear.pvalues&quot;), col_names=T) m1=match(rs$X1, stat$Predictor) m2=match(rs$X1, p$Predictor) out=data.frame(SNP=rs$X2, N=stat$n[m1], Z=(sqrt(stat$Stat)*stat$Direction)[m1], A1=stat$A1[m1], A2=stat$A2[m1], pval=p$P[m2], stringsAsFactors=F) out=out[complete.cases(out),] write.table(out, paste0(&quot;gwas-norm-337k/&quot;,i,&quot;-linear-rs.summaries&quot;), col.names=T, row.names=F, quote=F) } # perform ldsc------------------------------------------------------------------ mkdir out-norm-337k for i in {awake,bmi,chron,ever,fvc,height,quals,imp,neur,pulse,reaction,sbp,snoring,hyper}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 8G #SBATCH -c 3 #SBATCH -t 24:00:0 .././munge_sumstats.py \\ --sumstats ../../gwas-norm-337k/$i-linear-rs.summaries \\ --out ../out-norm-337k/$i \\ --merge-alleles ../w_hm3.snplist .././ldsc.py \\ --h2 ../out-norm-337k/$i.sumstats.gz \\ --ref-ld-chr ../eur_w_ld_chr/ \\ --w-ld-chr ../eur_w_ld_chr/ \\ --out ../out-norm-337k/$i-ldsc &quot;&gt;sh_script/ldsc-$i-norm-337k.sh done # submit jobs------------------------------------------------------------------- for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,reaction,sbp,snoring,hyper,quals}; do sbatch -A snpher ../sh_script/ldsc-$i-norm-337k.sh done&gt;../../job-records/ldsc-norm-337k # summary ---------------------------------------------------------------------- grep Intercept *ldsc.log | awk &#39;{split($1, a, /[-]/); split($3, b, /[()]/); print a[1], $2, b[2]}&#39; &gt; ../../summary/ldsc-norm-337k R ldsc=read.table(&quot;summary/ldsc-norm-337k&quot;, header=F, stringsAsFactors = F) # get p-values for Wald tests # H0: intercept = 1 alpha=0.05/14 # Bonferroni corrected alpha ldsc=data.frame(trait=ldsc$V1, est=ldsc$V2, se=ldsc$V3, wald_p=pchisq(((ldsc$V2-1)/ldsc$V3)^2, df=1, lower.tail=F), sig=pchisq(((ldsc$V2-1)/ldsc$V3)^2, df=1, lower.tail=F) &lt; alpha, stringsAsFactors = F) 8.7 aver2_j-337k 8.7.1 calc #::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: # snp lists #::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: # new directory mkdir inflation/norm mkdir inflation/norm/out # lista &amp; listb m=10000 infile=gen/snps-norm.use left=inflation/norm/left-snps right=inflation/norm/right-snps awk &#39;{split($1, a, &quot;:&quot;); if (a[1]&lt;8) print $1 }&#39; $infile | shuf | head -n $m &gt;$left awk &#39;{split($1, a, &quot;:&quot;); if (a[1]&gt;=8) print $1 }&#39; $infile | shuf | head -n $m &gt;$right #::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: # compute ave r^2_j #::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: lista=../inflation/norm/right-snps listb=../inflation/norm/left-snps bfile=../gen/geno-norm out=../inflation/norm/out/10k-snps echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 60G #SBATCH -c 7 #SBATCH -t 00:10:0 ./ldak5.2 --max-threads 7 \\ --calc-inflation $out \\ --bfile $bfile \\ --lista $lista \\ --listb $listb &quot;&gt;sh_script/calc-r-10k-snps # submit the job sbatch -A snpher ../sh_script/calc-r-10k-snps &gt;../job-records/calc-r-norm # compute ave r_j^2 for each i------------------------------------------------- R require(vroom) nm=&quot;10k-snps&quot; dat=vroom(paste0(&quot;inflation/norm/out/&quot;,nm,&quot;.pairwise&quot;), col_names=F) lista=read.table(paste0(&quot;inflation/norm/out/&quot;,nm,&quot;.predictorsa&quot;), stringsAsFactors = F) listb=read.table(paste0(&quot;inflation/norm/out/&quot;,nm,&quot;.predictorsb&quot;), stringsAsFactors = F) dat=dat[,-c(10001)]^2 outb=data.frame(predictor=listb$V1, ave_r2=apply(dat,2, mean)) outa=data.frame(predictor=lista$V1, ave_r2=apply(dat,1, mean)) out=rbind(outa,outb) write.table(out,paste0(&quot;summary/ave-r2-&quot;,nm, &quot;-ukbb-norm&quot;), col.names=F, row.names=F, quote=F) 8.7.2 organize data mkdir gwas-norm-337k-out for trait in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do gwas=gwas-norm-337k/$trait-linear.summaries aver2=summary/ave-r2-10k-snps-ukbb-norm out=gwas-norm-337k-out/$trait.out awk &#39;NR&gt;1 {print $1, $5}&#39; $gwas &gt; tmp/gwas.tmp awk &#39;NR==FNR {a[$1]; b[$1]=$2; next} {if ($1 in a) print b[$1]; else print &quot;NA&quot; }&#39; $aver2 tmp/gwas.tmp &gt; tmp/aver2.tmp # put info together paste tmp/gwas.tmp \\ tmp/aver2.tmp \\ | awk &#39;BEGIN{OFS=&quot;;&quot; ; print &quot;snp;chisq;aver2&quot;} {$1=$1}1&#39; &gt; $out done 8.7.3 chisq ~ aver2_j #:::::::::::::::::::::::::::::::::::::::::::::: # estimate slope: chisq ~ aver2_j #:::::::::::::::::::::::::::::::::::::::::::::: require(vroom) traits=c(&quot;awake&quot;,&quot;bmi&quot;,&quot;chron&quot;,&quot;ever&quot;, &quot;neur&quot;,&quot;pulse&quot;,&quot;quals&quot;, &quot;fvc&quot;, &quot;height&quot;,&quot;imp&quot;, &quot;reaction&quot;,&quot;sbp&quot;,&quot;snoring&quot;,&quot;hyper&quot;) for(i in 1:length(traits)){ trait=traits[i] file=paste0(&quot;gwas-norm-337k-out/&quot;,trait,&quot;.out&quot;) dat=vroom(file, col_names=T, delim=&quot;;&quot;) dat=dat[complete.cases(dat),] mod=lm(chisq ~ aver2,data=dat) slope0=data.frame(trait=trait, slope_aver2=coef(mod)[2], p_aver2=summary(mod)$coefficients[,4][2], stringsAsFactors = F) if(i==1){slope=slope0} else {slope=rbind(slope,slope0)} } #:::::::::::::::::::::::::::::::::::::::::::::: # plot chisq ~ aver2_j #:::::::::::::::::::::::::::::::::::::::::::::: # make a plot ------------------------------------------------------------------ require(vroom) traits=c(&quot;awake&quot;,&quot;bmi&quot;,&quot;chron&quot;,&quot;ever&quot;, &quot;neur&quot;,&quot;pulse&quot;,&quot;quals&quot;, &quot;fvc&quot;, &quot;height&quot;,&quot;imp&quot;, &quot;reaction&quot;,&quot;sbp&quot;,&quot;snoring&quot;,&quot;hyper&quot;) png(paste0(&quot;fig/chisq-by-aver2-bin-ukbb-recommend-337k.png&quot;), width = 50, height = 30, units = &quot;cm&quot;, res=600) par(mfrow=c(3,5)) for (i in 1:length(traits)){ trait=traits[i] file=paste0(&quot;gwas-norm-337k-out/&quot;,trait,&quot;.out&quot;) dat=vroom(file, col_names=T, delim=&quot;;&quot;) # bin a variable by quantile cutoff=quantile(dat$aver2, probs = seq(0, 1, 0.005), na.rm=T) dat$bin=cut(dat$aver2, breaks=cutoff, labels=1:(length(cutoff)-1)) # average chisq by bin values out=data.frame(chisq_ave=tapply(dat$chisq,INDEX=dat$bin, mean)) out$bin_val=tapply(dat$aver2,INDEX=dat$bin, mean) plot(out$bin_val, out$chisq_ave, xlab=&quot;ave r2&quot;, ylab=&quot;ave chisq&quot;, main=trait, las=1, cex = 1.5, pch=21, bg=&quot;orange&quot;, col=&quot;white&quot;, lwd=0.5) } dev.off() 8.8 HE 8.8.1 making grms # making grm ------------------------------------------------------------------- #::: # under gcta #::: # all snps echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --partition normal #SBATCH --mem 60G #SBATCH -c 10 #SBATCH -t 08:0:0 #SBATCH --constraint \\&quot;s04|s05\\&quot; ./ldak5.1 --max-threads 10 \\ --calc-kins-direct ../kinship/gcta-all-norm \\ --bfile ../gen/geno-norm-100k \\ --extract ../gen/snps-norm-100k.use \\ --power -1 \\ --ignore-weights YES \\ --single YES &quot; &gt; sh_script/grm-all-snps-norm sbatch -A snpher ../sh_script/grm-all-snps-norm &gt; ../job-records/grm-all-snps-norm # grm by snp blocks: right vs. left awk &#39;$1&lt;8 {print $2}&#39; geno-norm-100k.bim &gt; left-snps-norm-100k.use awk &#39;$1&gt;=8 {print $2}&#39; geno-norm-100k.bim &gt; right-snps-norm-100k.use for i in left right; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --partition normal #SBATCH --mem 60G #SBATCH -c 10 #SBATCH -t 20:0:0 #SBATCH --constraint \\&quot;s04|s05\\&quot; ./ldak5.1 --max-threads 10 \\ --calc-kins-direct ../kinship/gcta-$i-norm \\ --bfile ../gen/geno-norm-100k \\ --extract ../gen/$i-snps-norm-100k.use \\ --power -1 \\ --ignore-weights YES \\ --single YES &quot; &gt; sh_script/grm-gcta-$i-norm done for i in left right; do sbatch -A snpher ../sh_script/grm-gcta-$i-norm done &gt; ../job-records/grm-gcta-by-snps-norm #::: # under ldak-thin #::: #----------- # 1. thin snps #----------- for j in {1..22}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --partition normal #SBATCH --mem 10G #SBATCH -c 4 #SBATCH -t 4:0:0 #SBATCH --constraint \\&quot;s04|s05\\&quot; ./ldak5.1 --max-threads 4 \\ --window-prune 0.98 \\ --window-kb 100 \\ --extract ../gen/snps-norm-100k.use \\ --bfile ../gen/geno-norm-100k \\ --thin ../ldak-thin/chr$j-norm \\ --chr $j &quot; &gt; sh_script/ldak-thin$j-norm done # submit script for j in {1..22}; do sbatch -A snpher ../sh_script/ldak-thin$j-norm done &gt; ../job-records/ldak-thin-norm # check job completion--- file=job-records/ldak-thin-norm jobs=`awk &#39;{print $4}&#39; $file` mkdir $file-tmp for i in $jobs; do jobinfo $i | awk -F &quot;:&quot; -v i=$i &#39;$1~/Name/ {print i, $2}&#39; &gt;&gt; $file-tmp/name.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/State/ {print$2}&#39; &gt;&gt; $file-tmp/state.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Cores/ {print$2}&#39; &gt;&gt; $file-tmp/cores.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Used walltime/ {print $2 &quot;:&quot; $3 &quot;:&quot; $4}&#39; &gt;&gt; $file-tmp/time.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Max Mem/ {split($2,a,/[(]/ ); print a[1]}&#39; &gt;&gt; $file-tmp/mem.tmp done paste $file-tmp/name.tmp \\ $file-tmp/state.tmp \\ $file-tmp/cores.tmp \\ $file-tmp/time.tmp \\ $file-tmp/mem.tmp \\ | awk &#39;BEGIN{print &quot;ID name state cores time mem&quot;}{print $0}&#39; &gt; $file.out rm -r $file-tmp # combine snp list cat ldak-thin/chr{1..22}-norm.in &gt; ldak-thin/ldak-thin-norm.in #---------------------- # 2. kinship matrix under ldak-thin #------------------------ echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --partition normal #SBATCH --mem 60G #SBATCH -c 10 #SBATCH -t 08:0:0 #SBATCH --constraint \\&quot;s04|s05\\&quot; ./ldak5.1 --max-threads 10 \\ --calc-kins-direct ../kinship/ldak-thin-all-norm \\ --bfile ../gen/geno-norm-100k \\ --extract ../ldak-thin/ldak-thin-norm.in \\ --power -0.25 \\ --ignore-weights YES \\ --single YES &quot; &gt; sh_script/ldak-thin-grm-all-snps-norm sbatch -A snpher ../sh_script/ldak-thin-grm-all-snps-norm &gt; ../job-records/ldak-thin-grm-all-snps-norm # grm by snp blocks: right vs. left awk &#39;{split($1, a, /[:]/); if (a[1]&lt;8) print $1}&#39; \\ ldak-thin/ldak-thin-norm.in &gt; gen/left-ldak-thin-norm.snps awk &#39;{split($1, a, /[:]/); if (a[1]&gt;=8) print $1}&#39; \\ ldak-thin/ldak-thin-norm.in &gt; gen/right-ldak-thin-norm.snps for i in left right; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --partition normal #SBATCH --mem 60G #SBATCH -c 10 #SBATCH -t 08:0:0 #SBATCH --constraint \\&quot;s04|s05\\&quot; ./ldak5.1 --max-threads 10 \\ --calc-kins-direct ../kinship/ldak-thin-$i-norm \\ --bfile ../gen/geno-norm-100k \\ --extract ../gen/$i-ldak-thin-norm.snps \\ --power -0.25 \\ --ignore-weights YES \\ --single YES &quot; &gt; sh_script/ldak-thin-grm-$i-norm done for i in left right; do sbatch -A snpher ../sh_script/ldak-thin-grm-$i-norm done &gt; ../job-records/grm-ldak-thin-by-snps-norm 8.8.2 estimation NEED To check what covariates to adjust for HE basic.covariates.use or covariates.use? # regress grm on covariates----------------------------------------------------- for grm in gcta-all-norm gcta-left-norm gcta-right-norm ldak-thin-all-norm ldak-thin-left-norm ldak-thin-right-norm; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 50G #SBATCH -c 5 #SBATCH -t 10:0:0 ./ldak5.1 --adjust-grm ../kinship/$grm.covar \\ --grm ../kinship/$grm \\ --covar ../phen/covariates.use \\ --max-threads 5 &quot;&gt; sh_script/$grm-adjust.sh done # submit jobs for grm in gcta-all-norm gcta-left-norm gcta-right-norm ldak-thin-all-norm ldak-thin-left-norm ldak-thin-right-norm; do sbatch -A snpher ../sh_script/$grm-adjust.sh done &gt; ../job-records/grm-adjust-for-HE # check job completion---------------------------------------------------------- file=job-records/grm-adjust-for-HE jobs=`awk &#39;{print $4}&#39; $file` mkdir $file-tmp for i in $jobs; do jobinfo $i | awk -F &quot;:&quot; -v i=$i &#39;$1~/Name/ {print i, $2}&#39; &gt;&gt; $file-tmp/name.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/State/ {print$2}&#39; &gt;&gt; $file-tmp/state.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Cores/ {print$2}&#39; &gt;&gt; $file-tmp/cores.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Used walltime/ {print $2 &quot;:&quot; $3 &quot;:&quot; $4}&#39; &gt;&gt; $file-tmp/time.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Max Mem/ {split($2,a,/[(]/ ); print a[1]}&#39; &gt;&gt; $file-tmp/mem.tmp done paste $file-tmp/name.tmp \\ $file-tmp/state.tmp \\ $file-tmp/cores.tmp \\ $file-tmp/time.tmp \\ $file-tmp/mem.tmp \\ | awk &#39;BEGIN{print &quot;ID name state cores time mem&quot;}{print $0}&#39; &gt; $file.out rm -r $file-tmp # HE under gcta----------------------------------------------------------------- for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do for k in all left right; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 2G #SBATCH -c 1 #SBATCH -t 00:30:0 ./ldak5.1 --he ../he-norm/$i-he-gcta-$k \\ --pheno ../phen/continuous-traits/$i.raw.pheno \\ --grm ../kinship/gcta-$k-norm.covar \\ --kinship-details NO \\ --check-root NO \\ --covar ../phen/covariates.use \\ --max-threads 1 \\ --memory-save YES &quot;&gt; sh_script/$i-he-gcta-$k-snps-norm.sh done done # submit files------------------------------------------------------------------ for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do for k in all left right; do sbatch -A snpher ../sh_script/$i-he-gcta-$k-snps-norm.sh done done &gt; ../job-records/he-gcta # HE under ldak-thin------------------------------------------------------------ for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do for k in all left right; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 2G #SBATCH -c 1 #SBATCH -t 0:30:0 ./ldak5.1 --he ../he-norm/$i-he-ldak-thin-$k \\ --pheno ../phen/continuous-traits/$i.raw.pheno \\ --grm ../kinship/ldak-thin-$k-norm.covar \\ --kinship-details NO \\ --check-root NO \\ --covar ../phen/covariates.use \\ --max-threads 1 \\ --memory-save YES &quot;&gt; sh_script/$i-he-ldak-thin-$k-norm.sh done done # submit files------------------------------------------------------------------ for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do for k in all left right; do sbatch -A snpher ../sh_script/$i-he-ldak-thin-$k-norm.sh done done &gt; ../job-records/he-ldak-thin 8.8.3 summary #:::::::::::: # under gcta #:::::::::::: # extract h2 estimates --------------------------------------------------------- # right rm summary/he-gcta-norm.right for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do outfile=he-norm/$i-he-gcta-right.he awk -v i=$i &#39;$1==&quot;Her_All&quot; {print i, $2, $3}&#39; $outfile &gt;&gt; summary/he-gcta-norm.right done # left rm summary/he-gcta-norm.left for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do outfile=he-norm/$i-he-gcta-left.he awk -v i=$i &#39;$1==&quot;Her_All&quot; {print i, $2, $3}&#39; $outfile &gt;&gt; summary/he-gcta-norm.left done # all rm summary/he-gcta-norm.all for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do outfile=he-norm/$i-he-gcta-all.he awk -v i=$i &#39;$1==&quot;Her_All&quot; {print i, $2, $3}&#39; $outfile &gt;&gt; summary/he-gcta-norm.all done # inflation test---------------------------------------------------------------- R full=read.table(paste0(&quot;summary/he-gcta-norm.all&quot;), header=F) left=read.table(paste0(&quot;summary/he-gcta-norm.left&quot;), header=F) right=read.table(paste0(&quot;summary/he-gcta-norm.right&quot;), header=F) names(full)=names(left)=names(right)=c(&quot;code&quot;,&quot;h2&quot;,&quot;se&quot;) # some analyses did not complete --&gt; match dataframes dim(full);dim(left);dim(right) common=intersect(full$code, left$code) common=intersect(common, right$code) m1=match(common, right$code) m2=match(common, full$code) m3=match(common, left$code) right=right[m1,] full=full[m2,] left=left[m3,] for(i in 1:dim(full)[1]){ est1=left$h2[i] sd1=left$se[i] est2=right$h2[i] sd2=right$se[i] est=full$h2[i] sd=full$se[i] N=100000 d1=rnorm(N,est1,sd1) d2=rnorm(N,est2,sd2) d=rnorm(N,est,sd) p=1-mean(d1+d2-d&gt;=0) out0=data.frame(code=full$code[i], right_est=est2, right_sd=sd2, left_est=est1, left_sd=sd1, all_est=est, all_sd=sd, p_inflation=p) if(i==1){out=out0}else{out=rbind(out,out0)} } write.table(out, paste0(&quot;summary/he-gcta-inflation-norm.txt&quot;), col.names=T, row.names=F, quote=F) #:::::::::::: # under ldak-thin #:::::::::::: # extract h2 estimates --------------------------------------------------------- # right rm summary/he-ldak-thin-norm.right for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do outfile=he-norm/$i-he-ldak-thin-right.he awk -v i=$i &#39;$1==&quot;Her_All&quot; {print i, $2, $3}&#39; $outfile &gt;&gt; summary/he-ldak-thin-norm.right done # left rm summary/he-ldak-thin-norm.left for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do outfile=he-norm/$i-he-ldak-thin-left.he awk -v i=$i &#39;$1==&quot;Her_All&quot; {print i, $2, $3}&#39; $outfile &gt;&gt; summary/he-ldak-thin-norm.left done # all rm summary/he-ldak-thin-norm.all for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do outfile=he-norm/$i-he-gcta-all.he awk -v i=$i &#39;$1==&quot;Her_All&quot; {print i, $2, $3}&#39; $outfile &gt;&gt; summary/he-ldak-thin-norm.all done # inflation test---------------------------------------------------------------- R full=read.table(paste0(&quot;summary/he-ldak-thin-norm.all&quot;), header=F) left=read.table(paste0(&quot;summary/he-ldak-thin-norm.left&quot;), header=F) right=read.table(paste0(&quot;summary/he-ldak-thin-norm.right&quot;), header=F) names(full)=names(left)=names(right)=c(&quot;code&quot;,&quot;h2&quot;,&quot;se&quot;) # some analyses did not complete --&gt; match dataframes dim(full);dim(left);dim(right) common=intersect(full$code, left$code) common=intersect(common, right$code) m1=match(common, right$code) m2=match(common, full$code) m3=match(common, left$code) right=right[m1,] full=full[m2,] left=left[m3,] for(i in 1:dim(full)[1]){ est1=left$h2[i] sd1=left$se[i] est2=right$h2[i] sd2=right$se[i] est=full$h2[i] sd=full$se[i] N=100000 d1=rnorm(N,est1,sd1) d2=rnorm(N,est2,sd2) d=rnorm(N,est,sd) p=1-mean(d1+d2-d&gt;=0) out0=data.frame(code=full$code[i], right_est=est2, right_sd=sd2, left_est=est1, left_sd=sd1, all_est=est, all_sd=sd, p_inflation=p) if(i==1){out=out0}else{out=rbind(out,out0)} } write.table(out, paste0(&quot;summary/he-ldak-thin-inflation-norm.txt&quot;), col.names=T, row.names=F, quote=F) "],["control.html", "9 control GWAS 9.1 ID list 9.2 QC of hp3 SNPs 9.3 GWAS 9.4 ldsc intercept 9.5 HE", " 9 control GWAS Here we perform GWASs that serve as the control group for the good versus bad GWASs comparison. For the bad GWASs (section 7), we have a total of 100k individuals, which consist of 93,528 unrelated white British (from the good GWASs) and 6,472 blacks and Asians. We observed inflation of the test statistics. Although unlikely, it is still possible that some of the inflation is due to random errors. To rule out this possibility [or to ascertain that the observed inflation is due to population stratification not random errors], we used the same 93,528 unrelated white British but replaced the 6,472 blacks and Asians with unrelated white British that were not included in the good GWASs. 9.1 ID list We used previously obtained id lists (see section 6.1 for the good GWAS id list and section 7.1 for the bad GWAS id list ) to derive the id list for the control GWASs. These are: overlap-complete-cases.id: N = 147,008. Unrelated white British who have no missing data for all 14 traits and covariates. rand.100000: ID list for the good gwas. Randomly selected from overlap-complete-cases.id white.rand.93528: unrelated whites as a part of the bad gwas ID list. Randomly selected from rand.100000 Here are the steps: identify IDs from overlap-complete-cases.id not included in rand.100000. randomly select 6,472 from the identified IDs. combine white.rand.93528 with the randomly selected 6,472 IDs. options(scipen = 100) id1=read.table(&quot;unrelated/overlap-complete-cases.id&quot;, header=F) id2=read.table(&quot;unrelated/rand.100000&quot;, header=F) id3=read.table(&quot;white.rand.93528&quot;, header=F) # pool for selection common=intersect(id1$V1, id2$V1) pool=id1[!id1$V1%in%common,] # randomly select 6,472 from the pool sel=pool[sample(dim(pool)[1], 6472, replace=F),] # combine with &#39;white.rand.93528&#39; write.table(rbind(sel,id3), &#39;control-gwas.id&#39;, quote=F, row.names=F, col.names=F) 9.2 QC of hp3 SNPs # QC SNPs----------------------------------------------------------------------- # stating number of SNPs= 1,184,423 for j in {1..22}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 20G #SBATCH -c 3 #SBATCH -t 1:0:0 ./plink2 --pfile ../gen/geno_plink/bhr$j \\ --keep ../control-gwas.id \\ --extract ../doug/ukbb.ldsc \\ --hwe 0.0001 \\ --hard-call-threshold .05 \\ --mach-r2-filter 0.8 2 \\ --make-bed \\ --memory 20000 \\ --out ../gen/tmp/bhr$j \\ --threads 3 &quot;&gt; sh_script/chr$j.sh done # submit jobs for j in {1..22}; do sbatch -A snpher ../sh_script/chr$j.sh done &gt; ../job-records/qc-control-gwas file=job-records/qc-control-gwas jobs=`awk &#39;{print $4}&#39; $file` mkdir $file-tmp for i in $jobs; do jobinfo $i | awk -F &quot;:&quot; -v i=$i &#39;$1~/Name/ {print i, $2}&#39; &gt;&gt; $file-tmp/name.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/State/ {print$2}&#39; &gt;&gt; $file-tmp/state.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Cores/ {print$2}&#39; &gt;&gt; $file-tmp/cores.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Used walltime/ {print $2 &quot;:&quot; $3 &quot;:&quot; $4}&#39; &gt;&gt; $file-tmp/time.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Max Mem/ {split($2,a,/[(]/ ); print a[1]}&#39; &gt;&gt; $file-tmp/mem.tmp done paste $file-tmp/name.tmp \\ $file-tmp/state.tmp \\ $file-tmp/cores.tmp \\ $file-tmp/time.tmp \\ $file-tmp/mem.tmp \\ | awk &#39;BEGIN{print &quot;ID name state cores time mem&quot;}{print $0}&#39; &gt; $file.out rm -r $file-tmp # merge files rm bfile-control-gwas.list for j in {1..22}; do echo &quot;../gen/tmp/bhr$j&quot; &gt;&gt;bfile-control-gwas.list done echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 20G #SBATCH -c 3 #SBATCH -t 40:0:0 ./ldak5.1 --make-bed ../gen/geno-control \\ --mbfile ../gen/bfile-control-gwas.list \\ --max-threads 3 \\ --exclude-dups YES &quot;&gt; sh_script/mbfile-control.sh # submit the script sbatch -A snpher ../sh_script/mbfile-control.sh &gt;../job-records/mbfiles-control-gwas # MAF &amp; call-rate awk &lt; geno-control.stats &#39;($5&gt;.01 &amp;&amp; $6&gt;=0.95 &amp;&amp; NR&gt;1){print $1}&#39; &gt; snps-control-gwas.use # m = 1,103,182 SNPs 9.3 GWAS # linear regression------------------------------------------------------------- mkdir gwas-control dirout=gwas-control filein=geno-control id=control-gwas.id snp=snps-control-gwas.use for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 10G #SBATCH -c 2 #SBATCH -t 10:0:0 ./ldak5.1 --linear ../$dirout/$i-linear \\ --pheno ../phen/continuous-traits/$i.raw.pheno \\ --bfile ../gen/$filein \\ --keep ../$id \\ --extract ../gen/$snp \\ --covar ../phen/covariates.use \\ --max-threads 2 \\ &quot;&gt; sh_script/$i-linear.sh done # submit files------------------------------------------------------------------ for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do sbatch -A snpher ../sh_script/$i-linear.sh done&gt;../job-records/gwas-control # check job completion---------------------------------------------------------- file=job-records/gwas-control jobs=`awk &#39;{print $4}&#39; $file` mkdir $file-tmp for i in $jobs; do jobinfo $i | awk -F &quot;:&quot; -v i=$i &#39;$1~/Name/ {print i, $2}&#39; &gt;&gt; $file-tmp/name.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/State/ {print$2}&#39; &gt;&gt; $file-tmp/state.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Cores/ {print$2}&#39; &gt;&gt; $file-tmp/cores.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Used walltime/ {print $2 &quot;:&quot; $3 &quot;:&quot; $4}&#39; &gt;&gt; $file-tmp/time.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Max Mem/ {split($2,a,/[(]/ ); print a[1]}&#39; &gt;&gt; $file-tmp/mem.tmp done paste $file-tmp/name.tmp \\ $file-tmp/state.tmp \\ $file-tmp/cores.tmp \\ $file-tmp/time.tmp \\ $file-tmp/mem.tmp \\ | awk &#39;BEGIN{print &quot;ID name state cores time mem&quot;}{print $0}&#39; &gt; $file.out rm -r $file-tmp 9.4 ldsc intercept 9.4.1 under gcta # UP TO HERE #::::::::::::: # using original ldsc #::::::::::::: # format stats for ldsc--------------------------------------------------------- library(vroom) options(scipen = 100) rs=vroom(&quot;doug/ukbb.ldsc&quot;, col_names=F) phen=c(&quot;awake&quot;,&quot;bmi&quot;,&quot;chron&quot;,&quot;ever&quot;,&quot;fvc&quot;, &quot;height&quot;,&quot;imp&quot;,&quot;neur&quot;,&quot;pulse&quot;,&quot;quals&quot;, &quot;reaction&quot;,&quot;sbp&quot;,&quot;snoring&quot;,&quot;hyper&quot;, &quot;quals&quot;) for(i in phen){ stat=vroom(paste0(&quot;gwas-control/&quot;,i,&quot;-linear.summaries&quot;), col_names=T) p=vroom(paste0(&quot;gwas-control/&quot;,i,&quot;-linear.pvalues&quot;), col_names=T) m1=match(rs$X1, stat$Predictor) m2=match(rs$X1, p$Predictor) out=data.frame(SNP=rs$X2, N=stat$n[m1], Z=(sqrt(stat$Stat)*stat$Direction)[m1], A1=stat$A1[m1], A2=stat$A2[m1], pval=p$P[m2], stringsAsFactors=F) out=out[complete.cases(out),] write.table(out, paste0(&quot;gwas-control/&quot;,i,&quot;-linear-rs.summaries&quot;), col.names=T, row.names=F, quote=F) } # perform ldsc------------------------------------------------------------------ mkdir out-control for i in {awake,bmi,chron,ever,fvc,height,quals,imp,neur,pulse,reaction,sbp,snoring,hyper}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 2G #SBATCH -c 3 #SBATCH -t 24:00:0 .././munge_sumstats.py \\ --sumstats ../../gwas-control/$i-linear-rs.summaries \\ --out ../out-control/$i \\ --merge-alleles ../w_hm3.snplist .././ldsc.py \\ --h2 ../out-control/$i.sumstats.gz \\ --ref-ld-chr ../eur_w_ld_chr/ \\ --w-ld-chr ../eur_w_ld_chr/ \\ --out ../out-control/$i-ldsc &quot;&gt;sh_script/ldsc-$i-control.sh done # submit jobs------------------------------------------------------------------- for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,reaction,sbp,snoring,hyper,quals}; do sbatch -A snpher ../sh_script/ldsc-$i-control.sh done&gt;../../job-records/ldsc-control #::::::::::::: # using sumher #::::::::::::: # insert genetic distance into bim file----------------------------------------- head geno-control.fam &gt; small-control for j in {1..22}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --mem 8G #SBATCH -c 1 #SBATCH -t 3:00:0 #SBATCH --constraint \\&quot;s04|s05\\&quot; ./plink1.9 --bfile ../gen/geno-control \\ --chr $j \\ --cm-map /home/zhoux/snpher/faststorage/genetic_maps/genetic_map_chr@_combined_b37.txt \\ --make-bed \\ --out new$j \\ --keep ../gen/small-control &quot; &gt; sh_script/map$j done for j in {1..22}; do sbatch -A snpher ../sh_script/map$j done &gt; genetic-distance-hapmap3 cd /home/zhoux/dsmwpred/xuan/quality-control/qc-10oct/gen cat new{1..22}.bim | awk &#39;{print $2, $3}&#39; &gt; maps-hapmap3-control.txt rm new{1..22}.{bim,bed,fam,log} awk &#39;(NR==FNR){arr[$1]=$2;next}{print $1, $2, arr[$2], $4, $5, $6}&#39; &gt; geno-control.bim2 maps-hapmap3-control.txt geno-control.bim mv geno-control.bim geno-control.bim0 mv geno-control.bim2 geno-control.bim # compute tagging under gcta---------------------------------------------------- mkdir tagging-control for j in {1..22}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 5G #SBATCH -c 1 #SBATCH -t 5:0:0 ./ldak5.1 --calc-tagging ../tagging-control/gcta-hapmap3-chr-$j \\ --bfile ../gen/geno-control \\ --ignore-weights YES \\ --power -1 \\ --window-cm 1 \\ --chr $j &quot;&gt; sh_script/tagging-gcta-hapmap3-chr$j done for j in {1..22}; do sbatch -A snpher ../sh_script/tagging-gcta-hapmap3-chr$j done &gt; ../job-records/tagging-gcta-hapmap3-control # check job completion---------------------------------------------------------- file=job-records/tagging-gcta-hapmap3-control jobs=`awk &#39;{print $4}&#39; $file` mkdir $file-tmp for i in $jobs; do jobinfo $i | awk -F &quot;:&quot; -v i=$i &#39;$1~/Name/ {print i, $2}&#39; &gt;&gt; $file-tmp/name.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/State/ {print$2}&#39; &gt;&gt; $file-tmp/state.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Cores/ {print$2}&#39; &gt;&gt; $file-tmp/cores.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Used walltime/ {print $2 &quot;:&quot; $3 &quot;:&quot; $4}&#39; &gt;&gt; $file-tmp/time.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Max Mem/ {split($2,a,/[(]/ ); print a[1]}&#39; &gt;&gt; $file-tmp/mem.tmp done paste $file-tmp/name.tmp \\ $file-tmp/state.tmp \\ $file-tmp/cores.tmp \\ $file-tmp/time.tmp \\ $file-tmp/mem.tmp \\ | awk &#39;BEGIN{print &quot;ID name state cores time mem&quot;}{print $0}&#39; &gt; $file.out rm -r $file-tmp # merge tagging files----------------------------------------------------------- rm list.txt for j in {1..22}; do echo &quot;tagging-control/gcta-hapmap3-chr-$j.tagging&quot; &gt;&gt; list.txt done ./ldak5.1 --join-tagging tagging-control/gcta-hapmap3 --taglist list.txt # ldsc intercept---------------------------------------------------------------- mkdir sumher-control dirin1=tagging-control dirin2=gwas-control dirout=sumher-control for i in {awake,bmi,chron,ever,fvc,height,quals,imp,neur,pulse,reaction,sbp,snoring,hyper}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 5G #SBATCH -c 1 #SBATCH -t 5:0:0 ./ldak5.1 --sum-hers ../$dirout/$i-sumher-gcta \\ --tagfile ../$dirin1/gcta-hapmap3.tagging \\ --summary ../$dirin2/$i-linear.summaries \\ --check-sums NO \\ --intercept YES &quot;&gt; sh_script/$i-sumher-gcta done for i in {awake,bmi,chron,ever,fvc,height,quals,imp,neur,pulse,reaction,sbp,snoring,hyper}; do sbatch -A snpher ../sh_script/$i-sumher-gcta done&gt;../job-records/sumher-gcta-control 9.4.2 under ldak-thin # get weights------------------------------------------------------------------- awk &lt; ldak-thin/ldak-thin-control.in &#39;{print $1, 1}&#39; &gt; ldak-thin/weights.ldak-thin-control # calculate tagging under ldak-thin--------------------------------------------- dirout=tagging-control filein1=geno-control filein2=weights.ldak-thin-control for j in {1..22}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --partition normal #SBATCH --mem 40G #SBATCH -c 5 #SBATCH -t 10:0:0 #SBATCH --constraint \\&quot;s04|s05\\&quot; ./ldak5.1 --calc-tagging ../$dirout/ldak-thin-hapmap3-chr-$j \\ --bfile ../gen/$filein1 \\ --weights ../ldak-thin/$filein2 \\ --power -.25 \\ --window-cm 1 \\ --chr $j \\ --save-matrix YES \\ --max-threads 5 &quot; &gt; sh_script/tagging-ldak-thin-hapmap3-chr$j.sh done # submit scripts for j in {1..22}; do sbatch -A snpher ../sh_script/tagging-ldak-thin-hapmap3-chr$j.sh done &gt; ../job-records/tagging-ldak-thin-control # check job completion---------------------------------------------------------- file=job-records/tagging-ldak-thin-control jobs=`awk &#39;{print $4}&#39; $file` mkdir $file-tmp for i in $jobs; do jobinfo $i | awk -F &quot;:&quot; -v i=$i &#39;$1~/Name/ {print i, $2}&#39; &gt;&gt; $file-tmp/name.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/State/ {print$2}&#39; &gt;&gt; $file-tmp/state.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Cores/ {print$2}&#39; &gt;&gt; $file-tmp/cores.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Used walltime/ {print $2 &quot;:&quot; $3 &quot;:&quot; $4}&#39; &gt;&gt; $file-tmp/time.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Max Mem/ {split($2,a,/[(]/ ); print a[1]}&#39; &gt;&gt; $file-tmp/mem.tmp done paste $file-tmp/name.tmp \\ $file-tmp/state.tmp \\ $file-tmp/cores.tmp \\ $file-tmp/time.tmp \\ $file-tmp/mem.tmp \\ | awk &#39;BEGIN{print &quot;ID name state cores time mem&quot;}{print $0}&#39; &gt; $file.out rm -r $file-tmp # merge tagging files----------------------------------------------------------- rm list.txt rm matlist.txt for j in {1..22}; do echo &quot;tagging-control/ldak-thin-hapmap3-chr-$j.tagging&quot; &gt;&gt; list.txt echo &quot;tagging-control/ldak-thin-hapmap3-chr-$j.matrix&quot; &gt;&gt; matlist.txt done dirout=tagging-control ./ldak5.1 --join-tagging $dirout/ldak-thin-hapmap3 --taglist list.txt --matlist matlist.txt # ldsc intercept---------------------------------------------------------------- dirin1=tagging-control dirin2=gwas-control dirout=sumher-control for i in {awake,bmi,chron,ever,fvc,height,quals,imp,neur,pulse,reaction,sbp,snoring,hyper}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 5G #SBATCH -c 1 #SBATCH -t 00:30:0 ./ldak5.1 --sum-hers ../$dirout/$i-sumher-ldak-thin \\ --tagfile ../$dirin1/ldak-thin-hapmap3.tagging \\ --summary ../$dirin2/$i-linear.summaries \\ --check-sums NO \\ --intercept YES &quot;&gt; sh_script/$i-sumher-ldak-thin done for i in {awake,bmi,chron,ever,fvc,height,quals,imp,neur,pulse,reaction,sbp,snoring,hyper}; do sbatch -A snpher ../sh_script/$i-sumher-ldak-thin done&gt;../job-records/sumher-ldak-thin-control 9.4.3 summary nm=control # original ldsc cd ldsc/out-control grep Intercept *ldsc.log | awk &#39;{split($1, a, /[-]/); split($3, b, /[()]/); print a[1], $2, b[2]}&#39; &gt; ../../summary/ldsc-$nm # sumher under gcta cd sumher-control grep Intercept_Estimate *gcta.extra | awk &#39;{ split($1, a, /[-]/); print a[1], $2}&#39; &gt;../summary/sumher-gcta-$nm-est grep Intercept_SD *gcta.extra | awk &#39;{ split($1, a, /[-]/); print a[1], $2}&#39; &gt;../summary/sumher-gcta-$nm-sd cd ../summary/ paste sumher-gcta-$nm-est sumher-gcta-$nm-sd | awk &#39;{print $1, $2, $4}&#39; &gt; sumher-gcta-$nm # suhmer under ldak-thin grep Intercept_Estimate *ldak-thin.extra | awk &#39;{ split($1, a, /[-]/); print a[1], $2}&#39; &gt;../summary/sumher-ldak-thin-$nm-est grep Intercept_SD *ldak-thin.extra | awk &#39;{ split($1, a, /[-]/); print a[1], $2}&#39; &gt;../summary/sumher-ldak-thin-$nm-sd cd ../summary/ paste sumher-ldak-thin-$nm-est sumher-ldak-thin-$nm-sd | awk &#39;{print $1, $2, $4}&#39; &gt; sumher-ldak-thin-$nm 9.5 HE 9.5.1 making grms # making grm ------------------------------------------------------------------- #::: # under gcta #::: fileout=gcta-all-control filein=geno-control snp=snps-control-gwas.use # all snps echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --partition normal #SBATCH --mem 60G #SBATCH -c 10 #SBATCH -t 08:0:0 #SBATCH --constraint \\&quot;s04|s05\\&quot; ./ldak5.1 --max-threads 10 \\ --calc-kins-direct ../kinship/$fileout \\ --bfile ../gen/$filein \\ --extract ../gen/$snp \\ --power -1 \\ --ignore-weights YES \\ --single YES &quot; &gt; sh_script/grm-all-snps sbatch -A snpher ../sh_script/grm-all-snps &gt; ../job-records/grm-all-snps-control # grm by snp blocks: right vs. left awk &#39;$1&lt;8 {print $2}&#39; geno-control.bim &gt; left-snps-control.use awk &#39;$1&gt;=8 {print $2}&#39; geno-control.bim &gt; right-snps-control.use filein=geno-control for i in left right; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --partition normal #SBATCH --mem 60G #SBATCH -c 10 #SBATCH -t 20:0:0 #SBATCH --constraint \\&quot;s04|s05\\&quot; ./ldak5.1 --max-threads 10 \\ --calc-kins-direct ../kinship/gcta-$i-control \\ --bfile ../gen/$filein \\ --extract ../gen/$i-snps-control.use \\ --power -1 \\ --ignore-weights YES \\ --single YES &quot; &gt; sh_script/grm-gcta-$i done for i in left right; do sbatch -A snpher ../sh_script/grm-gcta-$i done &gt; ../job-records/grm-gcta-by-snps-control #::: # under ldak-thin #::: #----------- # 1. thin snps #----------- snp=snps-control-gwas.use filein=geno-control for j in {1..22}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --partition normal #SBATCH --mem 10G #SBATCH -c 4 #SBATCH -t 4:0:0 #SBATCH --constraint \\&quot;s04|s05\\&quot; ./ldak5.1 --max-threads 4 \\ --window-prune 0.98 \\ --window-kb 100 \\ --extract ../gen/$snp \\ --bfile ../gen/$filein \\ --thin ../ldak-thin/chr$j-control \\ --chr $j &quot; &gt; sh_script/ldak-thin$j done # submit script for j in {1..22}; do sbatch -A snpher ../sh_script/ldak-thin$j done &gt; ../job-records/ldak-thin-control # check job completion--- file=job-records/ldak-thin-control jobs=`awk &#39;{print $4}&#39; $file` mkdir $file-tmp for i in $jobs; do jobinfo $i | awk -F &quot;:&quot; -v i=$i &#39;$1~/Name/ {print i, $2}&#39; &gt;&gt; $file-tmp/name.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/State/ {print$2}&#39; &gt;&gt; $file-tmp/state.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Cores/ {print$2}&#39; &gt;&gt; $file-tmp/cores.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Used walltime/ {print $2 &quot;:&quot; $3 &quot;:&quot; $4}&#39; &gt;&gt; $file-tmp/time.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Max Mem/ {split($2,a,/[(]/ ); print a[1]}&#39; &gt;&gt; $file-tmp/mem.tmp done paste $file-tmp/name.tmp \\ $file-tmp/state.tmp \\ $file-tmp/cores.tmp \\ $file-tmp/time.tmp \\ $file-tmp/mem.tmp \\ | awk &#39;BEGIN{print &quot;ID name state cores time mem&quot;}{print $0}&#39; &gt; $file.out rm -r $file-tmp # combine snp list cat ldak-thin/chr{1..22}-control.in &gt; ldak-thin/ldak-thin-control.in #---------------------- # 2. kinship matrix under ldak-thin #----------------------- fileout=ldak-thin-all-control filein=geno-control snp=ldak-thin-control.in echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --partition normal #SBATCH --mem 60G #SBATCH -c 10 #SBATCH -t 08:0:0 #SBATCH --constraint \\&quot;s04|s05\\&quot; ./ldak5.1 --max-threads 10 \\ --calc-kins-direct ../kinship/$fileout \\ --bfile ../gen/$filein \\ --extract ../ldak-thin/$snp \\ --power -0.25 \\ --ignore-weights YES \\ --single YES &quot; &gt; sh_script/ldak-thin-grm-all-snps sbatch -A snpher ../sh_script/ldak-thin-grm-all-snps &gt; ../job-records/ldak-thin-grm-all-snps-control # grm by snp blocks: right vs. left awk &#39;{split($1, a, /[:]/); if (a[1]&lt;8) print $1}&#39; \\ ldak-thin/ldak-thin-control.in &gt; gen/left-ldak-thin-control.snps awk &#39;{split($1, a, /[:]/); if (a[1]&gt;=8) print $1}&#39; \\ ldak-thin/ldak-thin-control.in &gt; gen/right-ldak-thin-control.snps for i in left right; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --partition normal #SBATCH --mem 60G #SBATCH -c 10 #SBATCH -t 08:0:0 #SBATCH --constraint \\&quot;s04|s05\\&quot; ./ldak5.1 --max-threads 10 \\ --calc-kins-direct ../kinship/ldak-thin-$i-control \\ --bfile ../gen/geno-control \\ --extract ../gen/$i-ldak-thin-control.snps \\ --power -0.25 \\ --ignore-weights YES \\ --single YES &quot; &gt; sh_script/ldak-thin-grm-$i done for i in left right; do sbatch -A snpher ../sh_script/ldak-thin-grm-$i done &gt; ../job-records/grm-ldak-thin-by-snps-control 9.5.2 estimation NEED To check what covariates to adjust for HE basic.covariates.use or covariates.use? # regress grm on covariates----------------------------------------------------- for grm in gcta-all-control gcta-left-control gcta-right-control ldak-thin-all-control ldak-thin-left-control ldak-thin-right-control; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 50G #SBATCH -c 5 #SBATCH -t 10:0:0 ./ldak5.1 --adjust-grm ../kinship/$grm.covar \\ --grm ../kinship/$grm \\ --covar ../phen/covariates.use \\ --max-threads 5 &quot;&gt; sh_script/$grm-adjust.sh done # submit jobs for grm in gcta-all-control gcta-left-control gcta-right-control ldak-thin-all-control ldak-thin-left-control ldak-thin-right-control; do sbatch -A snpher ../sh_script/$grm-adjust.sh done &gt; ../job-records/grm-adjust-for-HE-control # check job completion---------------------------------------------------------- file=job-records/grm-adjust-for-HE-control jobs=`awk &#39;{print $4}&#39; $file` mkdir $file-tmp for i in $jobs; do jobinfo $i | awk -F &quot;:&quot; -v i=$i &#39;$1~/Name/ {print i, $2}&#39; &gt;&gt; $file-tmp/name.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/State/ {print$2}&#39; &gt;&gt; $file-tmp/state.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Cores/ {print$2}&#39; &gt;&gt; $file-tmp/cores.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Used walltime/ {print $2 &quot;:&quot; $3 &quot;:&quot; $4}&#39; &gt;&gt; $file-tmp/time.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Max Mem/ {split($2,a,/[(]/ ); print a[1]}&#39; &gt;&gt; $file-tmp/mem.tmp done paste $file-tmp/name.tmp \\ $file-tmp/state.tmp \\ $file-tmp/cores.tmp \\ $file-tmp/time.tmp \\ $file-tmp/mem.tmp \\ | awk &#39;BEGIN{print &quot;ID name state cores time mem&quot;}{print $0}&#39; &gt; $file.out rm -r $file-tmp # HE under gcta----------------------------------------------------------------- mkdir he-control dirout=he-control for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do for k in all left right; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 2G #SBATCH -c 1 #SBATCH -t 00:30:0 ./ldak5.1 --he ../$dirout/$i-he-gcta-$k \\ --pheno ../phen/continuous-traits/$i.raw.pheno \\ --grm ../kinship/gcta-$k-control.covar \\ --kinship-details NO \\ --check-root NO \\ --covar ../phen/covariates.use \\ --max-threads 1 \\ --memory-save YES &quot;&gt; sh_script/$i-he-gcta-$k-snps-control.sh done done # submit files------------------------------------------------------------------ for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do for k in all left right; do sbatch -A snpher ../sh_script/$i-he-gcta-$k-snps-control.sh done done &gt; ../job-records/he-gcta-control # HE under ldak-thin------------------------------------------------------------ dirout=he-control for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do for k in all left right; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 2G #SBATCH -c 1 #SBATCH -t 0:30:0 ./ldak5.1 --he ../$dirout/$i-he-ldak-thin-$k \\ --pheno ../phen/continuous-traits/$i.raw.pheno \\ --grm ../kinship/ldak-thin-$k-control.covar \\ --kinship-details NO \\ --check-root NO \\ --covar ../phen/covariates.use \\ --max-threads 1 \\ --memory-save YES &quot;&gt; sh_script/$i-he-ldak-thin-$k-control.sh done done # submit files------------------------------------------------------------------ for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do for k in all left right; do sbatch -A snpher ../sh_script/$i-he-ldak-thin-$k-control.sh done done &gt; ../job-records/he-ldak-thin-control 9.5.3 summary #:::::::::::: # under gcta #:::::::::::: nm=control # extract h2 estimates --------------------------------------------------------- # right rm summary/he-gcta-$nm.right for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do outfile=he-$nm/$i-he-gcta-right.he awk -v i=$i &#39;$1==&quot;Her_All&quot; {print i, $2, $3}&#39; $outfile &gt;&gt; summary/he-gcta-$nm.right done # left rm summary/he-gcta-$nm.left for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do outfile=he-$nm/$i-he-gcta-left.he awk -v i=$i &#39;$1==&quot;Her_All&quot; {print i, $2, $3}&#39; $outfile &gt;&gt; summary/he-gcta-$nm.left done # all rm summary/he-gcta-$nm.all for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do outfile=he-$nm/$i-he-gcta-all.he awk -v i=$i &#39;$1==&quot;Her_All&quot; {print i, $2, $3}&#39; $outfile &gt;&gt; summary/he-gcta-$nm.all done # inflation test---------------------------------------------------------------- R full=read.table(paste0(&quot;summary/he-gcta-control.all&quot;), header=F) left=read.table(paste0(&quot;summary/he-gcta-control.left&quot;), header=F) right=read.table(paste0(&quot;summary/he-gcta-control.right&quot;), header=F) names(full)=names(left)=names(right)=c(&quot;code&quot;,&quot;h2&quot;,&quot;se&quot;) # some analyses did not complete --&gt; match dataframes dim(full);dim(left);dim(right) common=intersect(full$code, left$code) common=intersect(common, right$code) m1=match(common, right$code) m2=match(common, full$code) m3=match(common, left$code) right=right[m1,] full=full[m2,] left=left[m3,] for(i in 1:dim(full)[1]){ est1=left$h2[i] sd1=left$se[i] est2=right$h2[i] sd2=right$se[i] est=full$h2[i] sd=full$se[i] N=100000 d1=rnorm(N,est1,sd1) d2=rnorm(N,est2,sd2) d=rnorm(N,est,sd) p=1-mean(d1+d2-d&gt;=0) out0=data.frame(code=full$code[i], right_est=est2, right_sd=sd2, left_est=est1, left_sd=sd1, all_est=est, all_sd=sd, p_inflation=p) if(i==1){out=out0}else{out=rbind(out,out0)} } write.table(out, paste0(&quot;summary/he-gcta-inflation-control.txt&quot;), col.names=T, row.names=F, quote=F) #:::::::::::: # under ldak-thin #:::::::::::: nm=control # extract h2 estimates --------------------------------------------------------- # right rm summary/he-ldak-thin-$nm.right for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do outfile=he-$nm/$i-he-ldak-thin-right.he awk -v i=$i &#39;$1==&quot;Her_All&quot; {print i, $2, $3}&#39; $outfile &gt;&gt; summary/he-ldak-thin-$nm.right done # left rm summary/he-ldak-thin-$nm.left for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do outfile=he-$nm/$i-he-ldak-thin-left.he awk -v i=$i &#39;$1==&quot;Her_All&quot; {print i, $2, $3}&#39; $outfile &gt;&gt; summary/he-ldak-thin-$nm.left done # all rm summary/he-ldak-thin-$nm.all for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do outfile=he-$nm/$i-he-gcta-all.he awk -v i=$i &#39;$1==&quot;Her_All&quot; {print i, $2, $3}&#39; $outfile &gt;&gt; summary/he-ldak-thin-$nm.all done # inflation test---------------------------------------------------------------- R full=read.table(paste0(&quot;summary/he-ldak-thin-control.all&quot;), header=F) left=read.table(paste0(&quot;summary/he-ldak-thin-control.left&quot;), header=F) right=read.table(paste0(&quot;summary/he-ldak-thin-control.right&quot;), header=F) names(full)=names(left)=names(right)=c(&quot;code&quot;,&quot;h2&quot;,&quot;se&quot;) # some analyses did not complete --&gt; match dataframes dim(full);dim(left);dim(right) common=intersect(full$code, left$code) common=intersect(common, right$code) m1=match(common, right$code) m2=match(common, full$code) m3=match(common, left$code) right=right[m1,] full=full[m2,] left=left[m3,] for(i in 1:dim(full)[1]){ est1=left$h2[i] sd1=left$se[i] est2=right$h2[i] sd2=right$se[i] est=full$h2[i] sd=full$se[i] N=100000 d1=rnorm(N,est1,sd1) d2=rnorm(N,est2,sd2) d=rnorm(N,est,sd) p=1-mean(d1+d2-d&gt;=0) out0=data.frame(code=full$code[i], right_est=est2, right_sd=sd2, left_est=est1, left_sd=sd1, all_est=est, all_sd=sd, p_inflation=p) if(i==1){out=out0}else{out=rbind(out,out0)} } write.table(out, paste0(&quot;summary/he-ldak-thin-inflation-control.txt&quot;), col.names=T, row.names=F, quote=F) "],["inclusive-gwas.html", "10 inclusive GWAS 10.1 QC 10.2 gwas-telomere length 10.3 notes/concerns", " 10 inclusive GWAS Here we conduct a GWAS that mimic the QC steps taken by some of the most inclusive GWAS studies. For example, the GWAS conducted by Codd et al. (2021) on telomere length has the following QC step, which resulted in n = 472,174 and m = 19.4 million SNPs We used imputed genotypes available in the UKB2 for the GWAS. To ensure quality, we restricted the analysis to variants with a MAF of ≥0.1% (where imputation accuracy is greatest) and an INFO score of ≥0.3. We tested 19.4 million variants using the BOLT-LMM package, adjusting for age, sex, array and the first ten principal components (PCs). The analysis was run separately for chromosome 23, where males were coded as 0/2. Here we want to test if the test statistics from GWAS conducted in such a way are inflated using the proposed method. We do not have access to telomere length, but we can use the 14 traits as examples instead. 10.1 QC #:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: # extract covariates #:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: # This has been done under &#39;Good GWAS&#39; section. Here we just want to extract from the file R options(scipen=999) require(vroom) dat=vroom(&quot;phen/covariates.phen&quot;, col_names=T) pc=paste0(&quot;pc&quot;,1:10) cov=c(&quot;eid&quot;,&quot;eid&quot;,&quot;age&quot;,&quot;geno_batch&quot;,pc) out=dat[,cov] write.table(out,&quot;phen/covariates-inclusive-gwas.use&quot;, col.names=F, row.names=F, quote=F) write.table(cov,&quot;phen/covariates-inclusive-gwas.use-names&quot;, col.names=F, row.names=F, quote=F) sel=out[complete.cases(out),] # n = 488,244 write.table(sel[,1:2], &quot;complete-cases-covariates-inclusive-gwas.id&quot;, col.names=F, row.names=F, quote=F) #:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: # id list of complete cases: covariates &amp; phenotypes #:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: # note: to remain as much people as possible, we did not select all 14 traits. but 9. # for these traits, n = 467, 104 have complete data cp complete-cases-covariates-inclusive-gwas.id inclusive-gwas.id dir=phen/continuous-traits/ # {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper} for tt in {awake,bmi,ever,height,imp,quals,reaction,imp,hyper}; do mv inclusive-gwas.id temp awk &#39;(NR==FNR){a[$1];next}($1 in a){print $1, $2}&#39; temp $dir/$tt.raw.pheno &gt; inclusive-gwas.id wc -l inclusive-gwas.id echo $tt done rm temp #:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: # extract genotypes #:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: # QC SNPs----------------------------------------------------------------------- # stating number of SNPs= for j in {1..22}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 20G #SBATCH -c 3 #SBATCH -t 10:0:0 ./plink2 --pfile ../gen/geno_plink/bhr$j \\ --keep ../inclusive-gwas.id \\ --hwe 0.0001 \\ --maf 0.001 \\ --hard-call-threshold .05 \\ --mach-r2-filter 0.3 2 \\ --make-bed \\ --memory 20000 \\ --out ../gen/tmp/bhr$j \\ --threads 3 &quot;&gt; sh_script/chr$j.sh done # submit jobs------------------------------------------------------------------- for j in {1..22}; do sbatch -A snpher ../sh_script/chr$j.sh done &gt; ../job-records/qc-inclusive-gwas # check job completion---------------------------------------------------------- file=job-records/qc-inclusive-gwas jobs=`awk &#39;{print $4}&#39; $file` mkdir $file-tmp for i in $jobs; do jobinfo $i | awk -F &quot;:&quot; -v i=$i &#39;$1~/Name/ {print i, $2}&#39; &gt;&gt; $file-tmp/name.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/State/ {print$2}&#39; &gt;&gt; $file-tmp/state.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Cores/ {print$2}&#39; &gt;&gt; $file-tmp/cores.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Used walltime/ {print $2 &quot;:&quot; $3 &quot;:&quot; $4}&#39; &gt;&gt; $file-tmp/time.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Max Mem/ {split($2,a,/[(]/ ); print a[1]}&#39; &gt;&gt; $file-tmp/mem.tmp done paste $file-tmp/name.tmp \\ $file-tmp/state.tmp \\ $file-tmp/cores.tmp \\ $file-tmp/time.tmp \\ $file-tmp/mem.tmp \\ | awk &#39;BEGIN{print &quot;ID name state cores time mem&quot;}{print $0}&#39; &gt; $file.out rm -r $file-tmp # merge files------------------------------------------------------------------- rm gen/bfile-inclusive-gwas.list for j in {1..22}; do echo &quot;../gen/tmp/bhr$j&quot; &gt;&gt; gen/bfile-inclusive-gwas.list done echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 80G #SBATCH -c 10 #SBATCH -t 10:0:0 ./ldak5.1 --make-bed ../gen/geno-inclusive-gwas \\ --mbfile ../gen/bfile-inclusive-gwas.list \\ --max-threads 10 \\ --exclude-dups YES &quot;&gt; sh_script/mbfile-inclusive-gwas.sh # submit the script------------------------------------------------------------- sbatch -A snpher ../sh_script/mbfile-inclusive-gwas.sh &gt;../job-records/mbfile-inclusive-gwas # compute info score------------------------------------------------------------ for j in {1..22}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 20G #SBATCH -c 3 #SBATCH -t 5:0:0 ./plink2 --pfile ../gen/geno_plink/bhr$j \\ --threads 3 \\ --keep ../inclusive-gwas.id \\ --memory 20000 \\ --freq cols=chrom,ref,alt,altfreq,machr2 \\ --out ../gen/info/chr$j &quot;&gt; sh_script/info-chr$j.sh done # submit file------------------------------------------------------------------- for j in {1..22}; do sbatch -A snpher ../sh_script/info-chr$j.sh done &gt; ../job-records/compute-info-score-inclusive-gwas # combine files ---------------------------------------------------------------- dir=gen/info rm $dir/inclusive-gwas-afreq for i in {1..22}; do if [ $i == 1 ]; then awk &#39;{print $0}&#39; $dir/chr$i.afreq &gt; $dir/inclusive-gwas-afreq else awk &#39;NR&gt;1 {print $0}&#39; $dir/chr$i.afreq &gt;&gt; $dir/inclusive-gwas-afreq fi done #:::::::::::::::::: # SNP list #:::::::::::::::::: # MAF &amp; call-rate awk &lt; gen/bfile-inclusive-gwas.stat &#39;($5&gt;.001 &amp;&amp; $6&gt;=0.95 &amp;&amp; NR&gt;1){print $1}&#39; &gt; snps-inclusive-gwas.use # m = SNPs 10.2 gwas-telomere length 10.2.1 aver2_j Here we want to check for evidence of inflation in the telomere GWAS statistics (Codd et al. 2021) due to confouding from population stratification. Here are the steps: download the GWAS stats (https://figshare.com/s/caa99dc0f76d62990195) randomly chose 10k SNPs from each side of the genome compute aver2_j for the 20k SNPs check if the chi square test stats vary with respect to aver2_j. We show below that the slope of the regression line is not sig. different from zero. Hence, there is no evidence of confounding by the proposed method. It should be noted though that we used the genotype data of n = 487,409 individuals to compute aver2_j, and the original GWAS was based on n = 472,174. #::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: # select SNPs &amp; organize data #::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: # download gwas stats----------------------------------------------------------- mkdir gwas-telomere wget https://figshare.com/ndownloader/files/28414941?private_link=caa99dc0f76d62990195 # m = 20,134,422 SNPs # organize data: snp name &amp; chisq ---------------------------------------------- infile=gwas-telomere/UKB_telomere_gwas_summarystats.tsv.gz outfile=gwas-telomere/telemere-gwas-organized zcat $infile | awk -F &#39;\\t&#39; &#39;BEGIN {print &quot;chr base_pair_location chr_base rs chisq&quot;} NR &gt;1 {print $3, $4,$3&quot;:&quot;$4, $1, ($8/$9)^2}&#39; &gt; $outfile # hapmap3 SNPs------------------------------------------------------------------ infile1=doug/ukbb.ldsc infile2=gwas-telomere/telemere-gwas-organized outfile=gwas-telomere/telemere-gwas-organized-hm3 awk &#39;NR==FNR{a[$3];next} ($3 in a || FNR==1 ){print $0}&#39; $infile1 $infile2 &gt; $outfile # choose snp lists-------------------------------------------------------------- # choose 40k for each side as the pool for selection m=40000 infile=gwas-telomere/telemere-gwas-organized-hm3 left=inflation/gwas-telomere/left-snps-pool right=inflation/gwas-telomere/right-snps-pool awk &#39;$1&lt;8 &amp;&amp; NR &gt; 1 {print $1, $2, $3}&#39; $infile | shuf | head -n $m &gt;$left awk &#39;$1&gt;=8 &amp;&amp; NR &gt; 1 {print $1, $2, $3}&#39; $infile | shuf | head -n $m &gt;$right # entire snp list of ukbb out=inflation/gwas-telomere/ukbb-bhr-all-snps rm $out for i in {1..22};do gen=gen/geno_plink/bhr$i.pvar awk &#39;{print $1, $2, $1&quot;:&quot;$2, $3}&#39; $gen &gt;&gt; $out done # wc -l gen/geno_plink/bhr{1..22}.pvar # put the chosen 40k snps in the right format snp=inflation/gwas-telomere/ukbb-bhr-all-snps leftin=inflation/gwas-telomere/left-snps-pool rightin=inflation/gwas-telomere/right-snps-pool leftout=inflation/gwas-telomere/left-snps-tmp rightout=inflation/gwas-telomere/right-snps-tmp awk &#39;(NR==FNR){a[$3];next} ($3 in a){print $4}&#39; $leftin $snp &gt; $leftout awk &#39;(NR==FNR){a[$3];next} ($3 in a){print $4}&#39; $rightin $snp &gt; $rightout # note: &gt; 40k are in the list of each side because some snps have the same basepair... #::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: # extract genotypes of the bfiles #::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: left=inflation/gwas-telomere/left-snps-tmp right=inflation/gwas-telomere/right-snps-tmp out=inflation/gwas-telomere/snp-all awk &#39;{print $0}&#39; $left $right &gt; $out # extract data ----------------------------------------------------------------- for j in {1..22}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 4G #SBATCH -c 3 #SBATCH -t 00:30:0 ./plink2 --pfile ../gen/geno_plink/bhr$j \\ --extract ../inflation/gwas-telomere/snp-all \\ --make-bed \\ --out ../gen/tmp/bhr$j \\ --memory 20000 \\ --threads 3 &quot;&gt; sh_script/chr$j.sh done # submit jobs------------------------------------------------------------------- for j in {1..22}; do sbatch -A snpher ../sh_script/chr$j.sh done &gt; ../job-records/bfile-telomere # check job completion---------------------------------------------------------- file=job-records/bfile-telomere jobs=`awk &#39;{print $4}&#39; $file` mkdir $file-tmp for i in $jobs; do jobinfo $i | awk -F &quot;:&quot; -v i=$i &#39;$1~/Name/ {print i, $2}&#39; &gt;&gt; $file-tmp/name.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/State/ {print$2}&#39; &gt;&gt; $file-tmp/state.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Cores/ {print$2}&#39; &gt;&gt; $file-tmp/cores.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Used walltime/ {print $2 &quot;:&quot; $3 &quot;:&quot; $4}&#39; &gt;&gt; $file-tmp/time.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Max Mem/ {split($2,a,/[(]/ ); print a[1]}&#39; &gt;&gt; $file-tmp/mem.tmp done paste $file-tmp/name.tmp \\ $file-tmp/state.tmp \\ $file-tmp/cores.tmp \\ $file-tmp/time.tmp \\ $file-tmp/mem.tmp \\ | awk &#39;BEGIN{print &quot;ID name state cores time mem&quot;}{print $0}&#39; &gt; $file.out rm -r $file-tmp # merge files------------------------------------------------------------------- rm gen/bfile.list for j in {1..22}; do echo &quot;../gen/tmp/bhr$j&quot; &gt;&gt; gen/bfile.list done echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 20G #SBATCH -c 3 #SBATCH -t 01:00:0 ./ldak5.1 --make-bed ../gen/geno-telomere \\ --mbfile ../gen/bfile.list \\ --max-threads 3 \\ --exclude-dups YES &quot;&gt; sh_script/mbfile-telomere.sh # submit the script------------------------------------------------------------- sbatch -A snpher ../sh_script/mbfile-telomere.sh &gt;../job-records/mbfile-telomere # compute info score------------------------------------------------------------ for j in {1..22}; do snp=../inflation/gwas-telomere/snp-all out=../gen/info/chr$j-telomere echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 5G #SBATCH -c 3 #SBATCH -t 00:20:0 ./plink2 --pfile ../gen/geno_plink/bhr$j \\ --threads 3 \\ --extract $snp \\ --memory 20000 \\ --freq cols=chrom,ref,alt,altfreq,machr2 \\ --out $out &quot;&gt; sh_script/info-chr$j.sh done # submit file------------------------------------------------------------------- for j in {1..22}; do sbatch -A snpher ../sh_script/info-chr$j.sh done &gt; ../job-records/compute-info-telomere # combine files ---------------------------------------------------------------- dir=gen/info rm $dir/telomere-afreq for i in {1..22}; do if [ $i == 1 ]; then awk &#39;{print $0}&#39; $dir/chr$i-telomere.afreq &gt; $dir/telomere-afreq else awk &#39;NR&gt;1 {print $0}&#39; $dir/chr$i-telomere.afreq &gt;&gt; $dir/telomere-afreq fi done #::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: # Finalize the 10k SNP list of each side #::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: m=10000 snp=gen/geno-telomere.bim leftin=inflation/gwas-telomere/left-snps-tmp rightin=inflation/gwas-telomere/right-snps-tmp leftout=inflation/gwas-telomere/left-snps rightout=inflation/gwas-telomere/right-snps awk &#39;(NR==FNR){a[$1];next} ($2 in a){print $2}&#39; $leftin $snp | shuf | head -$m &gt; $leftout awk &#39;(NR==FNR){a[$1];next} ($2 in a){print $2}&#39; $rightin $snp | shuf | head -$m &gt; $rightout #::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: # compute ave r^2_j #::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: lista=../inflation/gwas-telomere/right-snps listb=../inflation/gwas-telomere/left-snps bfile=../gen/geno-telomere out=../inflation/gwas-telomere/out/10k-snps echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 80G #SBATCH -c 7 #SBATCH -t 00:30:0 ./ldak5.2 --max-threads 7 \\ --calc-inflation $out \\ --bfile $bfile \\ --lista $lista \\ --listb $listb &quot;&gt;sh_script/calc-r-10k-snps # submit the job sbatch -A snpher ../sh_script/calc-r-10k-snps &gt;../job-records/calc-r-telomere # compute ave r_j^2 for each i------------------------------------------------- R require(vroom) nm=&quot;10k-snps&quot; dat=vroom(paste0(&quot;inflation/gwas-telomere/out/&quot;,nm,&quot;.pairwise&quot;), col_names=F) lista=read.table(paste0(&quot;inflation/gwas-telomere/out/&quot;,nm,&quot;.predictorsa&quot;), stringsAsFactors = F) listb=read.table(paste0(&quot;inflation/gwas-telomere/out/&quot;,nm,&quot;.predictorsb&quot;), stringsAsFactors = F) dat=dat[,-c(10001)]^2 outb=data.frame(predictor=listb$V1, ave_r2=apply(dat,2, mean)) outa=data.frame(predictor=lista$V1, ave_r2=apply(dat,1, mean)) out=rbind(outa,outb) write.table(out,paste0(&quot;summary/ave-r2-&quot;,nm, &quot;-ukbb-telomere&quot;), col.names=F, row.names=F, quote=F) 10.2.2 organize data # NEED TO CHECK THE FOLLOWING CODE aver2=summary/ave-r2-10k-snps-ukbb-telomere rs=doug/ukbb.ldsc gwas=gwas-telomere/telomere-gwas-organized-hm3 out=gwas-telomere/telomere.out awk &#39;NR==FNR {a[$1]; b[$1]=$2; next} ($1 in a) {print $1, b[$1], $2}&#39; $rs $aver2 &gt; tmp/aver2.tmp awk &#39;BEGIN{print &quot;snp rs chisq aver2&quot;} NR==FNR {a[$2]; b[$2]=$1; c[$2]=$3; next} ($4 in a) {print b[$4], $4, $5, c[$4] }&#39; tmp/aver2.tmp $gwas &gt; $out 10.2.3 chisq ~ aver2_j require(vroom) dat=vroom(&quot;gwas-telomere/telomere.out&quot;, col_names=T) # estimate slope: chisq ~ aver2_j----------------------------------------------- mod=lm(chisq ~ aver2,data=dat) summary(mod) #Coefficients: # Estimate Std. Error t value Pr(&gt;|t|) #(Intercept) 1.65142 0.09146 18.057 &lt;2e-16 *** #aver2 -196.61028 248.64693 -0.791 0.429 # make the plot: binned aver2_j------------------------------------------------- # bin a variable by quantile cutoff=quantile(dat$aver2, probs = seq(0, 1, 0.005), na.rm=T) dat$bin=cut(dat$aver2, breaks=cutoff, labels=1:(length(cutoff)-1)) # average chisq by bin values out=data.frame(chisq_ave=tapply(dat$chisq,INDEX=dat$bin, mean)) out$bin_val=tapply(dat$aver2,INDEX=dat$bin, mean) png(&quot;fig/chisq-by-aver2-bin-telomere.png&quot;, width = 10, height = 10, units = &quot;cm&quot;, res=600) start=0 end=max(out$chisq_ave) plot(out$bin_val, out$chisq_ave, xlab=&quot;ave r2&quot;, ylab=&quot;ave chisq&quot;, ylim=c(start,8), main=&quot;&quot;, las=1, cex = 0.8, pch=21, bg=&quot;orange&quot;, col=&quot;white&quot;, lwd=0.5) dev.off() # make the plot: raw aver2_j &amp; chisq-------------------------------------------- png(&quot;fig/chisq-by-aver2-bin-telomere-raw.png&quot;, width = 10, height = 10, units = &quot;cm&quot;, res=600) start=0 end=max(dat$chisq) plot(dat$aver2, dat$chisq, xlab=&quot;ave r2&quot;, ylab=&quot;chisq&quot;, ylim=c(start,400), main=&quot;&quot;, las=1, cex = 0.8, pch=21, bg=&quot;orange&quot;, col=&quot;white&quot;, lwd=0.5) dev.off() 10.3 notes/concerns Telomere length GWAS: The QC seems too rough so that some SNPs have multiple alleles. "],["related-individuals.html", "11 related individuals 11.1 genotyped SNPs 11.2 hapmap3 SNPs 11.3 mix unrel &amp; rel", " 11 related individuals 11.1 genotyped SNPs 11.1.1 aver2_j Previously we performed analyses on icd10 traits using related individuals. Here are relevant files: bfile: gen/geno-rel: created using icd10/related.inds id lists: 56757 icd10/related.inds 56754 relatedness/cut.05.related: relatedness &gt;= 0.05. 56753 relatedness/cut.125.related 48197 relatedness/cut.25.related 18294 relatedness/cut.5.related snp list after QC: gen/snps-rel-inds.use : 627,320 SNPs #::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: # create id lists &amp; snp lists #::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: # unrelated ids---------------------------------------------------------------- # serve as control groups n=(56753 48197 18294) nm=(cut.125 cut.25 cut.5) for i in {0..2}; do shuf rand.100000 | head -n ${n[$i]} &gt; white-unrel-rand-control-for-${nm[$i]} done # snp list---------------------------------------------------------------------- # common snps of related &amp; unrelated unrel=gen/snps-unrel-inds.use # 1,103,209 rel=gen/snps-rel-inds.use # 627,320 SNPs awk &#39;NR==FNR{a[$1];next} ($1 in a) {print $1}&#39; $unrel $rel &gt; gen/common-unrel-rel-snps # 153,313 # lista &amp; listb # this will be common for all id lists m=10000 infile=gen/common-unrel-rel-snps left=inflation/related/left-snps right=inflation/related/right-snps awk &#39;{split($1, a, &quot;:&quot;); if (a[1]&lt;8) print $1 }&#39; $infile | shuf | head -n $m &gt;$left awk &#39;{split($1, a, &quot;:&quot;); if (a[1]&gt;=8) print $1 }&#39; $infile | shuf | head -n $m &gt;$right #::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: # compute ave r^2_j #::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: for nm in {cut.125,cut.25,cut.5}; do # common snp lists lista=../inflation/related/right-snps listb=../inflation/related/left-snps # related individuals id=../relatedness/$nm.related bfile=../gen/geno-rel out=../inflation/related/out/10k-snps-$nm-rel echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 20G #SBATCH -c 2 #SBATCH -t 00:10:0 ./ldak5.2 --max-threads 2 \\ --calc-inflation $out \\ --bfile $bfile \\ --keep $id \\ --lista $lista \\ --listb $listb &quot;&gt;sh_script/calc-r-10k-snps-$nm-rel # unrelated controls id=../white-unrel-rand-control-for-$nm bfile=../gen/geno-unrel out=../inflation/related/out/10k-snps-$nm-unrel echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 20G #SBATCH -c 2 #SBATCH -t 00:10:0 ./ldak5.2 --max-threads 2 \\ --calc-inflation $out \\ --bfile $bfile \\ --keep $id \\ --lista $lista \\ --listb $listb &quot;&gt;sh_script/calc-r-10k-snps-$nm-unrel done # submit the job for nm in {cut.125,cut.25,cut.5}; do sbatch -A snpher ../sh_script/calc-r-10k-snps-$nm-rel sbatch -A snpher ../sh_script/calc-r-10k-snps-$nm-unrel done&gt;../job-records/calc-r-related # compute ave r_j^2 for each i------------------------------------------------- R require(vroom) cut=c(&quot;cut.125&quot;,&quot;cut.25&quot;,&quot;cut.5&quot;) rel=c(&quot;rel&quot;,&quot;unrel&quot;) for(j in 1:length(rel)){ for(i in 1:length(cut)){ nm=paste0(&quot;10k-snps-&quot;,cut[i],&quot;-&quot;,rel[j]) dat=vroom(paste0(&quot;inflation/related/out/&quot;,nm,&quot;.pairwise&quot;), col_names=F) lista=read.table(paste0(&quot;inflation/related/out/&quot;,nm,&quot;.predictorsa&quot;), stringsAsFactors = F) listb=read.table(paste0(&quot;inflation/related/out/&quot;,nm,&quot;.predictorsb&quot;), stringsAsFactors = F) dat=dat[,-c(10001)]^2 outb=data.frame(predictor=listb$V1, ave_r2=apply(dat,2, mean)) outa=data.frame(predictor=lista$V1, ave_r2=apply(dat,1, mean)) out=rbind(outa,outb) write.table(out,paste0(&quot;summary/ave-r2-&quot;,nm), col.names=F, row.names=F, quote=F) } } #::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: # summary #::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: # check if mean r^2_j differs for rel vs. unrel cut=c(&quot;cut.125&quot;,&quot;cut.25&quot;,&quot;cut.5&quot;) for(i in 1:length(cut)){ nm_rel=paste0(&quot;ave-r2-10k-snps-&quot;,cut[i],&quot;-rel&quot;) nm_unrel=paste0(&quot;ave-r2-10k-snps-&quot;,cut[i],&quot;-unrel&quot;) dat_rel=read.table(paste0(&quot;summary/&quot;,nm_rel),stringsAsFactors = F) dat_unrel=read.table(paste0(&quot;summary/&quot;,nm_unrel),stringsAsFactors = F) out0=data.frame(rel=cut[i], rel_ave=mean(dat_rel$V2), rel_sd=sd(dat_rel$V2), unrel_ave=mean(dat_unrel$V2), unrel_sd=sd(dat_unrel$V2), stringsAsFactors = F) if(i==1){out1=out0}else{out1=rbind(out1,out0)} } 11.1.2 gwas # create directories------------------------------------------------------------ for j in {cut.125,cut.25,cut.5}; do for i in {rel,unrel};do mkdir gwas-$j-$i done done # gwas ------------------------------------------------------------------------- for j in {cut.125,cut.25,cut.5}; do for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do # related individuals---------------------- out=../gwas-$j-rel/$i-linear id=../relatedness/$j.related snp=../gen/snps-rel-inds.use bfile=../gen/geno-rel echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 8G #SBATCH -c 1 #SBATCH -t 8:0:0 ./ldak5.1 --linear $out \\ --pheno ../phen/continuous-traits/$i.raw.pheno \\ --bfile $bfile \\ --keep $id \\ --extract $snp \\ --covar ../phen/covariates.use \\ --max-threads 2 \\ &quot;&gt; sh_script/$i-linear-$j-rel.sh # unrelated individuals---------------------- out=../gwas-$j-unrel/$i-linear id=../white-unrel-rand-control-for-$j snp=../gen/snps-unrel-inds.use bfile=../gen/geno-unrel echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 8G #SBATCH -c 1 #SBATCH -t 8:0:0 ./ldak5.1 --linear $out \\ --pheno ../phen/continuous-traits/$i.raw.pheno \\ --bfile $bfile \\ --keep $id \\ --extract $snp \\ --covar ../phen/covariates.use \\ --max-threads 2 \\ &quot;&gt; sh_script/$i-linear-$j-unrel.sh done done # submit jobs for j in {cut.125,cut.25,cut.5}; do for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do sbatch -A snpher ../sh_script/$i-linear-$j-rel.sh sbatch -A snpher ../sh_script/$i-linear-$j-unrel.sh done done&gt;../job-records/gwas-related # check job completion file=job-records/gwas-related jobs=`awk &#39;{print $4}&#39; $file` mkdir $file-tmp for i in $jobs; do jobinfo $i | awk -F &quot;:&quot; -v i=$i &#39;$1~/Name/ {print i, $2}&#39; &gt;&gt; $file-tmp/name.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/State/ {print$2}&#39; &gt;&gt; $file-tmp/state.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Cores/ {print$2}&#39; &gt;&gt; $file-tmp/cores.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Used walltime/ {print $2 &quot;:&quot; $3 &quot;:&quot; $4}&#39; &gt;&gt; $file-tmp/time.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Max Mem/ {split($2,a,/[(]/ ); print a[1]}&#39; &gt;&gt; $file-tmp/mem.tmp done paste $file-tmp/name.tmp \\ $file-tmp/state.tmp \\ $file-tmp/cores.tmp \\ $file-tmp/time.tmp \\ $file-tmp/mem.tmp \\ | awk &#39;BEGIN{print &quot;ID name state cores time mem&quot;}{print $0}&#39; &gt; $file.out rm -r $file-tmp 11.1.3 organize data #::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: # compute MAF #::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: for j in {cut.125,cut.25,cut.5}; do for i in {rel,unrel};do out=../gen/maf/geno-$j-$i if [ $i == rel ]; then bfile=../gen/geno-rel id=../relatedness/$j.related else bfile=../gen/geno-unrel id=../white-unrel-rand-control-for-$j fi echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 10G #SBATCH -c 2 #SBATCH -t 5:0:0 ./ldak5.1 --calc-stats $out \\ --bfile $bfile \\ --keep $id &quot;&gt; sh_script/calc-maf-$j-$i.sh done done # submit script for j in {cut.125,cut.25,cut.5}; do for i in {rel,unrel};do sbatch -A snpher ../sh_script/calc-maf-$j-$i.sh done done&gt;../job-records/calc-maf-rel #::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: # extract LD scores #::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: # we do this for related individuals. # ld scores of snp list for unrelated id: snps-unrel-maf.001.ldscore # convert snp list to rs system ------------------------------------------------ infile=gen/snps-rel-inds.use outfile=gen/snps-rel-rs awk &#39;(NR==FNR){a[$1]; b[$1]=$2; next} ($1 in a){print b[$1], $2}&#39; doug/ukbb.ldsc $infile &gt; $outfile # extract ld scores ----------------------------------------------------------- dir=ldsc/eur_w_ld_chr for chrom in {1..22}; do zcat $dir/$chrom.l2.ldscore.gz | awk &#39;NR&gt;1 {print $2, $6}&#39; &gt; ldscore awk &#39;(NR==FNR){a[$1];next}($1 in a){print $0}&#39; gen/snps-rel-rs ldscore &gt; temp if [ $chrom -eq 1 ] then mv temp snps-rel.ldscore else cat snps-rel.ldscore temp &gt; temp2 mv temp2 snps-rel.ldscore fi echo $chrom done #::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: # put info together #::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: # maf: gen/maf/geno-[cut.125]-[rel] # chi square : gwas-[cut.125]-[rel]/[trait]-linear.summaries # ave r^2_j: summary/ave-r2-10k-snps-[cut.25]-[unrel] # ld score from ldsc ref panel: snps-unrel-maf.001.ldscore; snps-rel.ldscore # fixed file rs=doug/ukbb.ldsc for j in {cut.125,cut.25,cut.5}; do for i in {rel,unrel};do # files vary depending on j &amp;/or i maf=gen/maf/geno-$j-$i.stats # use as the snp list to integrate all info aver2=summary/ave-r2-10k-snps-$j-$i if [ $i == rel ]; then ldsc=snps-rel.ldscore else ldsc=snps-unrel-maf.001.ldscore fi # create temporary files awk &#39;NR &gt; 1 {print $1, $5 }&#39; $maf &gt; tmp/maf.tmp awk &#39;NR==FNR {a[$2]; b[$2]=$1; next} ($1 in a) {print b[$1], $0}&#39; $rs $ldsc &gt; tmp/ldsc.tmp1 # here we make sure the order of the rows are the same as maf.tmp awk &#39;NR==FNR {a[$1]; b[$1]=$2; c[$1]=$3 ; next} {if ($1 in a) print b[$1], c[$1]; else print &quot;NA&quot;}&#39; tmp/ldsc.tmp1 tmp/maf.tmp &gt; tmp/ldsc.tmp awk &#39;NR==FNR {a[$1]; b[$1]=$2; next} {if ($1 in a) print b[$1]; else print &quot;NA&quot; }&#39; $aver2 tmp/maf.tmp &gt; tmp/aver2.tmp for trait in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do # files vary with j, i and trait gwas=gwas-$j-$i/$trait-linear.summaries out=gwas-related-all-out/$trait-$j-$i.out awk &#39;NR==FNR {a[$1]; b[$1]=$5; next} {if ($1 in a) print b[$1]; else print &quot;NA&quot; }&#39; $gwas tmp/maf.tmp &gt; tmp/gwas.tmp # put info together paste tmp/maf.tmp \\ tmp/gwas.tmp \\ tmp/aver2.tmp \\ tmp/ldsc.tmp \\ | awk &#39;BEGIN{OFS=&quot;;&quot; ; print &quot;snp;maf;chisq;aver2;rs;ldsc&quot;} {$1=$1}1&#39; &gt; $out done done done 11.1.4 summary #:::::::::::::::::::::::::::::::::::::::::::::: # estimate slope: chisq ~ aver2_j #:::::::::::::::::::::::::::::::::::::::::::::: require(vroom) #cuts=c(&quot;cut.125&quot;,&quot;cut.25&quot;,&quot;cut.5&quot;) cuts=&quot;cut.125&quot; related=c(&quot;rel&quot;,&quot;unrel&quot;) traits=c(&quot;awake&quot;,&quot;bmi&quot;,&quot;chron&quot;,&quot;ever&quot;, &quot;neur&quot;,&quot;pulse&quot;,&quot;quals&quot;, &quot;fvc&quot;, &quot;height&quot;,&quot;imp&quot;, &quot;reaction&quot;,&quot;sbp&quot;,&quot;snoring&quot;,&quot;hyper&quot;) for(i in 1:length(related)){ for(j in 1:length(cuts)){ for(k in 1:length(traits)){ rel=related[i] cut=cuts[j] trait=traits[k] file=paste0(&quot;gwas-related-all-out/&quot;,trait,&quot;-&quot;,cut, &quot;-&quot;,rel,&quot;.out&quot;) dat=vroom(file, col_names=T, delim=&quot;;&quot;) mod=lm(chisq ~ aver2,data=dat) slope0=data.frame(trait=trait, cutoff=cut, rel=rel, slope_aver2=coef(mod)[2], p_aver2=summary(mod)$coefficients[,4][2], stringsAsFactors = F) if(i==1 &amp; j==1 &amp; k==1){slope=slope0} else {slope=rbind(slope,slope0)} } } } out=slope[order(slope$trait, slope$cutoff, slope$rel),] #write.table(out,&quot;summary/chisq-aver2-slope-gwas-related.txt&quot;, # col.names=T, row.names=F, quote=F) #:::::::::::::::::::::::::::::::::::::::::::::: # plot chisq ~ aver2_j by rel | cut #:::::::::::::::::::::::::::::::::::::::::::::: # function to plot a single trait--------------------------------------------------- make_plot=function(trait, cut){ # define variables cut=cut trait=trait # define color library(RColorBrewer) qual_col_pals = brewer.pal.info[brewer.pal.info$category == &#39;qual&#39;,] col_vector = unlist(mapply(brewer.pal, qual_col_pals$maxcolors, rownames(qual_col_pals))) set.seed(14) mycol=sample(col_vector,2) # related file1=paste0(&quot;gwas-related-all-out/&quot;,trait,&quot;-&quot;,cut,&quot;-rel.out&quot;) dat1=vroom(file1, col_names=T, delim=&quot;;&quot;) # bin a variable by quantile cutoff=quantile(dat1$aver2, probs = seq(0, 1, 0.005), na.rm=T) dat1$bin=cut(dat1$aver2, breaks=cutoff, labels=1:(length(cutoff)-1)) # average chisq by bin values out1=data.frame(chisq_ave=tapply(dat1$chisq,INDEX=dat1$bin, mean)) out1$bin_val=tapply(dat1$aver2,INDEX=dat1$bin, mean) # unrelated file2=paste0(&quot;gwas-related-all-out/&quot;,trait,&quot;-&quot;,cut,&quot;-unrel.out&quot;) dat2=vroom(file2, col_names=T, delim=&quot;;&quot;) # bin a variable by quantile cutoff=quantile(dat2$aver2, probs = seq(0, 1, 0.005), na.rm=T) dat2$bin=cut(dat2$aver2, breaks=cutoff, labels=1:(length(cutoff)-1)) # average chisq by bin values out2=data.frame(chisq_ave=tapply(dat2$chisq,INDEX=dat2$bin, mean)) out2$bin_val=tapply(dat2$aver2,INDEX=dat2$bin, mean) xstart=min(out1$bin_val,out2$bin_val) xend=max(out1$bin_val,out2$bin_val) ystart=min(out1$chisq_ave,out2$chisq_ave) yend=max(out1$chisq_ave,out2$chisq_ave) plot(out1$bin_val, out1$chisq_ave, xlab=&quot;ave r2&quot;, ylab=&quot;ave chisq&quot;, xlim=c(xstart,xend), ylim=c(ystart,yend), main=paste0(trait,&quot; &quot;, cut), las=1, cex = 1.5, pch=21, bg=mycol[1], col=&quot;white&quot;, lwd=0.5) points(out2$bin_val, out2$chisq_ave, cex = 1.5, pch=21, col=&quot;white&quot;, bg=mycol[2], lwd=0.5) if(trait==&quot;awake&quot;){ legend(&quot;topleft&quot;, pch=19, legend=c(&quot;rel&quot;,&quot;unrel&quot;), col=mycol, cex=1.5, box.lty=0)} } # end of function # make a plot ------------------------------------------------------------------ require(vroom) cuts=c(&quot;cut.125&quot;,&quot;cut.25&quot;,&quot;cut.5&quot;) related=c(&quot;rel&quot;,&quot;unrel&quot;) traits=c(&quot;awake&quot;,&quot;bmi&quot;,&quot;chron&quot;,&quot;ever&quot;, &quot;neur&quot;,&quot;pulse&quot;,&quot;quals&quot;, &quot;fvc&quot;, &quot;height&quot;,&quot;imp&quot;, &quot;reaction&quot;,&quot;sbp&quot;,&quot;snoring&quot;,&quot;hyper&quot;) for(j in 1:length(cuts)){ cut=cuts[j] # plot chisq ~ aver2 by rel for a given cutoff for relatedness png(paste0(&quot;fig/chisq-by-aver2-bin-related-gwas-&quot;,cut,&quot;.png&quot;), width = 50, height = 30, units = &quot;cm&quot;, res=600) par(mfrow=c(3,5)) for(i in 1:length(traits)){ trait=traits[i] make_plot(trait, cut) } dev.off() } 11.2 hapmap3 SNPs 11.2.1 genotype data #::: # make bfiles by chromosome #:::: for j in {1..22}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 20G #SBATCH -c 3 #SBATCH -t 1:0:0 ./plink2 --pfile ../gen/geno_plink/bhr$j \\ --keep ../icd10/related.inds \\ --extract ../doug/ukbb.ldsc \\ --hwe 0.0001 \\ --hard-call-threshold .05 \\ --mach-r2-filter 0.8 2 \\ --make-bed \\ --memory 20000 \\ --out ../gen/tmp/bhr$j \\ --threads 3 \\ &quot;&gt; sh_script/chr$j.sh done # submit script for i in {1..22}; do sbatch -A snpher ../sh_script/chr$i.sh done&gt;../job-records/mkbfile-related # check job completion file=job-records/mkbfile-related jobs=`awk &#39;{print $4}&#39; $file` mkdir $file-tmp for i in $jobs; do jobinfo $i | awk -F &quot;:&quot; -v i=$i &#39;$1~/Name/ {print i, $2}&#39; &gt;&gt; $file-tmp/name.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/State/ {print$2}&#39; &gt;&gt; $file-tmp/state.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Cores/ {print$2}&#39; &gt;&gt; $file-tmp/cores.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Used walltime/ {print $2 &quot;:&quot; $3 &quot;:&quot; $4}&#39; &gt;&gt; $file-tmp/time.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Max Mem/ {split($2,a,/[(]/ ); print a[1]}&#39; &gt;&gt; $file-tmp/mem.tmp done paste $file-tmp/name.tmp \\ $file-tmp/state.tmp \\ $file-tmp/cores.tmp \\ $file-tmp/time.tmp \\ $file-tmp/mem.tmp \\ | awk &#39;BEGIN{print &quot;ID name state cores time mem&quot;}{print $0}&#39; &gt; $file.out rm -r $file-tmp #::::: # merge bfiles #:::: rm bfile.list for j in {1..22}; do echo &quot;../gen/tmp/bhr$j&quot; &gt;&gt;bfile.list done echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 20G #SBATCH -c 3 #SBATCH -t 40:0:0 ./ldak5.1 --make-bed ../gen/geno-rel-hmp3 \\ --mbfile ../gen/bfile.list \\ --max-threads 3 \\ --exclude-dups YES &quot;&gt; sh_script/mbfile.sh # submit the script sbatch -A snpher ../sh_script/mbfile.sh &gt;../job-records/mbfiles-related # snp list -------------------------------------------------------------------- # MAF &amp; call-rate awk &lt; gen/geno-rel-hmp3.stats &#39;($5&gt;.01 &amp;&amp; $6&gt;=0.95 &amp;&amp; NR&gt;1){print $1}&#39; &gt; gen/snps-rel-hmp3.use # m = 1,105,446 SNPs 11.2.2 gwas # script ---------------------------------------------------------------------- for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do #for j in {cut.125,cut.25,cut.5}; do j=cut.125 for chr in {1..22}; do id=../relatedness/$j.related snp=../gen/snps-rel-hmp3.use bfile=../gen/geno-rel-hmp3 out=../gwas-$j-rel/$i-linear-$chr echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 8G #SBATCH -c 1 #SBATCH -t 8:0:0 ./ldak5.1 --linear $out \\ --pheno ../phen/continuous-traits/$i.raw.pheno \\ --bfile $bfile \\ --keep $id \\ --extract $snp \\ --covar ../phen/basic-covariates.use \\ --max-threads 2 \\ --chr $chr &quot;&gt; sh_script/$i-linear-$j-rel-chr-$chr.sh done done #done # submit jobs------------------------------------------------------------------- for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do j=cut.125 for chr in {1..22}; do #for j in {cut.125,cut.25,cut.5}; do sbatch -A snpher ../sh_script/$i-linear-$j-rel-chr-$chr.sh #sbatch -A snpher ../sh_script/$i-linear-$j-unrel.sh done done&gt;../job-records/gwas-related # check job completion---------------------------------------------------------- file=job-records/gwas-related jobs=`awk &#39;{print $4}&#39; $file` mkdir $file-tmp for i in $jobs; do jobinfo $i | awk -F &quot;:&quot; -v i=$i &#39;$1~/Name/ {print i, $2}&#39; &gt;&gt; $file-tmp/name.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/State/ {print$2}&#39; &gt;&gt; $file-tmp/state.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Cores/ {print$2}&#39; &gt;&gt; $file-tmp/cores.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Used walltime/ {print $2 &quot;:&quot; $3 &quot;:&quot; $4}&#39; &gt;&gt; $file-tmp/time.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Max Mem/ {split($2,a,/[(]/ ); print a[1]}&#39; &gt;&gt; $file-tmp/mem.tmp done paste $file-tmp/name.tmp \\ $file-tmp/state.tmp \\ $file-tmp/cores.tmp \\ $file-tmp/time.tmp \\ $file-tmp/mem.tmp \\ | awk &#39;BEGIN{print &quot;ID name state cores time mem&quot;}{print $0}&#39; &gt; $file.out rm -r $file-tmp # merge files------------------------------------------------------------------- # only do .summaries &amp; .pvalues for i in {awake,bmi,quals,chron,ever,fvc,height,imp,neur,pulse,reaction,sbp,snoring,hyper}; do for j in {1..22}; do if [ $j == 1 ]; then awk &#39;{print $0}&#39; $i-linear-$j.summaries &gt; $i-linear.summaries awk &#39;{print $0}&#39; $i-linear-$j.pvalues &gt; $i-linear.pvalues else awk &#39;NR&gt;1 {print $0}&#39; $i-linear-$j.summaries &gt;&gt; $i-linear.summaries awk &#39;NR&gt;1 {print $0}&#39; $i-linear-$j.pvalues &gt;&gt; $i-linear.pvalues fi done done 11.2.3 aver2_j #::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: # snp lists #::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: # snp list---------------------------------------------------------------------- # common snps of related &amp; unrelated unrel=gen/snps-unrel-inds.use # 1,103,209 rel=gen/snps-rel-hmp3.use # 1,105,446 SNPs awk &#39;NR==FNR{a[$1];next} ($1 in a) {print $1}&#39; $unrel $rel &gt; gen/common-unrel-rel-snps # 1,101,844 # lista &amp; listb # this will be common for all id lists m=10000 infile=gen/common-unrel-rel-snps left=inflation/related/left-snps right=inflation/related/right-snps awk &#39;{split($1, a, &quot;:&quot;); if (a[1]&lt;8) print $1 }&#39; $infile | shuf | head -n $m &gt;$left awk &#39;{split($1, a, &quot;:&quot;); if (a[1]&gt;=8) print $1 }&#39; $infile | shuf | head -n $m &gt;$right #::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: # compute ave r^2_j #::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: #for nm in {cut.125,cut.25,cut.5}; do nm=cut.125 # common snp lists lista=../inflation/related/right-snps listb=../inflation/related/left-snps # related individuals id=../relatedness/$nm.related bfile=../gen/geno-rel-hmp3 out=../inflation/related/out/10k-snps-$nm-rel echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 20G #SBATCH -c 2 #SBATCH -t 00:10:0 ./ldak5.2 --max-threads 2 \\ --calc-inflation $out \\ --bfile $bfile \\ --keep $id \\ --lista $lista \\ --listb $listb &quot;&gt;sh_script/calc-r-10k-snps-$nm-rel # unrelated controls id=../white-unrel-rand-control-for-$nm bfile=../gen/geno-unrel out=../inflation/related/out/10k-snps-$nm-unrel echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 20G #SBATCH -c 2 #SBATCH -t 00:10:0 ./ldak5.2 --max-threads 2 \\ --calc-inflation $out \\ --bfile $bfile \\ --keep $id \\ --lista $lista \\ --listb $listb &quot;&gt;sh_script/calc-r-10k-snps-$nm-unrel #done # submit the job #for nm in {cut.125,cut.25,cut.5}; do for nm in cut.125; do sbatch -A snpher ../sh_script/calc-r-10k-snps-$nm-rel sbatch -A snpher ../sh_script/calc-r-10k-snps-$nm-unrel done&gt;../job-records/calc-r-related # compute ave r_j^2 for each i------------------------------------------------- R require(vroom) #cut=c(&quot;cut.125&quot;,&quot;cut.25&quot;,&quot;cut.5&quot;) cut=c(&quot;cut.125&quot;) rel=c(&quot;rel&quot;,&quot;unrel&quot;) for(j in 1:length(rel)){ for(i in 1:length(cut)){ nm=paste0(&quot;10k-snps-&quot;,cut[i],&quot;-&quot;,rel[j]) dat=vroom(paste0(&quot;inflation/related/out/&quot;,nm,&quot;.pairwise&quot;), col_names=F) lista=read.table(paste0(&quot;inflation/related/out/&quot;,nm,&quot;.predictorsa&quot;), stringsAsFactors = F) listb=read.table(paste0(&quot;inflation/related/out/&quot;,nm,&quot;.predictorsb&quot;), stringsAsFactors = F) dat=dat[,-c(10001)]^2 outb=data.frame(predictor=listb$V1, ave_r2=apply(dat,2, mean)) outa=data.frame(predictor=lista$V1, ave_r2=apply(dat,1, mean)) out=rbind(outa,outb) write.table(out,paste0(&quot;summary/ave-r2-&quot;,nm), col.names=F, row.names=F, quote=F) } } #::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: # summary #::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: # check if mean r^2_j differs for rel vs. unrel #cut=c(&quot;cut.125&quot;,&quot;cut.25&quot;,&quot;cut.5&quot;) cut=c(&quot;cut.125&quot;) for(i in 1:length(cut)){ nm_rel=paste0(&quot;ave-r2-10k-snps-&quot;,cut[i],&quot;-rel&quot;) nm_unrel=paste0(&quot;ave-r2-10k-snps-&quot;,cut[i],&quot;-unrel&quot;) dat_rel=read.table(paste0(&quot;summary/&quot;,nm_rel),stringsAsFactors = F) dat_unrel=read.table(paste0(&quot;summary/&quot;,nm_unrel),stringsAsFactors = F) out0=data.frame(rel=cut[i], rel_ave=mean(dat_rel$V2), rel_sd=sd(dat_rel$V2), unrel_ave=mean(dat_unrel$V2), unrel_sd=sd(dat_unrel$V2), stringsAsFactors = F) if(i==1){out1=out0}else{out1=rbind(out1,out0)} } 11.2.4 organize data #for j in {cut.125,cut.25,cut.5}; do for j in cut.125; do for i in {rel,unrel};do for trait in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do gwas=gwas-$j-$i/$trait-linear.summaries aver2=summary/ave-r2-10k-snps-$j-$i out=gwas-related-all-out/$trait-$j-$i.out awk &#39;NR&gt;1 {print $1, $5}&#39; $gwas &gt; tmp/gwas.tmp awk &#39;NR==FNR {a[$1]; b[$1]=$2; next} {if ($1 in a) print b[$1]; else print &quot;NA&quot; }&#39; $aver2 tmp/gwas.tmp &gt; tmp/aver2.tmp # put info together paste tmp/gwas.tmp \\ tmp/aver2.tmp \\ | awk &#39;BEGIN{OFS=&quot;;&quot; ; print &quot;snp;chisq;aver2&quot;} {$1=$1}1&#39; &gt; $out done done done 11.2.5 chisq ~ aver2_j #:::::::::::::::::::::::::::::::::::::::::::::: # estimate slope: chisq ~ aver2_j #:::::::::::::::::::::::::::::::::::::::::::::: require(vroom) #cuts=c(&quot;cut.125&quot;,&quot;cut.25&quot;,&quot;cut.5&quot;) cuts=&quot;cut.125&quot; related=c(&quot;rel&quot;,&quot;unrel&quot;) traits=c(&quot;awake&quot;,&quot;bmi&quot;,&quot;chron&quot;,&quot;ever&quot;, &quot;neur&quot;,&quot;pulse&quot;,&quot;quals&quot;, &quot;fvc&quot;, &quot;height&quot;,&quot;imp&quot;, &quot;reaction&quot;,&quot;sbp&quot;,&quot;snoring&quot;,&quot;hyper&quot;) for(i in 1:length(related)){ for(j in 1:length(cuts)){ for(k in 1:length(traits)){ rel=related[i] cut=cuts[j] trait=traits[k] file=paste0(&quot;gwas-related-all-out/&quot;,trait,&quot;-&quot;,cut, &quot;-&quot;,rel,&quot;.out&quot;) dat=vroom(file, col_names=T, delim=&quot;;&quot;) mod=lm(chisq ~ aver2,data=dat) slope0=data.frame(trait=trait, cutoff=cut, rel=rel, slope_aver2=coef(mod)[2], p_aver2=summary(mod)$coefficients[,4][2], stringsAsFactors = F) if(i==1 &amp; j==1 &amp; k==1){slope=slope0} else {slope=rbind(slope,slope0)} } } } out=slope[order(slope$trait, slope$cutoff, slope$rel),] #write.table(out,&quot;summary/chisq-aver2-slope-gwas-related.txt&quot;, # col.names=T, row.names=F, quote=F) #:::::::::::::::::::::::::::::::::::::::::::::: # plot chisq ~ aver2_j by rel | cut #:::::::::::::::::::::::::::::::::::::::::::::: # function to plot a single trait--------------------------------------------------- make_plot=function(trait, cut){ # define variables cut=cut trait=trait # define color library(RColorBrewer) qual_col_pals = brewer.pal.info[brewer.pal.info$category == &#39;qual&#39;,] col_vector = unlist(mapply(brewer.pal, qual_col_pals$maxcolors, rownames(qual_col_pals))) set.seed(14) mycol=sample(col_vector,2) # related file1=paste0(&quot;gwas-related-all-out/&quot;,trait,&quot;-&quot;,cut,&quot;-rel.out&quot;) dat1=vroom(file1, col_names=T, delim=&quot;;&quot;) # bin a variable by quantile cutoff=quantile(dat1$aver2, probs = seq(0, 1, 0.005), na.rm=T) dat1$bin=cut(dat1$aver2, breaks=cutoff, labels=1:(length(cutoff)-1)) # average chisq by bin values out1=data.frame(chisq_ave=tapply(dat1$chisq,INDEX=dat1$bin, mean)) out1$bin_val=tapply(dat1$aver2,INDEX=dat1$bin, mean) # unrelated file2=paste0(&quot;gwas-related-all-out/&quot;,trait,&quot;-&quot;,cut,&quot;-unrel.out&quot;) dat2=vroom(file2, col_names=T, delim=&quot;;&quot;) # bin a variable by quantile cutoff=quantile(dat2$aver2, probs = seq(0, 1, 0.005), na.rm=T) dat2$bin=cut(dat2$aver2, breaks=cutoff, labels=1:(length(cutoff)-1)) # average chisq by bin values out2=data.frame(chisq_ave=tapply(dat2$chisq,INDEX=dat2$bin, mean)) out2$bin_val=tapply(dat2$aver2,INDEX=dat2$bin, mean) xstart=min(out1$bin_val,out2$bin_val) xend=max(out1$bin_val,out2$bin_val) ystart=min(out1$chisq_ave,out2$chisq_ave) yend=max(out1$chisq_ave,out2$chisq_ave) plot(out1$bin_val, out1$chisq_ave, xlab=&quot;ave r2&quot;, ylab=&quot;ave chisq&quot;, xlim=c(xstart,xend), ylim=c(ystart,yend), main=paste0(trait,&quot; &quot;, cut), las=1, cex = 1.5, pch=21, bg=mycol[1], col=&quot;white&quot;, lwd=0.5) points(out2$bin_val, out2$chisq_ave, cex = 1.5, pch=21, col=&quot;white&quot;, bg=mycol[2], lwd=0.5) if(trait==&quot;awake&quot;){ legend(&quot;topleft&quot;, pch=19, legend=c(&quot;rel&quot;,&quot;unrel&quot;), col=mycol, cex=1.5, box.lty=0)} } # end of function # make a plot ------------------------------------------------------------------ require(vroom) #cuts=c(&quot;cut.125&quot;,&quot;cut.25&quot;,&quot;cut.5&quot;) cuts=&quot;cut.125&quot; related=c(&quot;rel&quot;,&quot;unrel&quot;) traits=c(&quot;awake&quot;,&quot;bmi&quot;,&quot;chron&quot;,&quot;ever&quot;, &quot;neur&quot;,&quot;pulse&quot;,&quot;quals&quot;, &quot;fvc&quot;, &quot;height&quot;,&quot;imp&quot;, &quot;reaction&quot;,&quot;sbp&quot;,&quot;snoring&quot;,&quot;hyper&quot;) for(j in 1:length(cuts)){ cut=cuts[j] # plot chisq ~ aver2 by rel for a given cutoff for relatedness png(paste0(&quot;fig/chisq-by-aver2-bin-related-gwas-&quot;,cut,&quot;.png&quot;), width = 50, height = 30, units = &quot;cm&quot;, res=600) par(mfrow=c(3,5)) for(i in 1:length(traits)){ trait=traits[i] make_plot(trait, cut) } dev.off() } 11.2.6 inflation ~ aver2_j #:::::::::::::::::::::::::::::::::::::::::::::: # estimate slope: inflation ~ aver2_j #:::::::::::::::::::::::::::::::::::::::::::::: require(vroom) cuts=&quot;cut.125&quot; traits=c(&quot;awake&quot;,&quot;bmi&quot;,&quot;chron&quot;,&quot;ever&quot;, &quot;neur&quot;,&quot;pulse&quot;,&quot;quals&quot;, &quot;fvc&quot;, &quot;height&quot;,&quot;imp&quot;, &quot;reaction&quot;,&quot;sbp&quot;,&quot;snoring&quot;,&quot;hyper&quot;) for(j in 1:length(cuts)){ for(k in 1:length(traits)){ cut=cuts[j] trait=traits[k] f1=paste0(&quot;gwas-related-all-out/&quot;,trait,&quot;-&quot;,cut,&quot;-rel.out&quot;) f2=paste0(&quot;gwas-related-all-out/&quot;,trait,&quot;-&quot;,cut,&quot;-unrel.out&quot;) d1=vroom(f1, col_names=T, delim=&quot;;&quot;) d2=vroom(f2, col_names=T, delim=&quot;;&quot;) common=intersect(d1$snp, d2$snp) m1=match(common, d1$snp) m2=match(common, d2$snp) dat=data.frame(snp=common, inflation=d1$chisq[m1]-d2$chisq[m2], aver2=d1$aver2[m1]) mod=lm(inflation ~ aver2,data=dat) slope0=data.frame(trait=trait, cutoff=cut, slope_aver2=coef(mod)[2], p_aver2=summary(mod)$coefficients[,4][2], stringsAsFactors = F) if(j==1 &amp; k==1){slope=slope0} else {slope=rbind(slope,slope0)} } } out=slope[order(slope$trait, slope$cutoff),] #write.table(out,&quot;summary/chisq-aver2-slope-gwas-related.txt&quot;, # col.names=T, row.names=F, quote=F) #:::::::::::::::::::::::::::::::::::::::::::::: # plot inflation ~ aver2_j #:::::::::::::::::::::::::::::::::::::::::::::: # make a plot ------------------------------------------------------------------ require(vroom) traits=c(&quot;awake&quot;,&quot;bmi&quot;,&quot;chron&quot;,&quot;ever&quot;, &quot;neur&quot;,&quot;pulse&quot;,&quot;quals&quot;, &quot;fvc&quot;, &quot;height&quot;,&quot;imp&quot;, &quot;reaction&quot;,&quot;sbp&quot;,&quot;snoring&quot;,&quot;hyper&quot;) cut=&quot;cut.125&quot; png(paste0(&quot;fig/inflation-by-aver2-bin-related-gwas.png&quot;), width = 50, height = 30, units = &quot;cm&quot;, res=600) par(mfrow=c(3,5)) for (i in 1:length(traits)){ trait=traits[i] f1=paste0(&quot;gwas-related-all-out/&quot;,trait,&quot;-&quot;,cut,&quot;-rel.out&quot;) f2=paste0(&quot;gwas-related-all-out/&quot;,trait,&quot;-&quot;,cut,&quot;-unrel.out&quot;) d1=vroom(f1, col_names=T, delim=&quot;;&quot;) d2=vroom(f2, col_names=T, delim=&quot;;&quot;) common=intersect(d1$snp, d2$snp) m1=match(common, d1$snp) m2=match(common, d2$snp) dat=data.frame(snp=common, inflation=d1$chisq[m1]-d2$chisq[m2], aver2=d1$aver2[m1]) # bin a variable by quantile cutoff=quantile(dat$aver2, probs = seq(0, 1, 0.005), na.rm=T) dat$bin=cut(dat$aver2, breaks=cutoff, labels=1:(length(cutoff)-1)) # average inflation by bin values out=data.frame(inflation_ave=tapply(dat$inflation,INDEX=dat$bin, mean)) out$bin_val=tapply(dat$aver2,INDEX=dat$bin, mean) plot(out$bin_val, out$inflation_ave, xlab=&quot;ave r2&quot;, ylab=&quot;ave inflation&quot;, main=trait, las=1, cex = 1.5, pch=21, bg=&quot;orange&quot;, col=&quot;white&quot;, lwd=0.5) } dev.off() 11.3 mix unrel &amp; rel 11.3.1 genotype # id list awk &#39;{print $1, $2}&#39; rand.100000 icd10/related.inds &gt; rel-unrel-combo.id # note: there are some overlap between the two id lists. #::: # make bfiles by chromosome #:::: for j in {1..22}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 20G #SBATCH -c 3 #SBATCH -t 1:0:0 ./plink2 --pfile ../gen/geno_plink/bhr$j \\ --keep ../rel-unrel-combo.id \\ --extract ../doug/ukbb.ldsc \\ --hwe 0.0001 \\ --hard-call-threshold .05 \\ --mach-r2-filter 0.8 2 \\ --make-bed \\ --memory 20000 \\ --out ../gen/tmp/bhr$j-combo \\ --threads 3 \\ &quot;&gt; sh_script/chr$j.sh done # submit script for i in {1..22}; do sbatch -A snpher ../sh_script/chr$i.sh done&gt;../job-records/mkbfile-related-unrel-combo # check job completion file=job-records/mkbfile-related-unrel-combo jobs=`awk &#39;{print $4}&#39; $file` mkdir $file-tmp for i in $jobs; do jobinfo $i | awk -F &quot;:&quot; -v i=$i &#39;$1~/Name/ {print i, $2}&#39; &gt;&gt; $file-tmp/name.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/State/ {print$2}&#39; &gt;&gt; $file-tmp/state.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Cores/ {print$2}&#39; &gt;&gt; $file-tmp/cores.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Used walltime/ {print $2 &quot;:&quot; $3 &quot;:&quot; $4}&#39; &gt;&gt; $file-tmp/time.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Max Mem/ {split($2,a,/[(]/ ); print a[1]}&#39; &gt;&gt; $file-tmp/mem.tmp done paste $file-tmp/name.tmp \\ $file-tmp/state.tmp \\ $file-tmp/cores.tmp \\ $file-tmp/time.tmp \\ $file-tmp/mem.tmp \\ | awk &#39;BEGIN{print &quot;ID name state cores time mem&quot;}{print $0}&#39; &gt; $file.out rm -r $file-tmp #::::: # merge bfiles #:::: rm bfile.list for j in {1..22}; do echo &quot;../gen/tmp/bhr$j-combo&quot; &gt;&gt;bfile.list done echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 20G #SBATCH -c 3 #SBATCH -t 40:0:0 ./ldak5.1 --make-bed ../gen/geno-rel-unrel-combo \\ --mbfile ../gen/bfile.list \\ --max-threads 3 \\ --exclude-dups YES &quot;&gt; sh_script/mbfile.sh # snp list -------------------------------------------------------------------- # MAF &amp; call-rate awk &lt; gen/geno-rel-unrel-combo.stats &#39;($5&gt;.01 &amp;&amp; $6&gt;=0.95 &amp;&amp; NR&gt;1){print $1}&#39; &gt; gen/snps-rel-unrel-combo.use # m = 1,102,906 SNPs 11.3.2 gwas mkdir gwas-rel-unrel-combo # script ---------------------------------------------------------------------- for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do for chr in {1..22}; do snp=../gen/snps-rel-unrel-combo.use bfile=../gen/geno-rel-unrel-combo out=../gwas-rel-unrel-combo/$i-linear-$chr echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 8G #SBATCH -c 1 #SBATCH -t 8:0:0 ./ldak5.1 --linear $out \\ --pheno ../phen/continuous-traits/$i.raw.pheno \\ --bfile $bfile \\ --extract $snp \\ --covar ../phen/basic-covariates.use \\ --max-threads 2 \\ --chr $chr &quot;&gt; sh_script/$i-linear-chr-$chr.sh done done #done # submit jobs------------------------------------------------------------------- for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do for chr in {1..22}; do sbatch -A snpher ../sh_script/$i-linear-chr-$chr.sh done done&gt;../job-records/gwas-combo # merge files------------------------------------------------------------------- # only do .summaries &amp; .pvalues for i in {awake,bmi,quals,chron,ever,fvc,height,imp,neur,pulse,reaction,sbp,snoring,hyper}; do for j in {1..22}; do if [ $j == 1 ]; then awk &#39;{print $0}&#39; $i-linear-$j.summaries &gt; $i-linear.summaries awk &#39;{print $0}&#39; $i-linear-$j.pvalues &gt; $i-linear.pvalues else awk &#39;NR&gt;1 {print $0}&#39; $i-linear-$j.summaries &gt;&gt; $i-linear.summaries awk &#39;NR&gt;1 {print $0}&#39; $i-linear-$j.pvalues &gt;&gt; $i-linear.pvalues fi done done 11.3.3 aver2_j #::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: # snp lists #::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: # common snps of related &amp; unrelated unrel=gen/snps-unrel-inds.use rel=gen/snps-rel-unrel-combo.use awk &#39;NR==FNR{a[$1];next} ($1 in a) {print $1}&#39; $unrel $rel &gt; gen/common-unrel-rel-combo-snps # 1,101,883 # lista &amp; listb m=10000 infile=gen/common-unrel-rel-combo-snps left=inflation/combo/left-snps right=inflation/combo/right-snps awk &#39;{split($1, a, &quot;:&quot;); if (a[1]&lt;8) print $1 }&#39; $infile | shuf | head -n $m &gt;$left awk &#39;{split($1, a, &quot;:&quot;); if (a[1]&gt;=8) print $1 }&#39; $infile | shuf | head -n $m &gt;$right #::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: # compute ave r^2_j #::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: # related lista=../inflation/combo/right-snps listb=../inflation/combo/left-snps bfile=../gen/geno-rel-unrel-combo out=../inflation/combo/out/10k-snps echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 30G #SBATCH -c 2 #SBATCH -t 00:30:0 ./ldak5.2 --max-threads 2 \\ --calc-inflation $out \\ --bfile $bfile \\ --lista $lista \\ --listb $listb &quot;&gt;sh_script/calc-r-10k-snps # submit the job sbatch -A snpher ../sh_script/calc-r-10k-snps &gt;../job-records/calc-r-combo # unrelated lista=../inflation/combo/right-snps listb=../inflation/combo/left-snps bfile=../gen/geno-unrel id=../unrelated/rand.100000 out=../inflation/combo/out/10k-snps-unrel echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 30G #SBATCH -c 2 #SBATCH -t 00:10:0 ./ldak5.2 --max-threads 2 \\ --calc-inflation $out \\ --keep $id \\ --bfile $bfile \\ --lista $lista \\ --listb $listb &quot;&gt;sh_script/calc-r-10k-snps-unrel # submit the job sbatch -A snpher ../sh_script/calc-r-10k-snps-unrel &gt;../job-records/calc-r-combo-unrel # compute ave r_j^2 for each i------------------------------------------------- R require(vroom) nm=&quot;10k-snps&quot; dat=vroom(paste0(&quot;inflation/combo/out/&quot;,nm,&quot;.pairwise&quot;), col_names=F) lista=read.table(paste0(&quot;inflation/combo/out/&quot;,nm,&quot;.predictorsa&quot;), stringsAsFactors = F) listb=read.table(paste0(&quot;inflation/combo/out/&quot;,nm,&quot;.predictorsb&quot;), stringsAsFactors = F) dat=dat[,-c(10001)]^2 outb=data.frame(predictor=listb$V1, ave_r2=apply(dat,2, mean)) outa=data.frame(predictor=lista$V1, ave_r2=apply(dat,1, mean)) out=rbind(outa,outb) write.table(out,paste0(&quot;summary/ave-r2-&quot;,nm, &quot;-rel-unrel-combo&quot;), col.names=F, row.names=F, quote=F) # for unrelated control rand.100000 R require(vroom) nm=&quot;10k-snps-unrel&quot; dat=vroom(paste0(&quot;inflation/combo/out/&quot;,nm,&quot;.pairwise&quot;), col_names=F) lista=read.table(paste0(&quot;inflation/combo/out/&quot;,nm,&quot;.predictorsa&quot;), stringsAsFactors = F) listb=read.table(paste0(&quot;inflation/combo/out/&quot;,nm,&quot;.predictorsb&quot;), stringsAsFactors = F) dat=dat[,-c(10001)]^2 outb=data.frame(predictor=listb$V1, ave_r2=apply(dat,2, mean)) outa=data.frame(predictor=lista$V1, ave_r2=apply(dat,1, mean)) out=rbind(outa,outb) write.table(out,&quot;summary/ave-r2-10k-snps-rel-unrel-combo-ref&quot;, col.names=F, row.names=F, quote=F) 11.3.4 organize data # related------------------------------------------------------------------------ for trait in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do gwas=gwas-rel-unrel-combo/$trait-linear.summaries aver2=summary/ave-r2-10k-snps-rel-unrel-combo out=gwas-rel-unrel-combo-out/$trait.out awk &#39;NR&gt;1 {print $1, $5}&#39; $gwas &gt; tmp/gwas.tmp awk &#39;NR==FNR {a[$1]; b[$1]=$2; next} {if ($1 in a) print b[$1]; else print &quot;NA&quot; }&#39; $aver2 tmp/gwas.tmp &gt; tmp/aver2.tmp # put info together paste tmp/gwas.tmp \\ tmp/aver2.tmp \\ | awk &#39;BEGIN{OFS=&quot;;&quot; ; print &quot;snp;chisq;aver2&quot;} {$1=$1}1&#39; &gt; $out done # unrelated control------------------------------------------------------------- for trait in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do gwas=unrelated/gwas-good/$trait-linear.summaries aver2=summary/ave-r2-10k-snps-rel-unrel-combo-ref out=gwas-rel-unrel-combo-out/$trait-ref.out awk &#39;NR&gt;1 {print $1, $5}&#39; $gwas &gt; tmp/gwas.tmp awk &#39;NR==FNR {a[$1]; b[$1]=$2; next} {if ($1 in a) print b[$1]; else print &quot;NA&quot; }&#39; $aver2 tmp/gwas.tmp &gt; tmp/aver2.tmp # put info together paste tmp/gwas.tmp \\ tmp/aver2.tmp \\ | awk &#39;BEGIN{OFS=&quot;;&quot; ; print &quot;snp;chisq;aver2&quot;} {$1=$1}1&#39; &gt; $out done 11.3.5 chisq ~ aver2_j #:::::::::::::::::::::::::::::::::::::::::::::: # estimate slope: chisq ~ aver2_j #:::::::::::::::::::::::::::::::::::::::::::::: require(vroom) traits=c(&quot;awake&quot;,&quot;bmi&quot;,&quot;chron&quot;,&quot;ever&quot;, &quot;neur&quot;,&quot;pulse&quot;,&quot;quals&quot;, &quot;fvc&quot;, &quot;height&quot;,&quot;imp&quot;, &quot;reaction&quot;,&quot;sbp&quot;,&quot;snoring&quot;,&quot;hyper&quot;) for(i in 1:length(traits)){ trait=traits[i] file=paste0(&quot;gwas-rel-unrel-combo-out/&quot;,trait,&quot;.out&quot;) dat=vroom(file, col_names=T, delim=&quot;;&quot;) dat=dat[complete.cases(dat),] mod=lm(chisq ~ aver2,data=dat) slope0=data.frame(trait=trait, slope_aver2=coef(mod)[2], p_aver2=summary(mod)$coefficients[,4][2], stringsAsFactors = F) if(i==1){slope=slope0} else {slope=rbind(slope,slope0)} } #:::::::::::::::::::::::::::::::::::::::::::::: # plot chisq ~ aver2_j #:::::::::::::::::::::::::::::::::::::::::::::: # make a plot ------------------------------------------------------------------ require(vroom) traits=c(&quot;awake&quot;,&quot;bmi&quot;,&quot;chron&quot;,&quot;ever&quot;, &quot;neur&quot;,&quot;pulse&quot;,&quot;quals&quot;, &quot;fvc&quot;, &quot;height&quot;,&quot;imp&quot;, &quot;reaction&quot;,&quot;sbp&quot;,&quot;snoring&quot;,&quot;hyper&quot;) png(paste0(&quot;fig/chisq-by-aver2-bin-unrel-rel-combo-gwas.png&quot;), width = 50, height = 30, units = &quot;cm&quot;, res=600) par(mfrow=c(3,5)) for (i in 1:length(traits)){ trait=traits[i] file=paste0(&quot;gwas-rel-unrel-combo-out/&quot;,trait,&quot;.out&quot;) dat=vroom(file, col_names=T, delim=&quot;;&quot;) # bin a variable by quantile cutoff=quantile(dat$aver2, probs = seq(0, 1, 0.005), na.rm=T) dat$bin=cut(dat$aver2, breaks=cutoff, labels=1:(length(cutoff)-1)) # average chisq by bin values out=data.frame(chisq_ave=tapply(dat$chisq,INDEX=dat$bin, mean)) out$bin_val=tapply(dat$aver2,INDEX=dat$bin, mean) plot(out$bin_val, out$chisq_ave, xlab=&quot;ave r2&quot;, ylab=&quot;ave chisq&quot;, main=trait, las=1, cex = 1.5, pch=21, bg=&quot;orange&quot;, col=&quot;white&quot;, lwd=0.5) } dev.off() 11.3.6 inflation ~ aver2_j #:::::::::::::::::::::::::::::::::::::::::::::: # estimate slope: inflation ~ aver2_j #:::::::::::::::::::::::::::::::::::::::::::::: require(vroom) traits=c(&quot;awake&quot;,&quot;bmi&quot;,&quot;chron&quot;,&quot;ever&quot;, &quot;neur&quot;,&quot;pulse&quot;,&quot;quals&quot;, &quot;fvc&quot;, &quot;height&quot;,&quot;imp&quot;, &quot;reaction&quot;,&quot;sbp&quot;,&quot;snoring&quot;,&quot;hyper&quot;) for(i in 1:length(traits)){ trait=traits[i] f1=paste0(&quot;gwas-rel-unrel-combo-out/&quot;,trait,&quot;.out&quot;) f2=paste0(&quot;gwas-rel-unrel-combo-out/&quot;,trait,&quot;-ref.out&quot;) d1=vroom(f1, col_names=T, delim=&quot;;&quot;) d2=vroom(f2, col_names=T, delim=&quot;;&quot;) common=intersect(d1$snp, d2$snp) m1=match(common, d1$snp) m2=match(common, d2$snp) dat=data.frame(snp=common, inflation=d1$chisq[m1]-d2$chisq[m2], aver2=d1$aver2[m1]) mod=lm(inflation ~ aver2,data=dat) slope0=data.frame(trait=trait, slope_aver2=coef(mod)[2], p_aver2=summary(mod)$coefficients[,4][2], stringsAsFactors = F) if(i==1){slope=slope0} else {slope=rbind(slope,slope0)} } out=slope[order(slope$trait),] #:::::::::::::::::::::::::::::::::::::::::::::: # plot inflation ~ aver2_j #:::::::::::::::::::::::::::::::::::::::::::::: # make a plot ------------------------------------------------------------------ require(vroom) traits=c(&quot;awake&quot;,&quot;bmi&quot;,&quot;chron&quot;,&quot;ever&quot;, &quot;neur&quot;,&quot;pulse&quot;,&quot;quals&quot;, &quot;fvc&quot;, &quot;height&quot;,&quot;imp&quot;, &quot;reaction&quot;,&quot;sbp&quot;,&quot;snoring&quot;,&quot;hyper&quot;) png(paste0(&quot;fig/inflation-by-aver2-bin-rel-unrel-combo.png&quot;), width = 50, height = 30, units = &quot;cm&quot;, res=600) par(mfrow=c(3,5)) for (i in 1:length(traits)){ trait=traits[i] f1=paste0(&quot;gwas-rel-unrel-combo-out/&quot;,trait,&quot;.out&quot;) f2=paste0(&quot;gwas-rel-unrel-combo-out/&quot;,trait,&quot;-ref.out&quot;) d1=vroom(f1, col_names=T, delim=&quot;;&quot;) d2=vroom(f2, col_names=T, delim=&quot;;&quot;) common=intersect(d1$snp, d2$snp) m1=match(common, d1$snp) m2=match(common, d2$snp) dat=data.frame(snp=common, inflation=d1$chisq[m1]-d2$chisq[m2], aver2=d1$aver2[m1]) # bin a variable by quantile cutoff=quantile(dat$aver2, probs = seq(0, 1, 0.005), na.rm=T) dat$bin=cut(dat$aver2, breaks=cutoff, labels=1:(length(cutoff)-1)) # average inflation by bin values out=data.frame(inflation_ave=tapply(dat$inflation,INDEX=dat$bin, mean)) out$bin_val=tapply(dat$aver2,INDEX=dat$bin, mean) plot(out$bin_val, out$inflation_ave, xlab=&quot;ave r2&quot;, ylab=&quot;ave inflation&quot;, main=trait, las=1, cex = 1.5, pch=21, bg=&quot;orange&quot;, col=&quot;white&quot;, lwd=0.5) } dev.off() "],["compute-sum_ijm_1-m_2r2_ij.html", "12 compute \\(\\sum_{i,j}^{m_1, m_2}r^2_{i,j}\\) 12.1 good GWAS-all qced snps 12.2 good GWASs- ldak-thin snps 12.3 bad GWASs-all qced snps 12.4 summary 12.5 compute aver2_j 12.6 mixed pop GWAS with PC as covariates", " 12 compute \\(\\sum_{i,j}^{m_1, m_2}r^2_{i,j}\\) 12.1 good GWAS-all qced snps #:::: # here we define a R function to compute sum(r^2) #::: echo &quot;# here we define a R function to compute sum(r^2) options(stringsAsFactors=FALSE) ip&lt;-commandArgs(trailingOnly=TRUE) options(warn=1) require(vroom) compute_sumr2=function(filein, fileout){ dir=\\&quot;/home/zhoux/dsmwpred/xuan/quality-control/qc-10oct/inflation/\\&quot; dat=vroom(paste0(dir,\\&quot;out/\\&quot;, filein), col_names=F) r=dat[lower.tri(dat, diag = T)] sumr2=sum(r^2) write.table(cbind(sumr2, length(r)), paste0(dir,\\&quot;summary/\\&quot;, fileout), col.names=F, row.names=F, quote=F, append=T) } compute_sumr2(ip[1],ip[2]) &quot;&gt;inflation/calc-sum-r2.r # script echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 20G #SBATCH -c 10 #SBATCH -t 4:00:0 #::: # 0. define vars &amp; create snp lists #::: m=1000 nm=1k lista=left-snps-goodgwas-$nm listb=right-snps-goodgwas-$nm out=$nm-snps-goodgwas filein=$nm-snps-goodgwas.pairwise fileout=sum-r2-$nm-snps-goodgwas # loop and recycle files to avoid storage problems for i in {1..500}; do #:: # 1. create snp lists &amp; use ldak to compute r_i,j #:: shuf ../gen/left-hapmap3.snps | head -n $m &gt; ../inflation/$lista shuf ../gen/right-hapmap3.snps | head -n $m &gt; ../inflation/$listb ./ldak5.2 --max-threads 10 \\ --calc-inflation ../inflation/out/$out \\ --bfile ../gen/geno-unrel \\ --lista ../inflation/$lista \\ --listb ../inflation/$listb #:: # 2. compute sum(r^2): see for details #:: Rscript --vanilla ../inflation/calc-sum-r2.r $filein $fileout done &quot;&gt;sh_script/calc-sum-r2 # submit the job m=1000 nm=1k sbatch -A snpher ../sh_script/calc-sum-r2 &gt;../job-records/calc-sum-r2-$nm-snps-goodgwas 12.2 good GWASs- ldak-thin snps # script echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 20G #SBATCH -c 10 #SBATCH -t 4:00:0 #::: # 0. define vars &amp; create snp lists #::: # to be changed m=1000 nm=1k snpa=../gen/left-mix-pop.snps snpb=../gen/right-mix-pop.snps id=../mix-pop-gwas.id bfile=../gen/geno-mix lista=left-snps-badgwas-$nm listb=right-snps-badgwas-$nm out=$nm-snps-badgwas filein=$nm-snps-badgwas.pairwise fileout=sum-r2-$nm-snps-badgwas # loop and recycle files to avoid storage problems for i in {1..500}; do #:: # 1. create snp lists &amp; use ldak to compute r_i,j #:: shuf $snpa | head -n $m &gt; ../inflation/$lista shuf $snpb | head -n $m &gt; ../inflation/$listb ./ldak5.2 --max-threads 10 \\ --calc-inflation ../inflation/out/$out \\ --bfile $bfile \\ --keep $id \\ --lista ../inflation/$lista \\ --listb ../inflation/$listb #:: # 2. compute sum(r^2): see for details #:: Rscript --vanilla ../inflation/calc-sum-r2.r $filein $fileout done &quot;&gt;sh_script/calc-sum-r2 # submit the job m=1000 nm=1k sbatch -A snpher ../sh_script/calc-sum-r2 &gt;../job-records/calc-sum-r2-$nm-snps-badgwas 12.3 bad GWASs-all qced snps # script echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 20G #SBATCH -c 10 #SBATCH -t 4:00:0 #::: # 0. define vars &amp; create snp lists #::: # to be changed m=1000 nm=1k snpa=../gen/left-mix-pop.snps snpb=../gen/right-mix-pop.snps id=../mix-pop-gwas.id bfile=../gen/geno-mix lista=left-snps-badgwas-$nm listb=right-snps-badgwas-$nm out=$nm-snps-badgwas filein=$nm-snps-badgwas.pairwise fileout=sum-r2-$nm-snps-badgwas # loop and recycle files to avoid storage problems for i in {1..500}; do #:: # 1. create snp lists &amp; use ldak to compute r_i,j #:: shuf $snpa | head -n $m &gt; ../inflation/$lista shuf $snpb | head -n $m &gt; ../inflation/$listb ./ldak5.2 --max-threads 10 \\ --calc-inflation ../inflation/out/$out \\ --bfile $bfile \\ --keep $id \\ --lista ../inflation/$lista \\ --listb ../inflation/$listb #:: # 2. compute sum(r^2): see for details #:: Rscript --vanilla ../inflation/calc-sum-r2.r $filein $fileout done &quot;&gt;sh_script/calc-sum-r2 # submit the job m=1000 nm=1k sbatch -A snpher ../sh_script/calc-sum-r2 &gt;../job-records/calc-sum-r2-$nm-snps-badgwas 12.4 summary #:: # ave r_ij^2 #:: # good gwas grep &#39;Average squared correlation&#39; sh_out/calc-sum-r2-60083794.out | awk &#39;{split($0, a, &quot;;&quot;) split(a[1], b, &quot; &quot;); print b[5]}&#39; &gt; inflation/summary/ave-r2-1k-snps-goodgwas # bad gwas grep &#39;Average squared correlation&#39; sh_out/calc-sum-r2-60086056.out | awk &#39;{split($0, a, &quot;;&quot;) split(a[1], b, &quot; &quot;); print b[5]}&#39; &gt; inflation/summary/ave-r2-1k-snps-badgwas R good=read.table(&quot;inflation/summary/ave-r2-1k-snps-goodgwas&quot;, header=F) bad=read.table(&quot;inflation/summary/ave-r2-1k-snps-badgwas&quot;, header=F) png(&quot;fig/ave-r2-his-1k-snps.png&quot;, width =40, height = 20, units = &quot;cm&quot;, res=600) par(mfrow=c(1,2)) hist(good$V1, main=&quot;ave r2 good GWAS&quot;, breaks=50, freq=F, col=&quot;lightgray&quot;, border=&quot;lightgray&quot;) hist(bad$V1, main=&quot;ave r2 bad GWAS&quot;, breaks=50, freq=F, col=&quot;lightgray&quot;, border=&quot;lightgray&quot;) dev.off() # mean var # good 1.004277e-05 2.172758e-16 # bad 0.0003566028 9.250966e-10 #:: # r_ij^2 #:: require(vroom) good=vroom(&quot;inflation/out/1k-snps-goodgwas.pairwise&quot;, col_names=F) bad=vroom(&quot;inflation/out/1k-snps-badgwas.pairwise&quot;, col_names=F) r2_good=c(as.matrix(good)^2) r2_bad=c(as.matrix(bad)^2) png(&quot;fig/r2-his-1k-snps.png&quot;, width =40, height = 20, units = &quot;cm&quot;, res=600) par(mfrow=c(1,2)) hist(r2_good, main=&quot;r2 good GWAS&quot;, breaks=100, freq=F, col=&quot;lightgray&quot;, border=&quot;lightgray&quot;) hist(r2_bad, main=&quot;r2 bad GWAS&quot;, breaks=100, freq=F, col=&quot;lightgray&quot;, border=&quot;lightgray&quot;) dev.off() # mean var # good 1.002858e-05 2.020087e-10 # bad 0.0003632657 2.666479e-06 # good gwas dat=read.table(&quot;inflation/summary/sum-r2-1k-snps-goodgwas&quot;, header=F) png(paste0(&quot;fig/sumr2-good-gwas-1k-snps.png&quot;), width =20, height = 20, units = &quot;cm&quot;, res=600) hist(dat$V1, main=&quot;good GWAS&quot;) dev.off() # bad gwas dat=read.table(&quot;inflation/summary/sum-r2-1k-snps-badgwas&quot;, header=F) png(paste0(&quot;fig/sumr2-bad-gwas-1k-snps.png&quot;), width =20, height = 20, units = &quot;cm&quot;, res=600) hist(dat$V1, main=&quot;bad GWAS&quot;) dev.off() 12.5 compute aver2_j compute aver2_j. #::: # 1. compute r^2 #::: echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 20G #SBATCH -c 10 #SBATCH -t 4:00:0 #::: # 0. define vars &amp; create snp lists #::: # to be changed m=10000 nm=10k lista=left-snps-unrel-inds-\\$nm listb=right-snps-unrel-inds-\\$nm # NOTE: both good and bad gwas share the same snp list: snps-unrel-inds.use awk &#39;{split(\\$1, a, \\&quot;:\\&quot;); if (a[1]&lt;8) print \\$1 }&#39; ../gen/snps-unrel-inds.use | shuf | head -n \\$m &gt;../inflation/\\$lista awk &#39;{split(\\$1, a, \\&quot;:\\&quot;); if (a[1]&gt;=8) print \\$1 }&#39; ../gen/snps-unrel-inds.use | shuf | head -n \\$m &gt;../inflation/\\$listb #:: # 1. good gwas #:: id=../unrelated/rand.100000 bfile=../gen/geno-unrel out=\\$nm-snps-goodgwas ./ldak5.2 --max-threads 10 \\ --calc-inflation ../inflation/out/\\$out \\ --bfile \\$bfile \\ --keep \\$id \\ --lista ../inflation/\\$lista \\ --listb ../inflation/\\$listb #:: # 2. bad gwas #:: id=../mix-pop-gwas.id bfile=../gen/geno-mix out=\\$nm-snps-badgwas ./ldak5.2 --max-threads 10 \\ --calc-inflation ../inflation/out/\\$out \\ --bfile \\$bfile \\ --keep \\$id \\ --lista ../inflation/\\$lista \\ --listb ../inflation/\\$listb &quot;&gt;sh_script/calc-sum-r2 # submit the job m=10000 nm=10k sbatch -A snpher ../sh_script/calc-sum-r2 &gt;../job-records/calc-sum-r2-$nm-snps #::: # 2. compute ave r_j^2 for each i #::: R require(vroom) names=c(&quot;goodgwas&quot;, &quot;badgwas&quot;) for(i in 1:length(names)){ nm=names[i] dat=vroom(paste0(&quot;inflation/out/10k-snps-&quot;,nm,&quot;.pairwise&quot;), col_names=F) lista=read.table(paste0(&quot;inflation/out/10k-snps-&quot;,nm,&quot;.predictorsa&quot;), stringsAsFactors = F) listb=read.table(paste0(&quot;inflation/out/10k-snps-&quot;,nm,&quot;.predictorsb&quot;), stringsAsFactors = F) dat=dat[,-c(10001)]^2 outb=data.frame(predictor=listb$V1, ave_r2=apply(dat,2, mean)) outa=data.frame(predictor=lista$V1, ave_r2=apply(dat,1, mean)) out=rbind(outa,outb) write.table(out,paste0(&quot;summary/ave-r2-by-snp-&quot;,nm), col.names=F, row.names=F, quote=F) } #::: # 3. convert to rs system #::: awk &#39;(NR==FNR){a[$1]; b[$1]=$2; next}($1 in a){print b[$1], $2}&#39; doug/ukbb.ldsc summary/ave-r2-by-snp-goodgwas &gt; summary/ave-r2-by-snp-goodgwas-rs awk &#39;(NR==FNR){a[$1]; b[$1]=$2; next}($1 in a){print b[$1], $2}&#39; doug/ukbb.ldsc summary/ave-r2-by-snp-badgwas &gt; summary/ave-r2-by-snp-badgwas-rs 12.6 mixed pop GWAS with PC as covariates Previously we conducted mixed pop GWAS with the first 40 PC as covariates. Since we used the same genotype data (i.e., the same individuals) as for the bad GWASs, \\(\\overline{r^2_j}\\) is the same. The difference is the chi-square test statistics. Here we want to check if the relationship between \\(\\overline{r^2_j}\\) and chi square still exists for the bad gwas. # align GWAS test statistics with ld score-------------------------------------- dir1=&quot;gwas-mix-with-cov/&quot; dir2=&quot;unrelated/gwas-good/&quot; dir3=&quot;gwas-mix/&quot; require(&quot;vroom&quot;) snps=vroom(&quot;overlap-control-good-bad.ldscore&quot;, col_names=F) names(snps)=c(&quot;snp&quot;,&quot;ldsc_ref&quot;) traits=c(&quot;awake&quot;,&quot;bmi&quot;,&quot;chron&quot;,&quot;ever&quot;, &quot;neur&quot;,&quot;pulse&quot;,&quot;quals&quot;, &quot;fvc&quot;, &quot;height&quot;,&quot;imp&quot;, &quot;reaction&quot;,&quot;sbp&quot;,&quot;snoring&quot;,&quot;hyper&quot;) for(i in 1:length(traits)){ trait=traits[i] dat1=vroom(paste0(dir1,trait,&quot;-linear-rs.summaries&quot;), col_names=T) dat2=vroom(paste0(dir2,trait,&quot;-linear-rs.summaries&quot;), col_names=T) dat3=vroom(paste0(dir3,trait,&quot;-linear-rs.summaries&quot;), col_names=T) m1=match(snps$snp, dat1$SNP) m2=match(snps$snp, dat2$SNP) m3=match(snps$snp, dat3$SNP) out=data.frame(SNP=snps$snp, ldsc_ref=snps$ldsc_ref, bad_cov_chisq=dat1$Z[m1]^2, good_chisq=dat2$Z[m2]^2, bad_chisq=dat3$Z[m3]^2, stringsAsFactors = F) out=out[complete.cases(out),] # bin LD scores according to quantiles cutoff1=quantile(out$ldsc_ref, probs = seq(0, 1, 0.005)) out$ldsc_ref_bin=cut(out$ldsc_ref, breaks=cutoff1, labels=1:(length(cutoff1)-1)) write.table(out,paste0(&quot;summary/&quot;,trait,&quot;-gwas-test-stats-compare3.txt&quot;), col.names=T, row.names=F, quote=F) } # align chisq with ave r^2_j---------------------------------------------------- stat=vroom(&quot;gen/geno-unrel-rs.maf&quot;, col_names=F) r2_good=vroom(&quot;summary/ave-r2-by-snp-goodgwas-rs&quot;, col_names=F) r2_bad=vroom(&quot;summary/ave-r2-by-snp-badgwas-rs&quot;, col_names=F) traits=c(&quot;awake&quot;,&quot;bmi&quot;,&quot;chron&quot;,&quot;ever&quot;, &quot;neur&quot;,&quot;pulse&quot;,&quot;quals&quot;, &quot;fvc&quot;, &quot;height&quot;,&quot;imp&quot;, &quot;reaction&quot;,&quot;sbp&quot;,&quot;snoring&quot;,&quot;hyper&quot;) for(i in 1:length(traits)){ trait=traits[i] dat=vroom(paste0(&quot;summary/&quot;,trait,&quot;-gwas-test-stats-compare3.txt&quot;), col_names=T) inflation=data.frame(snp=dat$SNP, inflation=dat$bad_chisq-dat$good_chisq, bad_chisq=dat$bad_chisq, bad_cov_chisq=dat$bad_cov_chisq, good_chisq=dat$good_chisq, stringsAsFactors = F) m1=match(inflation$snp, stat$X1) m2=match(inflation$snp,r2_good$X1) m3=match(inflation$snp,r2_bad$X1) out=data.frame(inflation, maf=stat$X4[m1], r2_good=r2_good$X2[m2], r2_bad=r2_bad$X2[m2], stringsAsFactors = F) # bin maf &amp; r2_bad according to quantiles cutoff1=quantile(out$maf, probs = seq(0, 1, 0.005), na.rm=T) cutoff2=quantile(out$r2_bad, probs = seq(0, 1, 0.005), na.rm=T) cutoff3=quantile(out$r2_good, probs = seq(0, 1, 0.005), na.rm=T) out$maf_bin=cut(out$maf, breaks=cutoff1, labels=1:(length(cutoff1)-1)) out$r2_bad_bin=cut(out$r2_bad, breaks=cutoff2, labels=1:(length(cutoff2)-1)) out$r2_good_bin=cut(out$r2_good, breaks=cutoff3, labels=1:(length(cutoff3)-1)) write.table(out,paste0(&quot;inflation/summary/&quot;,trait,&quot;-inflation-by-maf-r2&quot;), col.names=T, row.names=F, quote=F) } # plot bad chisq by binned ave r2 -------------------------------------------------- require(vroom) traits=c(&quot;awake&quot;,&quot;bmi&quot;,&quot;chron&quot;,&quot;ever&quot;, &quot;neur&quot;,&quot;pulse&quot;,&quot;quals&quot;, &quot;fvc&quot;, &quot;height&quot;,&quot;imp&quot;, &quot;reaction&quot;,&quot;sbp&quot;,&quot;snoring&quot;,&quot;hyper&quot;) png(paste0(&quot;fig/badgwas-with-cov-chisq-by-aver2-bin.png&quot;), width = 50, height = 30, units = &quot;cm&quot;, res=600) par(mfrow=c(3,5)) for(i in 1:length(traits)){ trait=traits[i] dat=vroom(paste0(&quot;inflation/summary/&quot;,trait,&quot;-inflation-by-maf-r2&quot;), col_names=T) sel=dat[,c(&quot;snp&quot;,&quot;bad_cov_chisq&quot;,&quot;r2_bad&quot;,&quot;r2_bad_bin&quot;)] sel=sel[complete.cases(sel),] out=data.frame(bad_cov_chisq=tapply(sel$bad_cov_chisq,INDEX=sel$r2_bad_bin, mean)) out$r2_bad_bin=1:dim(out)[1] out$r2_bad_bin_val=tapply(sel$r2_bad,INDEX=sel$r2_bad_bin, mean) plot(out$r2_bad_bin_val, out$bad_cov_chisq, xlab=&quot;ave r2&quot;, ylab=&quot;chisq test stat&quot;, main=trait, las=1, cex = 1.5, pch=21, bg=&quot;grey&quot;, col=&quot;white&quot;, lwd=0.5) } dev.off() # plot good chisq by binned ave r2 -------------------------------------------------- require(vroom) traits=c(&quot;awake&quot;,&quot;bmi&quot;,&quot;chron&quot;,&quot;ever&quot;, &quot;neur&quot;,&quot;pulse&quot;,&quot;quals&quot;, &quot;fvc&quot;, &quot;height&quot;,&quot;imp&quot;, &quot;reaction&quot;,&quot;sbp&quot;,&quot;snoring&quot;,&quot;hyper&quot;) png(paste0(&quot;fig/goodgwas-chisq-by-aver2-bin.png&quot;), width = 50, height = 30, units = &quot;cm&quot;, res=600) par(mfrow=c(3,5)) for(i in 1:length(traits)){ trait=traits[i] dat=vroom(paste0(&quot;inflation/summary/&quot;,trait,&quot;-inflation-by-maf-r2&quot;), col_names=T) sel=dat[,c(&quot;snp&quot;,&quot;good_chisq&quot;,&quot;r2_good&quot;,&quot;r2_good_bin&quot;)] sel=sel[complete.cases(sel),] out=data.frame(good_chisq=tapply(sel$good_chisq,INDEX=sel$r2_good_bin, mean)) out$r2_good_bin=1:dim(out)[1] out$r2_good_bin_val=tapply(sel$r2_good,INDEX=sel$r2_good_bin, mean) plot(out$r2_good_bin_val, out$good_chisq, xlab=&quot;ave r2&quot;, ylab=&quot;chisq test stat&quot;, main=trait, las=1, cex = 1.5, pch=21, bg=&quot;grey&quot;, col=&quot;white&quot;, lwd=0.5) } dev.off() # plot chisq by ldsc----------------------------------------------------------- require(&quot;vroom&quot;) traits=c(&quot;awake&quot;,&quot;bmi&quot;,&quot;chron&quot;,&quot;ever&quot;, &quot;neur&quot;,&quot;pulse&quot;,&quot;quals&quot;, &quot;fvc&quot;, &quot;height&quot;,&quot;imp&quot;, &quot;reaction&quot;,&quot;sbp&quot;,&quot;snoring&quot;,&quot;hyper&quot;) png(paste0(&quot;fig/badgwas-with-cov-by-ldscbin.png&quot;), width =50, height = 30, units = &quot;cm&quot;, res=600) par(mfrow=c(3,5)) for(i in 1:length(traits)){ trait=traits[i] trait dat=vroom(paste0(&quot;summary/&quot;,trait,&quot;-gwas-test-stats-compare3.txt&quot;), col_names=T) out1=data.frame(ave_ldscore=tapply(dat$ldsc_ref,INDEX=dat$ldsc_ref_bin, mean), ave_good_chisq=tapply(dat$good_chisq,INDEX=dat$ldsc_ref_bin, mean), ave_bad_cov_chisq=tapply(dat$bad_cov_chisq,INDEX=dat$ldsc_ref_bin, mean)) #out2=data.frame(ave_ldscore=tapply(dat$ldsc_mix,INDEX=dat$ldsc_mix_bin, mean), # ave_control_chisq=tapply(dat$control_chisq,INDEX=dat$ldsc_mix_bin, mean), # ave_good_chisq=tapply(dat$good_chisq,INDEX=dat$ldsc_mix_bin, mean), # ave_bad_chisq=tapply(dat$bad_chisq,INDEX=dat$ldsc_mix_bin, mean)) end=round(max(c(out1[,2], out1[,3])),0) #end2=round(max(c(out2[,2], out2[,3], out2[,4])),0) #end=max(end1,end2) start=0 plot(out1$ave_ldscore, out1$ave_good_chisq, xlab=&quot;ldscore&quot;, ylab=&quot;mean chisquare&quot;, ylim=c(start, end), main=trait, las=1, cex = 1.5, pch=21, bg=&quot;gray&quot;, col=&quot;white&quot;, lwd=0.5) points(out1$ave_ldscore, out1$ave_bad_cov_chisq, cex = 1.5, pch=21, col=&quot;white&quot;, bg=&quot;orange&quot;) } dev.off() # regress chi square from bad gwas with cov on ldsc require(vroom) traits=c(&quot;awake&quot;,&quot;bmi&quot;,&quot;chron&quot;,&quot;ever&quot;, &quot;neur&quot;,&quot;pulse&quot;,&quot;quals&quot;, &quot;fvc&quot;, &quot;height&quot;,&quot;imp&quot;, &quot;reaction&quot;,&quot;sbp&quot;,&quot;snoring&quot;,&quot;hyper&quot;) for(i in 1:length(traits)){ trait=traits[i] trait dat=vroom(paste0(&quot;summary/&quot;,trait,&quot;-gwas-test-stats-compare3.txt&quot;), col_names=T) dat2=vroom(paste0(&quot;inflation/summary/&quot;,trait,&quot;-inflation-by-maf-r2&quot;), col_names=T) m=match(dat$SNP,dat2$snp) out=data.frame(dat2[m,-c(9:11)],dat[,-c(1,3:6)]) out=out[complete.cases(out),] #ldsc_ref2=(out$ldsc_ref)^2 #r2_bad2=(out$r2_bad)^2 mod0=lm(bad_cov_chisq ~ 1,data=out) mod1=lm(bad_cov_chisq ~ ldsc_ref,data=out) mod1.1=lm(bad_chisq ~ ldsc_ref + ldsc_ref2 ,data=out) mod2=lm(bad_chisq ~ r2_bad, data=out) mod2.1=lm(bad_chisq ~ r2_bad + r2_bad2, data=out) mod3=lm(bad_chisq ~ r2_bad + ldsc_ref ,data=out) mod3.1=lm(bad_chisq ~ r2_bad + ldsc_ref + ldsc_ref2 ,data=out) mod3.2=lm(bad_chisq ~ r2_bad + ldsc_ref + ldsc_ref2 + r2_bad*ldsc_ref ,data=out) mod4=lm(bad_chisq ~ r2_bad + ldsc_ref + r2_bad*ldsc_ref ,data=out) p0=data.frame(trait=trait, p_r2=anova(mod2, mod0)$P[2], p_r2_2=anova(mod2.1, mod2)$P[2], p_ldsc=anova(mod3,mod2)$P[2], p_ldsc2=anova(mod3.1,mod3)$P[2], p_ldsc_r2=anova(mod4,mod3)$P[2], stringsAsFactors = F) if(i==1){p=p0} else{p=rbind(p,p0)} } p_bad=p Bulik-Sullivan, B. K., Loh, P.-R., Finucane, H. K., Ripke, S., Yang, J., Patterson, N., Daly, M. J., Price, A. L., &amp; Neale, B. M. (2015). LD score regression distinguishes confounding from polygenicity in genome-wide association studies. Nature Genetics, 47(3), 291–295. Holmes, J. B., Speed, D., &amp; Balding, D. J. (2019). Summary statistic analyses can mistake confounding bias for heritability. Genetic Epidemiology, 43(8), 930–940. https://doi.org/https://doi.org/10.1002/gepi.22259 "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
