[["ukbb.html", "5 UKBB recommended 5.1 total N = 337k 5.2 QC of hp3 SNPs 5.3 GWAS 5.4 ldsc intercept 5.5 HE", " 5 UKBB recommended 5.1 total N = 337k Here we want to identify the unrelated white individuals recommended by the UKBB. Email from Florian: “We restrict individuals to the ones used for computing the principal components (PCs) in the UK Biobank (Field 22020). These individuals are unrelated and have passed some quality control including removing samples with a missing rate on autosomes larger than 0.02, having a mismatch between inferred sex and self-reported sex, and outliers based on heterozygosity (more details can be found in section S3 of Bycroft et al. (2018)).” And the White British are from this: https://biobank.ctsu.ox.ac.uk/crystal/field.cgi?id=22006 So required data fields: PC: 22020 White british: 22006 options(scipen = 100) # extract data head=read.table(&quot;phen/ukb45861.header&quot;, sep=&quot;,&quot;, header=F, stringsAsFactors = F) # function to get the variables get=function(nm){ colnum=grep(nm,head,fixed=TRUE) out=data.frame(t(rbind(colnum, head[,colnum]))) names(out)=c(&quot;column&quot;, &quot;field&quot;) return (out) } # get the variables out=rbind(get(&#39;22020-0&#39;), # PC get(&#39;22006-0&#39;)) # white british write.table(out,&quot;phen/vars.colnum&quot;, col.names=F, row.names=F, sep=&quot;\\t&quot;, quote=F) # extract dat awk -F &#39;&quot;,&quot;&#39; &#39;(NR==FNR){a[$1];next}{printf &quot;%s\\&quot;&quot;, $1;for(i in a){printf &quot; \\&quot;%s\\&quot;&quot;, $i};printf &quot;\\n&quot;}&#39; phen/vars.colnum phen/ukb45861.csv &gt; phen/ukbb-recommended.dat # get the id list of the intersect of the two data fields dat=read.table(&quot;phen/ukbb-recommended.dat&quot;, header=T, stringsAsFactors=F) id1=dat$eid[dat$X22020.0.0==1 &amp; !is.na(dat$X22020.0.0)] id2=dat$eid[dat$X22006.0.0==1 &amp; !is.na(dat$X22006.0.0)] out=intersect(id1,id2) # N = 337,462 write.table(out, &quot;ukbb-recommend.id&quot;, col.names=F, row.names=F, quote=F) 5.2 QC of hp3 SNPs Here we do QC to 1.2M hapmap3 SNPs for the UKBB recommended individuals. # QC SNPs----------------------------------------------------------------------- # stating number of SNPs= 1,184,423 # note: at this stage, we use all UKBB recommended IDs # we will do a random selection of IDs later. for j in {1..22}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 20G #SBATCH -c 3 #SBATCH -t 1:0:0 ./plink2 --pfile ../gen/geno_plink/bhr$j \\ --keep ../ukbb-recommend.id \\ --extract ../doug/ukbb.ldsc \\ --hwe 0.0001 \\ --hard-call-threshold .05 \\ --mach-r2-filter 0.8 2 \\ --make-bed \\ --memory 20000 \\ --out ../gen/tmp/bhr$j-norm \\ --threads 3 &quot;&gt; sh_script/chr$j.sh done # submit jobs for j in {1..22}; do sbatch -A snpher ../sh_script/chr$j.sh done &gt; ../job-records/qc-norm # merge files rm bfile-norm.list for j in {1..22}; do echo &quot;../gen/tmp/bhr$j-norm&quot; &gt;&gt;bfile-norm.list done echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 20G #SBATCH -c 3 #SBATCH -t 20:0:0 ./ldak5.1 --make-bed ../gen/geno-norm \\ --mbfile ../gen/bfile-norm.list \\ --max-threads 3 \\ --exclude-dups YES &quot;&gt; sh_script/mbfile-norm.sh # submit the script sbatch -A snpher ../sh_script/mbfile-norm.sh &gt;../job-records/mbfiles-norm # randomly select 100k individuals shuf ukbb-recommend.id | head -n 100000 &gt; ukbb-recommned-rand.100000 # make bfile for these individuals echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 20G #SBATCH -c 3 #SBATCH -t 20:0:0 ./ldak5.1 --make-bed ../gen/geno-norm-100k \\ --bfile ../gen/geno-norm \\ --keep ../ukbb-recommned-rand.100000 \\ --max-threads 3 \\ --exclude-dups YES &quot;&gt; sh_script/mbfile-norm-100k.sh # submit the script sbatch -A snpher ../sh_script/mbfile-norm-100k.sh &gt;../job-records/mbfiles-norm-100k # MAF &amp; call-rate awk &lt; geno-norm-100k.stats &#39;($5&gt;.01 &amp;&amp; $6&gt;=0.95 &amp;&amp; NR&gt;1){print $1}&#39; &gt; snps-norm-100k.use # m = 1,100,799 SNPs 5.3 GWAS # linear regression------------------------------------------------------------- mkdir gwas-norm for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 10G #SBATCH -c 2 #SBATCH -t 10:0:0 ./ldak5.1 --linear ../gwas-norm/$i-linear \\ --pheno ../phen/continuous-traits/$i.raw.pheno \\ --bfile ../gen/geno-norm-100k \\ --keep ../ukbb-recommned-rand.100000 \\ --extract ../gen/snps-norm-100k.use \\ --covar ../phen/covariates.use \\ --max-threads 2 \\ &quot;&gt; sh_script/$i-linear.sh done # submit files------------------------------------------------------------------ for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do sbatch -A snpher ../sh_script/$i-linear.sh done&gt;../job-records/gwas-norm # check job completion---------------------------------------------------------- file=job-records/gwas-norm jobs=`awk &#39;{print $4}&#39; $file` mkdir $file-tmp for i in $jobs; do jobinfo $i | awk -F &quot;:&quot; -v i=$i &#39;$1~/Name/ {print i, $2}&#39; &gt;&gt; $file-tmp/name.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/State/ {print$2}&#39; &gt;&gt; $file-tmp/state.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Cores/ {print$2}&#39; &gt;&gt; $file-tmp/cores.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Used walltime/ {print $2 &quot;:&quot; $3 &quot;:&quot; $4}&#39; &gt;&gt; $file-tmp/time.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Max Mem/ {split($2,a,/[(]/ ); print a[1]}&#39; &gt;&gt; $file-tmp/mem.tmp done paste $file-tmp/name.tmp \\ $file-tmp/state.tmp \\ $file-tmp/cores.tmp \\ $file-tmp/time.tmp \\ $file-tmp/mem.tmp \\ | awk &#39;BEGIN{print &quot;ID name state cores time mem&quot;}{print $0}&#39; &gt; $file.out rm -r $file-tmp 5.4 ldsc intercept 5.4.1 under gcta #::::::::::::: # using original ldsc #::::::::::::: # format stats for ldsc--------------------------------------------------------- library(vroom) options(scipen = 100) rs=vroom(&quot;doug/ukbb.ldsc&quot;, col_names=F) phen=c(&quot;awake&quot;,&quot;bmi&quot;,&quot;chron&quot;,&quot;ever&quot;,&quot;fvc&quot;, &quot;height&quot;,&quot;imp&quot;,&quot;neur&quot;,&quot;pulse&quot;,&quot;quals&quot;, &quot;reaction&quot;,&quot;sbp&quot;,&quot;snoring&quot;,&quot;hyper&quot;, &quot;quals&quot;) for(i in phen){ stat=vroom(paste0(&quot;gwas-norm/&quot;,i,&quot;-linear.summaries&quot;), col_names=T) p=vroom(paste0(&quot;gwas-norm/&quot;,i,&quot;-linear.pvalues&quot;), col_names=T) m1=match(rs$X1, stat$Predictor) m2=match(rs$X1, p$Predictor) out=data.frame(SNP=rs$X2, N=stat$n[m1], Z=(sqrt(stat$Stat)*stat$Direction)[m1], A1=stat$A1[m1], A2=stat$A2[m1], pval=p$P[m2], stringsAsFactors=F) out=out[complete.cases(out),] write.table(out, paste0(&quot;gwas-norm/&quot;,i,&quot;-linear-rs.summaries&quot;), col.names=T, row.names=F, quote=F) } # perform ldsc------------------------------------------------------------------ mkdir out-norm-100k for i in {awake,bmi,chron,ever,fvc,height,quals,imp,neur,pulse,reaction,sbp,snoring,hyper}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 2G #SBATCH -c 3 #SBATCH -t 24:00:0 .././munge_sumstats.py \\ --sumstats ../../gwas-norm/$i-linear-rs.summaries \\ --out ../out-norm-100k/$i \\ --merge-alleles ../w_hm3.snplist .././ldsc.py \\ --h2 ../out-norm-100k/$i.sumstats.gz \\ --ref-ld-chr ../eur_w_ld_chr/ \\ --w-ld-chr ../eur_w_ld_chr/ \\ --out ../out-norm-100k/$i-ldsc &quot;&gt;sh_script/ldsc-$i-norm-100k.sh done # submit jobs------------------------------------------------------------------- for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,reaction,sbp,snoring,hyper,quals}; do sbatch -A snpher ../sh_script/ldsc-$i-norm-100k.sh done&gt;../../job-records/ldsc-norm-100k #::::::::::::: # using sumher #::::::::::::: # insert genetic distance into bim file----------------------------------------- head geno-norm-100k.fam &gt; small-norm for j in {1..22}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --mem 8G #SBATCH -c 1 #SBATCH -t 3:00:0 #SBATCH --constraint \\&quot;s04|s05\\&quot; ./plink1.9 --bfile ../gen/geno-norm-100k \\ --chr $j \\ --cm-map /home/zhoux/snpher/faststorage/genetic_maps/genetic_map_chr@_combined_b37.txt \\ --make-bed \\ --out new$j \\ --keep ../gen/small-norm &quot; &gt; sh_script/map$j done for j in {1..22}; do sbatch -A snpher ../sh_script/map$j done &gt; genetic-distance-hapmap3 cd /home/zhoux/dsmwpred/xuan/quality-control/qc-10oct/gen cat new{1..22}.bim | awk &#39;{print $2, $3}&#39; &gt; maps-hapmap3-norm-100k.txt rm new{1..22}.{bim,bed,fam,log} awk &#39;(NR==FNR){arr[$1]=$2;next}{print $1, $2, arr[$2], $4, $5, $6}&#39; &gt; geno-norm-100k.bim2 maps-hapmap3-norm-100k.txt geno-norm-100k.bim mv geno-norm-100k.bim geno-norm-100k.bim0 mv geno-norm-100k.bim2 geno-norm-100k.bim # compute tagging under gcta---------------------------------------------------- mkdir tagging-norm-100k for j in {1..22}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 5G #SBATCH -c 1 #SBATCH -t 5:0:0 ./ldak5.1 --calc-tagging ../tagging-norm-100k/gcta-hapmap3-chr-$j \\ --bfile ../gen/geno-norm-100k \\ --ignore-weights YES \\ --power -1 \\ --window-cm 1 \\ --chr $j &quot;&gt; sh_script/tagging-gcta-hapmap3-chr$j done for j in {1..22}; do sbatch -A snpher ../sh_script/tagging-gcta-hapmap3-chr$j done &gt; ../job-records/tagging-gcta-hapmap3-norm-100k # check job completion---------------------------------------------------------- file=job-records/tagging-gcta-hapmap3-norm-100k jobs=`awk &#39;{print $4}&#39; $file` mkdir $file-tmp for i in $jobs; do jobinfo $i | awk -F &quot;:&quot; -v i=$i &#39;$1~/Name/ {print i, $2}&#39; &gt;&gt; $file-tmp/name.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/State/ {print$2}&#39; &gt;&gt; $file-tmp/state.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Cores/ {print$2}&#39; &gt;&gt; $file-tmp/cores.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Used walltime/ {print $2 &quot;:&quot; $3 &quot;:&quot; $4}&#39; &gt;&gt; $file-tmp/time.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Max Mem/ {split($2,a,/[(]/ ); print a[1]}&#39; &gt;&gt; $file-tmp/mem.tmp done paste $file-tmp/name.tmp \\ $file-tmp/state.tmp \\ $file-tmp/cores.tmp \\ $file-tmp/time.tmp \\ $file-tmp/mem.tmp \\ | awk &#39;BEGIN{print &quot;ID name state cores time mem&quot;}{print $0}&#39; &gt; $file.out rm -r $file-tmp # merge tagging files----------------------------------------------------------- rm list.txt for j in {1..22}; do echo &quot;tagging-norm-100k/gcta-hapmap3-chr-$j.tagging&quot; &gt;&gt; list.txt done ./ldak5.1 --join-tagging tagging-norm-100k/gcta-hapmap3 --taglist list.txt # ldsc intercept---------------------------------------------------------------- mkdir sumher-norm-100k dirin1=tagging-norm-100k dirin2=gwas-norm dirout=sumher-norm-100k for i in {awake,bmi,chron,ever,fvc,height,quals,imp,neur,pulse,reaction,sbp,snoring,hyper}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 5G #SBATCH -c 1 #SBATCH -t 5:0:0 ./ldak5.1 --sum-hers ../$dirout/$i-sumher-gcta \\ --tagfile ../$dirin1/gcta-hapmap3.tagging \\ --summary ../$dirin2/$i-linear.summaries \\ --check-sums NO \\ --intercept YES &quot;&gt; sh_script/$i-sumher-gcta done for i in {awake,bmi,chron,ever,fvc,height,quals,imp,neur,pulse,reaction,sbp,snoring,hyper}; do sbatch -A snpher ../sh_script/$i-sumher-gcta done&gt;../job-records/sumher-gcta-norm-100k 5.4.2 under ldak-thin # get weights------------------------------------------------------------------- awk &lt; ldak-thin/ldak-thin-norm.in &#39;{print $1, 1}&#39; &gt; ldak-thin/weights.ldak-thin-norm # calculate tagging under ldak-thin--------------------------------------------- dirout=tagging-norm-100k filein1=geno-norm-100k filein2=weights.ldak-thin-norm for j in {1..22}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --partition normal #SBATCH --mem 40G #SBATCH -c 5 #SBATCH -t 10:0:0 #SBATCH --constraint \\&quot;s04|s05\\&quot; ./ldak5.1 --calc-tagging ../$dirout/ldak-thin-hapmap3-chr-$j \\ --bfile ../gen/$filein1 \\ --weights ../ldak-thin/$filein2 \\ --power -.25 \\ --window-cm 1 \\ --chr $j \\ --save-matrix YES \\ --max-threads 5 &quot; &gt; sh_script/tagging-ldak-thin-hapmap3-chr$j.sh done # submit scripts for j in {1..22}; do sbatch -A snpher ../sh_script/tagging-ldak-thin-hapmap3-chr$j.sh done &gt; ../job-records/tagging-ldak-thin-norm-100k # check job completion---------------------------------------------------------- file=job-records/tagging-ldak-thin-norm-100k jobs=`awk &#39;{print $4}&#39; $file` mkdir $file-tmp for i in $jobs; do jobinfo $i | awk -F &quot;:&quot; -v i=$i &#39;$1~/Name/ {print i, $2}&#39; &gt;&gt; $file-tmp/name.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/State/ {print$2}&#39; &gt;&gt; $file-tmp/state.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Cores/ {print$2}&#39; &gt;&gt; $file-tmp/cores.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Used walltime/ {print $2 &quot;:&quot; $3 &quot;:&quot; $4}&#39; &gt;&gt; $file-tmp/time.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Max Mem/ {split($2,a,/[(]/ ); print a[1]}&#39; &gt;&gt; $file-tmp/mem.tmp done paste $file-tmp/name.tmp \\ $file-tmp/state.tmp \\ $file-tmp/cores.tmp \\ $file-tmp/time.tmp \\ $file-tmp/mem.tmp \\ | awk &#39;BEGIN{print &quot;ID name state cores time mem&quot;}{print $0}&#39; &gt; $file.out rm -r $file-tmp # merge tagging files----------------------------------------------------------- rm list.txt rm matlist.txt for j in {1..22}; do echo &quot;tagging-norm-100k/ldak-thin-hapmap3-chr-$j.tagging&quot; &gt;&gt; list.txt echo &quot;tagging-norm-100k/ldak-thin-hapmap3-chr-$j.matrix&quot; &gt;&gt; matlist.txt done dirout=tagging-norm-100k ./ldak5.1 --join-tagging $dirout/ldak-thin-hapmap3 --taglist list.txt --matlist matlist.txt # ldsc intercept---------------------------------------------------------------- dirin1=tagging-norm-100k dirin2=gwas-norm dirout=sumher-norm-100k for i in {awake,bmi,chron,ever,fvc,height,quals,imp,neur,pulse,reaction,sbp,snoring,hyper}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 5G #SBATCH -c 1 #SBATCH -t 00:30:0 ./ldak5.1 --sum-hers ../$dirout/$i-sumher-ldak-thin \\ --tagfile ../$dirin1/ldak-thin-hapmap3.tagging \\ --summary ../$dirin2/$i-linear.summaries \\ --check-sums NO \\ --intercept YES &quot;&gt; sh_script/$i-sumher-ldak-thin done for i in {awake,bmi,chron,ever,fvc,height,quals,imp,neur,pulse,reaction,sbp,snoring,hyper}; do sbatch -A snpher ../sh_script/$i-sumher-ldak-thin done&gt;../job-records/sumher-ldak-thin-norm-100k 5.4.3 summary # original ldsc grep Intercept *ldsc.log | awk &#39;{split($1, a, /[-]/); split($3, b, /[()]/); print a[1], $2, b[2]}&#39; &gt; ../../summary/ldsc-norm-100k # sumher under gcta grep Intercept_Estimate *gcta.extra | awk &#39;{ split($1, a, /[-]/); print a[1], $2}&#39; &gt;../summary/sumher-gcta-norm-100k-est grep Intercept_SD *gcta.extra | awk &#39;{ split($1, a, /[-]/); print a[1], $2}&#39; &gt;../summary/sumher-gcta-norm-100k-sd cd ../summary/ paste sumher-gcta-norm-100k-est sumher-gcta-norm-100k-sd | awk &#39;{print $1, $2, $4}&#39; &gt; sumher-gcta-norm-100k # suhmer under ldak-thin grep Intercept_Estimate *ldak-thin.extra | awk &#39;{ split($1, a, /[-]/); print a[1], $2}&#39; &gt;../summary/sumher-ldak-thin-norm-100k-est grep Intercept_SD *ldak-thin.extra | awk &#39;{ split($1, a, /[-]/); print a[1], $2}&#39; &gt;../summary/sumher-ldak-thin-norm-100k-sd cd ../summary/ paste sumher-ldak-thin-norm-100k-est sumher-ldak-thin-norm-100k-sd | awk &#39;{print $1, $2, $4}&#39; &gt; sumher-ldak-thin-norm-100k 5.5 HE 5.5.1 making grms # making grm ------------------------------------------------------------------- #::: # under gcta #::: # all snps echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --partition normal #SBATCH --mem 60G #SBATCH -c 10 #SBATCH -t 08:0:0 #SBATCH --constraint \\&quot;s04|s05\\&quot; ./ldak5.1 --max-threads 10 \\ --calc-kins-direct ../kinship/gcta-all-norm \\ --bfile ../gen/geno-norm-100k \\ --extract ../gen/snps-norm-100k.use \\ --power -1 \\ --ignore-weights YES \\ --single YES &quot; &gt; sh_script/grm-all-snps-norm sbatch -A snpher ../sh_script/grm-all-snps-norm &gt; ../job-records/grm-all-snps-norm # grm by snp blocks: right vs. left awk &#39;$1&lt;8 {print $2}&#39; geno-norm-100k.bim &gt; left-snps-norm-100k.use awk &#39;$1&gt;=8 {print $2}&#39; geno-norm-100k.bim &gt; right-snps-norm-100k.use for i in left right; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --partition normal #SBATCH --mem 60G #SBATCH -c 10 #SBATCH -t 20:0:0 #SBATCH --constraint \\&quot;s04|s05\\&quot; ./ldak5.1 --max-threads 10 \\ --calc-kins-direct ../kinship/gcta-$i-norm \\ --bfile ../gen/geno-norm-100k \\ --extract ../gen/$i-snps-norm-100k.use \\ --power -1 \\ --ignore-weights YES \\ --single YES &quot; &gt; sh_script/grm-gcta-$i-norm done for i in left right; do sbatch -A snpher ../sh_script/grm-gcta-$i-norm done &gt; ../job-records/grm-gcta-by-snps-norm #::: # under ldak-thin #::: #----------- # 1. thin snps #----------- for j in {1..22}; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --partition normal #SBATCH --mem 10G #SBATCH -c 4 #SBATCH -t 4:0:0 #SBATCH --constraint \\&quot;s04|s05\\&quot; ./ldak5.1 --max-threads 4 \\ --window-prune 0.98 \\ --window-kb 100 \\ --extract ../gen/snps-norm-100k.use \\ --bfile ../gen/geno-norm-100k \\ --thin ../ldak-thin/chr$j-norm \\ --chr $j &quot; &gt; sh_script/ldak-thin$j-norm done # submit script for j in {1..22}; do sbatch -A snpher ../sh_script/ldak-thin$j-norm done &gt; ../job-records/ldak-thin-norm # check job completion--- file=job-records/ldak-thin-norm jobs=`awk &#39;{print $4}&#39; $file` mkdir $file-tmp for i in $jobs; do jobinfo $i | awk -F &quot;:&quot; -v i=$i &#39;$1~/Name/ {print i, $2}&#39; &gt;&gt; $file-tmp/name.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/State/ {print$2}&#39; &gt;&gt; $file-tmp/state.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Cores/ {print$2}&#39; &gt;&gt; $file-tmp/cores.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Used walltime/ {print $2 &quot;:&quot; $3 &quot;:&quot; $4}&#39; &gt;&gt; $file-tmp/time.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Max Mem/ {split($2,a,/[(]/ ); print a[1]}&#39; &gt;&gt; $file-tmp/mem.tmp done paste $file-tmp/name.tmp \\ $file-tmp/state.tmp \\ $file-tmp/cores.tmp \\ $file-tmp/time.tmp \\ $file-tmp/mem.tmp \\ | awk &#39;BEGIN{print &quot;ID name state cores time mem&quot;}{print $0}&#39; &gt; $file.out rm -r $file-tmp # combine snp list cat ldak-thin/chr{1..22}-norm.in &gt; ldak-thin/ldak-thin-norm.in #---------------------- # 2. kinship matrix under ldak-thin #------------------------ echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --partition normal #SBATCH --mem 60G #SBATCH -c 10 #SBATCH -t 08:0:0 #SBATCH --constraint \\&quot;s04|s05\\&quot; ./ldak5.1 --max-threads 10 \\ --calc-kins-direct ../kinship/ldak-thin-all-norm \\ --bfile ../gen/geno-norm-100k \\ --extract ../ldak-thin/ldak-thin-norm.in \\ --power -0.25 \\ --ignore-weights YES \\ --single YES &quot; &gt; sh_script/ldak-thin-grm-all-snps-norm sbatch -A snpher ../sh_script/ldak-thin-grm-all-snps-norm &gt; ../job-records/ldak-thin-grm-all-snps-norm # grm by snp blocks: right vs. left awk &#39;{split($1, a, /[:]/); if (a[1]&lt;8) print $1}&#39; \\ ldak-thin/ldak-thin-norm.in &gt; gen/left-ldak-thin-norm.snps awk &#39;{split($1, a, /[:]/); if (a[1]&gt;=8) print $1}&#39; \\ ldak-thin/ldak-thin-norm.in &gt; gen/right-ldak-thin-norm.snps for i in left right; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --partition normal #SBATCH --mem 60G #SBATCH -c 10 #SBATCH -t 08:0:0 #SBATCH --constraint \\&quot;s04|s05\\&quot; ./ldak5.1 --max-threads 10 \\ --calc-kins-direct ../kinship/ldak-thin-$i-norm \\ --bfile ../gen/geno-norm-100k \\ --extract ../gen/$i-ldak-thin-norm.snps \\ --power -0.25 \\ --ignore-weights YES \\ --single YES &quot; &gt; sh_script/ldak-thin-grm-$i-norm done for i in left right; do sbatch -A snpher ../sh_script/ldak-thin-grm-$i-norm done &gt; ../job-records/grm-ldak-thin-by-snps-norm 5.5.2 estimation NEED To check what covariates to adjust for HE basic.covariates.use or covariates.use? # regress grm on covariates----------------------------------------------------- for grm in gcta-all-norm gcta-left-norm gcta-right-norm ldak-thin-all-norm ldak-thin-left-norm ldak-thin-right-norm; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 50G #SBATCH -c 5 #SBATCH -t 10:0:0 ./ldak5.1 --adjust-grm ../kinship/$grm.covar \\ --grm ../kinship/$grm \\ --covar ../phen/covariates.use \\ --max-threads 5 &quot;&gt; sh_script/$grm-adjust.sh done # submit jobs for grm in gcta-all-norm gcta-left-norm gcta-right-norm ldak-thin-all-norm ldak-thin-left-norm ldak-thin-right-norm; do sbatch -A snpher ../sh_script/$grm-adjust.sh done &gt; ../job-records/grm-adjust-for-HE # check job completion---------------------------------------------------------- file=job-records/grm-adjust-for-HE jobs=`awk &#39;{print $4}&#39; $file` mkdir $file-tmp for i in $jobs; do jobinfo $i | awk -F &quot;:&quot; -v i=$i &#39;$1~/Name/ {print i, $2}&#39; &gt;&gt; $file-tmp/name.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/State/ {print$2}&#39; &gt;&gt; $file-tmp/state.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Cores/ {print$2}&#39; &gt;&gt; $file-tmp/cores.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Used walltime/ {print $2 &quot;:&quot; $3 &quot;:&quot; $4}&#39; &gt;&gt; $file-tmp/time.tmp jobinfo $i | awk -F &quot;:&quot; &#39;$1~/Max Mem/ {split($2,a,/[(]/ ); print a[1]}&#39; &gt;&gt; $file-tmp/mem.tmp done paste $file-tmp/name.tmp \\ $file-tmp/state.tmp \\ $file-tmp/cores.tmp \\ $file-tmp/time.tmp \\ $file-tmp/mem.tmp \\ | awk &#39;BEGIN{print &quot;ID name state cores time mem&quot;}{print $0}&#39; &gt; $file.out rm -r $file-tmp # HE under gcta----------------------------------------------------------------- for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do for k in all left right; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 2G #SBATCH -c 1 #SBATCH -t 00:30:0 ./ldak5.1 --he ../he-norm/$i-he-gcta-$k \\ --pheno ../phen/continuous-traits/$i.raw.pheno \\ --grm ../kinship/gcta-$k-norm.covar \\ --kinship-details NO \\ --check-root NO \\ --covar ../phen/covariates.use \\ --max-threads 1 \\ --memory-save YES &quot;&gt; sh_script/$i-he-gcta-$k-snps-norm.sh done done # submit files------------------------------------------------------------------ for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do for k in all left right; do sbatch -A snpher ../sh_script/$i-he-gcta-$k-snps-norm.sh done done &gt; ../job-records/he-gcta # HE under ldak-thin------------------------------------------------------------ for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do for k in all left right; do echo &quot;#&quot;&#39;!&#39;&quot;/bin/bash #SBATCH --constraint \\&quot;s04|s05\\&quot; #SBATCH --partition normal #SBATCH --mem 2G #SBATCH -c 1 #SBATCH -t 0:30:0 ./ldak5.1 --he ../he-norm/$i-he-ldak-thin-$k \\ --pheno ../phen/continuous-traits/$i.raw.pheno \\ --grm ../kinship/ldak-thin-$k-norm.covar \\ --kinship-details NO \\ --check-root NO \\ --covar ../phen/covariates.use \\ --max-threads 1 \\ --memory-save YES &quot;&gt; sh_script/$i-he-ldak-thin-$k-norm.sh done done # submit files------------------------------------------------------------------ for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do for k in all left right; do sbatch -A snpher ../sh_script/$i-he-ldak-thin-$k-norm.sh done done &gt; ../job-records/he-ldak-thin 5.5.3 summary #:::::::::::: # under gcta #:::::::::::: # extract h2 estimates --------------------------------------------------------- # right rm summary/he-gcta-norm.right for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do outfile=he-norm/$i-he-gcta-right.he awk -v i=$i &#39;$1==&quot;Her_All&quot; {print i, $2, $3}&#39; $outfile &gt;&gt; summary/he-gcta-norm.right done # left rm summary/he-gcta-norm.left for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do outfile=he-norm/$i-he-gcta-left.he awk -v i=$i &#39;$1==&quot;Her_All&quot; {print i, $2, $3}&#39; $outfile &gt;&gt; summary/he-gcta-norm.left done # all rm summary/he-gcta-norm.all for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do outfile=he-norm/$i-he-gcta-all.he awk -v i=$i &#39;$1==&quot;Her_All&quot; {print i, $2, $3}&#39; $outfile &gt;&gt; summary/he-gcta-norm.all done # inflation test---------------------------------------------------------------- R full=read.table(paste0(&quot;summary/he-gcta-norm.all&quot;), header=F) left=read.table(paste0(&quot;summary/he-gcta-norm.left&quot;), header=F) right=read.table(paste0(&quot;summary/he-gcta-norm.right&quot;), header=F) names(full)=names(left)=names(right)=c(&quot;code&quot;,&quot;h2&quot;,&quot;se&quot;) # some analyses did not complete --&gt; match dataframes dim(full);dim(left);dim(right) common=intersect(full$code, left$code) common=intersect(common, right$code) m1=match(common, right$code) m2=match(common, full$code) m3=match(common, left$code) right=right[m1,] full=full[m2,] left=left[m3,] for(i in 1:dim(full)[1]){ est1=left$h2[i] sd1=left$se[i] est2=right$h2[i] sd2=right$se[i] est=full$h2[i] sd=full$se[i] N=100000 d1=rnorm(N,est1,sd1) d2=rnorm(N,est2,sd2) d=rnorm(N,est,sd) p=1-mean(d1+d2-d&gt;=0) out0=data.frame(code=full$code[i], right_est=est2, right_sd=sd2, left_est=est1, left_sd=sd1, all_est=est, all_sd=sd, p_inflation=p) if(i==1){out=out0}else{out=rbind(out,out0)} } write.table(out, paste0(&quot;summary/he-gcta-inflation-norm.txt&quot;), col.names=T, row.names=F, quote=F) #:::::::::::: # under ldak-thin #:::::::::::: # extract h2 estimates --------------------------------------------------------- # right rm summary/he-ldak-thin-norm.right for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do outfile=he-norm/$i-he-ldak-thin-right.he awk -v i=$i &#39;$1==&quot;Her_All&quot; {print i, $2, $3}&#39; $outfile &gt;&gt; summary/he-ldak-thin-norm.right done # left rm summary/he-ldak-thin-norm.left for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do outfile=he-norm/$i-he-ldak-thin-left.he awk -v i=$i &#39;$1==&quot;Her_All&quot; {print i, $2, $3}&#39; $outfile &gt;&gt; summary/he-ldak-thin-norm.left done # all rm summary/he-ldak-thin-norm.all for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do outfile=he-norm/$i-he-gcta-all.he awk -v i=$i &#39;$1==&quot;Her_All&quot; {print i, $2, $3}&#39; $outfile &gt;&gt; summary/he-ldak-thin-norm.all done # inflation test---------------------------------------------------------------- R full=read.table(paste0(&quot;summary/he-ldak-thin-norm.all&quot;), header=F) left=read.table(paste0(&quot;summary/he-ldak-thin-norm.left&quot;), header=F) right=read.table(paste0(&quot;summary/he-ldak-thin-norm.right&quot;), header=F) names(full)=names(left)=names(right)=c(&quot;code&quot;,&quot;h2&quot;,&quot;se&quot;) # some analyses did not complete --&gt; match dataframes dim(full);dim(left);dim(right) common=intersect(full$code, left$code) common=intersect(common, right$code) m1=match(common, right$code) m2=match(common, full$code) m3=match(common, left$code) right=right[m1,] full=full[m2,] left=left[m3,] for(i in 1:dim(full)[1]){ est1=left$h2[i] sd1=left$se[i] est2=right$h2[i] sd2=right$se[i] est=full$h2[i] sd=full$se[i] N=100000 d1=rnorm(N,est1,sd1) d2=rnorm(N,est2,sd2) d=rnorm(N,est,sd) p=1-mean(d1+d2-d&gt;=0) out0=data.frame(code=full$code[i], right_est=est2, right_sd=sd2, left_est=est1, left_sd=sd1, all_est=est, all_sd=sd, p_inflation=p) if(i==1){out=out0}else{out=rbind(out,out0)} } write.table(out, paste0(&quot;summary/he-ldak-thin-inflation-norm.txt&quot;), col.names=T, row.names=F, quote=F) "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
