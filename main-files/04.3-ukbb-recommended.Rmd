
# UKBB recommended {#ukbb}

## total N = 337k

Here we want to identify the unrelated white individuals recommended by the UKBB.

Email from Florian:
"We restrict individuals to the ones used for computing the principal components (PCs) in the UK Biobank (Field 22020). These individuals are unrelated and have passed some quality control including removing samples with a missing rate on autosomes larger than 0.02, having a mismatch between inferred sex and self-reported sex, and outliers based on heterozygosity (more details can be found in section S3 of Bycroft et al. (2018))."
And the White British are from this: https://biobank.ctsu.ox.ac.uk/crystal/field.cgi?id=22006

So required data fields:
PC: 22020
White british: 22006  

```{bash eval=F}

options(scipen = 100)
# extract data
head=read.table("phen/ukb45861.header", sep=",", header=F, stringsAsFactors = F)
# function to get the variables
get=function(nm){
  colnum=grep(nm,head,fixed=TRUE)
  out=data.frame(t(rbind(colnum, head[,colnum])))
  names(out)=c("column", "field")
  return (out)
}

# get the variables
out=rbind(get('22020-0'), # PC
      get('22006-0')) # white british

write.table(out,"phen/vars.colnum", col.names=F, row.names=F, sep="\t", quote=F)

# extract dat
awk -F '","' '(NR==FNR){a[$1];next}{printf "%s\"", $1;for(i in a){printf " \"%s\"", $i};printf "\n"}' phen/vars.colnum phen/ukb45861.csv > phen/ukbb-recommended.dat

# get the id list of the intersect of the two data fields
dat=read.table("phen/ukbb-recommended.dat", header=T, stringsAsFactors=F)
id1=dat$eid[dat$X22020.0.0==1 & !is.na(dat$X22020.0.0)]
id2=dat$eid[dat$X22006.0.0==1 & !is.na(dat$X22006.0.0)]
out=intersect(id1,id2) # N = 337,462
write.table(out, "ukbb-recommend.id", col.names=F, row.names=F, quote=F)

```

## QC of hp3 SNPs

Here we do QC to 1.2M hapmap3 SNPs for the UKBB recommended individuals.

```{bash eval=F}

# QC SNPs-----------------------------------------------------------------------
# stating number of SNPs= 1,184,423
# note: at this stage, we use all UKBB recommended IDs 
# we will do a random selection of IDs later.
for j in {1..22}; do
echo "#"'!'"/bin/bash
#SBATCH --constraint \"s04|s05\"
#SBATCH --partition normal
#SBATCH --mem 20G
#SBATCH -c 3
#SBATCH -t 1:0:0

./plink2 --pfile ../gen/geno_plink/bhr$j \
         --keep ../ukbb-recommend.id \
         --extract ../doug/ukbb.ldsc \
         --hwe 0.0001 \
         --hard-call-threshold .05 \
         --mach-r2-filter 0.8 2 \
         --make-bed \
         --memory 20000 \
         --out ../gen/tmp/bhr$j-norm \
         --threads 3
"> sh_script/chr$j.sh
done

# submit jobs
for j in {1..22}; do
sbatch -A snpher ../sh_script/chr$j.sh
done > ../job-records/qc-norm

# merge files
rm bfile-norm.list
for j in {1..22}; do
echo  "../gen/tmp/bhr$j-norm" >>bfile-norm.list
done

echo "#"'!'"/bin/bash
#SBATCH --constraint \"s04|s05\"
#SBATCH --partition normal
#SBATCH --mem 20G
#SBATCH -c 3
#SBATCH -t 20:0:0
./ldak5.1 --make-bed ../gen/geno-norm \
          --mbfile ../gen/bfile-norm.list \
          --max-threads 3 \
          --exclude-dups YES  
"> sh_script/mbfile-norm.sh

# submit the script
sbatch -A snpher ../sh_script/mbfile-norm.sh >../job-records/mbfiles-norm

# randomly select 100k individuals 
shuf ukbb-recommend.id | head -n 100000 > ukbb-recommned-rand.100000

# make bfile for these individuals
echo "#"'!'"/bin/bash
#SBATCH --constraint \"s04|s05\"
#SBATCH --partition normal
#SBATCH --mem 20G
#SBATCH -c 3
#SBATCH -t 20:0:0
./ldak5.1 --make-bed ../gen/geno-norm-100k \
          --bfile ../gen/geno-norm \
          --keep ../ukbb-recommned-rand.100000 \
          --max-threads 3 \
          --exclude-dups YES  
"> sh_script/mbfile-norm-100k.sh

# submit the script
sbatch -A snpher ../sh_script/mbfile-norm-100k.sh >../job-records/mbfiles-norm-100k


# MAF & call-rate 
awk < geno-norm-100k.stats '($5>.01 && $6>=0.95 && NR>1){print $1}' > snps-norm-100k.use
# m = 1,100,799 SNPs
 
```

## GWAS-100k

```{bash eval=F}

# linear regression-------------------------------------------------------------
mkdir gwas-norm
for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do
echo "#"'!'"/bin/bash
#SBATCH --constraint \"s04|s05\"
#SBATCH --partition normal
#SBATCH --mem 10G
#SBATCH -c 2
#SBATCH -t 10:0:0

./ldak5.1 --linear ../gwas-norm/$i-linear \
          --pheno ../phen/continuous-traits/$i.raw.pheno \
          --bfile ../gen/geno-norm-100k \
          --keep ../ukbb-recommned-rand.100000 \
          --extract ../gen/snps-norm-100k.use \
          --covar ../phen/covariates.use \
          --max-threads 2 \
"> sh_script/$i-linear.sh
done

# submit files------------------------------------------------------------------
for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do
sbatch -A snpher ../sh_script/$i-linear.sh
done>../job-records/gwas-norm

# check job completion----------------------------------------------------------
file=job-records/gwas-norm
jobs=`awk '{print $4}' $file`
mkdir $file-tmp
for i in $jobs; do
jobinfo $i | awk -F ":" -v i=$i '$1~/Name/ {print i, $2}' >> $file-tmp/name.tmp 
jobinfo $i | awk -F ":" '$1~/State/ {print$2}' >> $file-tmp/state.tmp
jobinfo $i | awk -F ":" '$1~/Cores/ {print$2}' >> $file-tmp/cores.tmp
jobinfo $i | awk -F ":" '$1~/Used walltime/ {print $2 ":" $3 ":" $4}' >> $file-tmp/time.tmp
jobinfo $i | awk -F ":" '$1~/Max Mem/ {split($2,a,/[(]/ ); print a[1]}' >> $file-tmp/mem.tmp
done
paste $file-tmp/name.tmp \
      $file-tmp/state.tmp \
      $file-tmp/cores.tmp \
      $file-tmp/time.tmp \
      $file-tmp/mem.tmp \
      | awk 'BEGIN{print "ID name state cores time mem"}{print $0}' > $file.out
rm -r $file-tmp

```

## GWAS-337k

Here we do gwas for all recommended individuals. Previously we made a bfile for all these individuals.

  * **bfile** (after QC) gen/geno-norm
  * **id list** ukbb-recommend.id

```{bash eval=F}

# snp list----------------------------------------------------------------------
# MAF & call rate filtering
awk < gen/geno-norm.stats '($5>.01 && $6>=0.95 && NR>1){print $1}' > gen/snps-norm.use #1,100,715 snps

# GWAS -------------------------------------------------------------------------
mkdir gwas-norm-337k
for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do
echo "#"'!'"/bin/bash
#SBATCH --constraint \"s04|s05\"
#SBATCH --partition normal
#SBATCH --mem 20G
#SBATCH -c 3
#SBATCH -t 10:0:0

./ldak5.1 --linear ../gwas-norm-337k/$i-linear \
          --pheno ../phen/continuous-traits/$i.raw.pheno \
          --bfile ../gen/geno-norm \
          --keep ../ukbb-recommend.id \
          --extract ../gen/snps-norm.use \
          --covar ../phen/covariates.use \
          --max-threads 3 \
"> sh_script/$i-linear.sh
done

# submit files------------------------------------------------------------------
for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do
sbatch -A snpher ../sh_script/$i-linear.sh
done>../job-records/gwas-norm-337k

# check job completion----------------------------------------------------------
file=job-records/gwas-norm-337k
jobs=`awk '{print $4}' $file`
mkdir $file-tmp
for i in $jobs; do
jobinfo $i | awk -F ":" -v i=$i '$1~/Name/ {print i, $2}' >> $file-tmp/name.tmp 
jobinfo $i | awk -F ":" '$1~/State/ {print$2}' >> $file-tmp/state.tmp
jobinfo $i | awk -F ":" '$1~/Cores/ {print$2}' >> $file-tmp/cores.tmp
jobinfo $i | awk -F ":" '$1~/Used walltime/ {print $2 ":" $3 ":" $4}' >> $file-tmp/time.tmp
jobinfo $i | awk -F ":" '$1~/Max Mem/ {split($2,a,/[(]/ ); print a[1]}' >> $file-tmp/mem.tmp
done
paste $file-tmp/name.tmp \
      $file-tmp/state.tmp \
      $file-tmp/cores.tmp \
      $file-tmp/time.tmp \
      $file-tmp/mem.tmp \
      | awk 'BEGIN{print "ID name state cores time mem"}{print $0}' > $file.out
rm -r $file-tmp

```

## ldsc-100k

### under gcta

```{bash eval=F}

#:::::::::::::
# using original ldsc
#:::::::::::::

# format stats for ldsc--------------------------------------------------------- 
library(vroom)
options(scipen = 100)
rs=vroom("doug/ukbb.ldsc", col_names=F)
phen=c("awake","bmi","chron","ever","fvc",
       "height","imp","neur","pulse","quals",
       "reaction","sbp","snoring","hyper", "quals")

for(i in phen){
  stat=vroom(paste0("gwas-norm/",i,"-linear.summaries"), col_names=T)
  p=vroom(paste0("gwas-norm/",i,"-linear.pvalues"), col_names=T)
  m1=match(rs$X1, stat$Predictor)
  m2=match(rs$X1, p$Predictor)
  out=data.frame(SNP=rs$X2,
                 N=stat$n[m1],
                 Z=(sqrt(stat$Stat)*stat$Direction)[m1],
                 A1=stat$A1[m1],
                 A2=stat$A2[m1], 
                 pval=p$P[m2], stringsAsFactors=F)
  out=out[complete.cases(out),]
  write.table(out, paste0("gwas-norm/",i,"-linear-rs.summaries"), 
  col.names=T, row.names=F, quote=F)
}

# perform ldsc------------------------------------------------------------------
mkdir out-norm-100k
for i in {awake,bmi,chron,ever,fvc,height,quals,imp,neur,pulse,reaction,sbp,snoring,hyper}; do
echo "#"'!'"/bin/bash
#SBATCH --constraint \"s04|s05\"
#SBATCH --partition normal
#SBATCH --mem 2G
#SBATCH -c 3
#SBATCH -t 24:00:0

.././munge_sumstats.py \
--sumstats ../../gwas-norm/$i-linear-rs.summaries \
--out ../out-norm-100k/$i \
--merge-alleles ../w_hm3.snplist

.././ldsc.py \
--h2 ../out-norm-100k/$i.sumstats.gz \
--ref-ld-chr ../eur_w_ld_chr/ \
--w-ld-chr ../eur_w_ld_chr/ \
--out ../out-norm-100k/$i-ldsc
">sh_script/ldsc-$i-norm-100k.sh
done

# submit jobs-------------------------------------------------------------------
for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,reaction,sbp,snoring,hyper,quals}; do
sbatch -A snpher ../sh_script/ldsc-$i-norm-100k.sh
done>../../job-records/ldsc-norm-100k

#:::::::::::::
# using sumher
#:::::::::::::

# insert genetic distance into bim file-----------------------------------------
head geno-norm-100k.fam > small-norm

for j in {1..22}; do
echo "#"'!'"/bin/bash
#SBATCH --mem 8G
#SBATCH -c 1
#SBATCH -t 3:00:0
#SBATCH --constraint \"s04|s05\"
./plink1.9 --bfile ../gen/geno-norm-100k \
          --chr $j \
          --cm-map /home/zhoux/snpher/faststorage/genetic_maps/genetic_map_chr@_combined_b37.txt \
          --make-bed \
          --out new$j \
          --keep ../gen/small-norm
" > sh_script/map$j
done

for j in {1..22}; do
sbatch -A snpher ../sh_script/map$j
done > genetic-distance-hapmap3

cd /home/zhoux/dsmwpred/xuan/quality-control/qc-10oct/gen
cat new{1..22}.bim | awk '{print $2, $3}' > maps-hapmap3-norm-100k.txt
rm new{1..22}.{bim,bed,fam,log}

awk '(NR==FNR){arr[$1]=$2;next}{print $1, $2, arr[$2], $4, $5, $6}' > geno-norm-100k.bim2 maps-hapmap3-norm-100k.txt geno-norm-100k.bim
mv geno-norm-100k.bim geno-norm-100k.bim0
mv geno-norm-100k.bim2 geno-norm-100k.bim

# compute tagging under gcta----------------------------------------------------
mkdir tagging-norm-100k
for j in {1..22}; do
echo "#"'!'"/bin/bash
#SBATCH --constraint \"s04|s05\"
#SBATCH --partition normal
#SBATCH --mem 5G
#SBATCH -c 1
#SBATCH -t 5:0:0

./ldak5.1 --calc-tagging ../tagging-norm-100k/gcta-hapmap3-chr-$j \
          --bfile ../gen/geno-norm-100k \
          --ignore-weights YES \
          --power -1 \
          --window-cm 1 \
          --chr $j
"> sh_script/tagging-gcta-hapmap3-chr$j
done

for j in {1..22}; do
sbatch -A snpher ../sh_script/tagging-gcta-hapmap3-chr$j 
done > ../job-records/tagging-gcta-hapmap3-norm-100k

# check job completion----------------------------------------------------------
file=job-records/tagging-gcta-hapmap3-norm-100k
jobs=`awk '{print $4}' $file`
mkdir $file-tmp
for i in $jobs; do
jobinfo $i | awk -F ":" -v i=$i '$1~/Name/ {print i, $2}' >> $file-tmp/name.tmp 
jobinfo $i | awk -F ":" '$1~/State/ {print$2}' >> $file-tmp/state.tmp
jobinfo $i | awk -F ":" '$1~/Cores/ {print$2}' >> $file-tmp/cores.tmp
jobinfo $i | awk -F ":" '$1~/Used walltime/ {print $2 ":" $3 ":" $4}' >> $file-tmp/time.tmp
jobinfo $i | awk -F ":" '$1~/Max Mem/ {split($2,a,/[(]/ ); print a[1]}' >> $file-tmp/mem.tmp
done
paste $file-tmp/name.tmp \
      $file-tmp/state.tmp \
      $file-tmp/cores.tmp \
      $file-tmp/time.tmp \
      $file-tmp/mem.tmp \
      | awk 'BEGIN{print "ID name state cores time mem"}{print $0}' > $file.out
rm -r $file-tmp

# merge tagging files-----------------------------------------------------------
rm list.txt
for j in {1..22}; do 
echo "tagging-norm-100k/gcta-hapmap3-chr-$j.tagging" >> list.txt
done
./ldak5.1 --join-tagging tagging-norm-100k/gcta-hapmap3 --taglist list.txt

# ldsc intercept----------------------------------------------------------------
mkdir sumher-norm-100k
dirin1=tagging-norm-100k
dirin2=gwas-norm
dirout=sumher-norm-100k
for i in {awake,bmi,chron,ever,fvc,height,quals,imp,neur,pulse,reaction,sbp,snoring,hyper}; do
echo "#"'!'"/bin/bash
#SBATCH --constraint \"s04|s05\"
#SBATCH --partition normal
#SBATCH --mem 5G
#SBATCH -c 1
#SBATCH -t 5:0:0

./ldak5.1 --sum-hers ../$dirout/$i-sumher-gcta \
          --tagfile ../$dirin1/gcta-hapmap3.tagging \
          --summary ../$dirin2/$i-linear.summaries \
          --check-sums NO \
          --intercept YES
"> sh_script/$i-sumher-gcta
done

for i in {awake,bmi,chron,ever,fvc,height,quals,imp,neur,pulse,reaction,sbp,snoring,hyper}; do
sbatch -A snpher ../sh_script/$i-sumher-gcta
done>../job-records/sumher-gcta-norm-100k

```

### under ldak-thin

```{bash eval=F}

# get weights-------------------------------------------------------------------
awk < ldak-thin/ldak-thin-norm.in '{print $1, 1}' > ldak-thin/weights.ldak-thin-norm

# calculate tagging under ldak-thin---------------------------------------------
dirout=tagging-norm-100k
filein1=geno-norm-100k
filein2=weights.ldak-thin-norm
for j in {1..22}; do
echo "#"'!'"/bin/bash
#SBATCH --partition normal
#SBATCH --mem 40G
#SBATCH -c 5
#SBATCH -t 10:0:0
#SBATCH --constraint \"s04|s05\"
./ldak5.1 --calc-tagging ../$dirout/ldak-thin-hapmap3-chr-$j \
          --bfile ../gen/$filein1 \
          --weights ../ldak-thin/$filein2 \
          --power -.25 \
          --window-cm 1 \
          --chr $j \
          --save-matrix YES \
          --max-threads 5
" > sh_script/tagging-ldak-thin-hapmap3-chr$j.sh
done

# submit scripts
for j in {1..22}; do
sbatch -A snpher ../sh_script/tagging-ldak-thin-hapmap3-chr$j.sh
done > ../job-records/tagging-ldak-thin-norm-100k

# check job completion----------------------------------------------------------
file=job-records/tagging-ldak-thin-norm-100k
jobs=`awk '{print $4}' $file`
mkdir $file-tmp
for i in $jobs; do
jobinfo $i | awk -F ":" -v i=$i '$1~/Name/ {print i, $2}' >> $file-tmp/name.tmp 
jobinfo $i | awk -F ":" '$1~/State/ {print$2}' >> $file-tmp/state.tmp
jobinfo $i | awk -F ":" '$1~/Cores/ {print$2}' >> $file-tmp/cores.tmp
jobinfo $i | awk -F ":" '$1~/Used walltime/ {print $2 ":" $3 ":" $4}' >> $file-tmp/time.tmp
jobinfo $i | awk -F ":" '$1~/Max Mem/ {split($2,a,/[(]/ ); print a[1]}' >> $file-tmp/mem.tmp
done
paste $file-tmp/name.tmp \
      $file-tmp/state.tmp \
      $file-tmp/cores.tmp \
      $file-tmp/time.tmp \
      $file-tmp/mem.tmp \
      | awk 'BEGIN{print "ID name state cores time mem"}{print $0}' > $file.out
rm -r $file-tmp

# merge tagging files-----------------------------------------------------------
rm list.txt
rm matlist.txt
for j in {1..22}; do
echo "tagging-norm-100k/ldak-thin-hapmap3-chr-$j.tagging" >> list.txt
echo "tagging-norm-100k/ldak-thin-hapmap3-chr-$j.matrix" >> matlist.txt
done
dirout=tagging-norm-100k
./ldak5.1 --join-tagging $dirout/ldak-thin-hapmap3 --taglist list.txt --matlist matlist.txt

# ldsc intercept----------------------------------------------------------------
dirin1=tagging-norm-100k
dirin2=gwas-norm
dirout=sumher-norm-100k
for i in {awake,bmi,chron,ever,fvc,height,quals,imp,neur,pulse,reaction,sbp,snoring,hyper}; do
echo "#"'!'"/bin/bash
#SBATCH --constraint \"s04|s05\"
#SBATCH --partition normal
#SBATCH --mem 5G
#SBATCH -c 1
#SBATCH -t 00:30:0

./ldak5.1 --sum-hers ../$dirout/$i-sumher-ldak-thin \
          --tagfile ../$dirin1/ldak-thin-hapmap3.tagging \
          --summary ../$dirin2/$i-linear.summaries \
          --check-sums NO \
          --intercept YES
"> sh_script/$i-sumher-ldak-thin
done

for i in {awake,bmi,chron,ever,fvc,height,quals,imp,neur,pulse,reaction,sbp,snoring,hyper}; do
sbatch -A snpher ../sh_script/$i-sumher-ldak-thin
done>../job-records/sumher-ldak-thin-norm-100k

```

### summary

```{bash eval=F}

# original ldsc
grep Intercept *ldsc.log | awk '{split($1, a, /[-]/); split($3, b, /[()]/); print a[1], $2, b[2]}' > ../../summary/ldsc-norm-100k

# sumher under gcta
grep Intercept_Estimate *gcta.extra | awk '{ split($1, a, /[-]/); print a[1], $2}' >../summary/sumher-gcta-norm-100k-est
grep Intercept_SD *gcta.extra | awk '{ split($1, a, /[-]/); print a[1], $2}' >../summary/sumher-gcta-norm-100k-sd
cd ../summary/
paste sumher-gcta-norm-100k-est sumher-gcta-norm-100k-sd | awk '{print $1, $2, $4}' > sumher-gcta-norm-100k
      
# suhmer under ldak-thin
grep Intercept_Estimate *ldak-thin.extra | awk '{ split($1, a, /[-]/); print a[1], $2}' >../summary/sumher-ldak-thin-norm-100k-est
grep Intercept_SD *ldak-thin.extra | awk '{ split($1, a, /[-]/); print a[1], $2}' >../summary/sumher-ldak-thin-norm-100k-sd
cd ../summary/
paste sumher-ldak-thin-norm-100k-est sumher-ldak-thin-norm-100k-sd | awk '{print $1, $2, $4}' > sumher-ldak-thin-norm-100k

```

## ldsc-337k

```{bash eval=F}
 #:::::::::::::
# using original ldsc
#:::::::::::::

# format stats for ldsc--------------------------------------------------------- 
library(vroom)
options(scipen = 100)
rs=vroom("doug/ukbb.ldsc", col_names=F)
phen=c("awake","bmi","chron","ever","fvc",
       "height","imp","neur","pulse","quals",
       "reaction","sbp","snoring","hyper", "quals")

for(i in phen){
  stat=vroom(paste0("gwas-norm-337k/",i,"-linear.summaries"), col_names=T)
  p=vroom(paste0("gwas-norm-337k/",i,"-linear.pvalues"), col_names=T)
  m1=match(rs$X1, stat$Predictor)
  m2=match(rs$X1, p$Predictor)
  out=data.frame(SNP=rs$X2,
                 N=stat$n[m1],
                 Z=(sqrt(stat$Stat)*stat$Direction)[m1],
                 A1=stat$A1[m1],
                 A2=stat$A2[m1], 
                 pval=p$P[m2], stringsAsFactors=F)
  out=out[complete.cases(out),]
  write.table(out, paste0("gwas-norm-337k/",i,"-linear-rs.summaries"), 
  col.names=T, row.names=F, quote=F)
}

# perform ldsc------------------------------------------------------------------
mkdir out-norm-337k

for i in {awake,bmi,chron,ever,fvc,height,quals,imp,neur,pulse,reaction,sbp,snoring,hyper}; do
echo "#"'!'"/bin/bash
#SBATCH --constraint \"s04|s05\"
#SBATCH --partition normal
#SBATCH --mem 8G
#SBATCH -c 3
#SBATCH -t 24:00:0

.././munge_sumstats.py \
--sumstats ../../gwas-norm-337k/$i-linear-rs.summaries \
--out ../out-norm-337k/$i \
--merge-alleles ../w_hm3.snplist

.././ldsc.py \
--h2 ../out-norm-337k/$i.sumstats.gz \
--ref-ld-chr ../eur_w_ld_chr/ \
--w-ld-chr ../eur_w_ld_chr/ \
--out ../out-norm-337k/$i-ldsc
">sh_script/ldsc-$i-norm-337k.sh
done

# submit jobs-------------------------------------------------------------------
for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,reaction,sbp,snoring,hyper,quals}; do
sbatch -A snpher ../sh_script/ldsc-$i-norm-337k.sh
done>../../job-records/ldsc-norm-337k

# summary ----------------------------------------------------------------------

grep Intercept *ldsc.log | awk '{split($1, a, /[-]/); split($3, b, /[()]/); print a[1], $2, b[2]}' > ../../summary/ldsc-norm-337k.intercept

grep Ratio *ldsc.log | awk '{split($1, a, /[-]/); split($3, b, /[()]/); print a[1], $2, b[2]}' > ../../summary/ldsc-norm-337k.ratio

R
# intercept
ldsc=read.table("summary/ldsc-norm-337k.intercept", header=F, stringsAsFactors = F)
# get p-values for Wald tests
# H0: intercept = 1
alpha=0.05/14 # Bonferroni corrected alpha
ldsc=data.frame(trait=ldsc$V1, est=ldsc$V2, se=ldsc$V3,
                wald_p=pchisq(((ldsc$V2-1)/ldsc$V3)^2, df=1, lower.tail=F),
                sig=pchisq(((ldsc$V2-1)/ldsc$V3)^2, df=1, lower.tail=F) < alpha,
                stringsAsFactors = F)
write.table(ldsc,"summary/ldsc-norm-337k.summary", col.names=T, row.names=F, quote=F)

# ratio
ldsc=read.table("summary/ldsc-norm-337k.ratio", header=F, stringsAsFactors = F)
# get p-values for Wald tests
# H0: ratio=0
alpha=0.05/14 # Bonferroni corrected alpha
ldsc=data.frame(trait=ldsc$V1, est=ldsc$V2, se=ldsc$V3,
                wald_p=pchisq(((ldsc$V2)/ldsc$V3)^2, df=1, lower.tail=F),
                sig=pchisq(((ldsc$V2)/ldsc$V3)^2, df=1, lower.tail=F) < alpha,
                stringsAsFactors = F)
write.table(ldsc,"summary/ldsc-norm-337k.ratio", col.names=T, row.names=F, quote=F)

```


## ldsc-337k: skipping 1st step

```{bash eval=F}

```

## aver2_j-337k

### calc

```{bash eval=F}

#:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
#  snp lists
#:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

# new directory
mkdir inflation/norm
mkdir inflation/norm/out

# lista & listb
m=10000
infile=gen/snps-norm.use
left=inflation/norm/left-snps
right=inflation/norm/right-snps

awk '{split($1, a, ":");
    if (a[1]<8) print $1 }' $infile | shuf | head -n $m >$left  
awk '{split($1, a, ":");
    if (a[1]>=8) print $1 }' $infile | shuf | head -n $m >$right

#:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
#  compute ave r^2_j
#:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

lista=../inflation/norm/right-snps
listb=../inflation/norm/left-snps
bfile=../gen/geno-norm
out=../inflation/norm/out/10k-snps

echo "#"'!'"/bin/bash
#SBATCH --constraint \"s04|s05\"
#SBATCH --partition normal
#SBATCH --mem 60G
#SBATCH -c 7
#SBATCH -t 00:10:0
./ldak5.2 --max-threads 7 \
          --calc-inflation $out \
          --bfile $bfile \
          --lista $lista \
          --listb $listb
">sh_script/calc-r-10k-snps

# submit the job
sbatch -A snpher ../sh_script/calc-r-10k-snps >../job-records/calc-r-norm

#  compute ave r_j^2 for each i-------------------------------------------------
R
require(vroom)

nm="10k-snps"
dat=vroom(paste0("inflation/norm/out/",nm,".pairwise"), col_names=F)
lista=read.table(paste0("inflation/norm/out/",nm,".predictorsa"), 
                stringsAsFactors = F)
listb=read.table(paste0("inflation/norm/out/",nm,".predictorsb"), 
                stringsAsFactors = F)

dat=dat[,-c(10001)]^2
outb=data.frame(predictor=listb$V1, ave_r2=apply(dat,2, mean))
outa=data.frame(predictor=lista$V1, ave_r2=apply(dat,1, mean))
out=rbind(outa,outb)

write.table(out,paste0("summary/ave-r2-",nm, "-ukbb-norm"), col.names=F, row.names=F, quote=F)  

```

### organize data

See section \@ref(ukbb_337k_inflation) for an update. In the update, ldscores are now included in the each .out file.

```{bash eval=F}

mkdir gwas-norm-337k-out

for trait in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do

gwas=gwas-norm-337k/$trait-linear.summaries
aver2=summary/ave-r2-10k-snps-ukbb-norm
out=gwas-norm-337k-out/$trait.out

awk 'NR>1 {print $1, $5}' $gwas > tmp/gwas.tmp    

awk 'NR==FNR {a[$1]; b[$1]=$2; next} 
     {if ($1 in a) print b[$1]; 
     else print "NA" }' $aver2 tmp/gwas.tmp > tmp/aver2.tmp

# put info together
paste tmp/gwas.tmp \
      tmp/aver2.tmp \
      | awk 'BEGIN{OFS=";" ; 
                  print "snp;chisq;aver2"}
             {$1=$1}1' > $out
done

```

### chisq ~ aver2_j

```{R eval=F}

#::::::::::::::::::::::::::::::::::::::::::::::
# estimate slope: chisq ~ aver2_j
#::::::::::::::::::::::::::::::::::::::::::::::

require(vroom)
traits=c("awake","bmi","chron","ever",
        "neur","pulse","quals", "fvc", "height","imp", 
        "reaction","sbp","snoring","hyper")

for(i in 1:length(traits)){

trait=traits[i]

file=paste0("gwas-norm-337k-out/",trait,".out")

dat=vroom(file, col_names=T, delim=";")
dat=dat[complete.cases(dat),]
mod=lm(chisq ~ aver2,data=dat)

slope0=data.frame(trait=trait,
                  slope_aver2=coef(mod)[2],
                  p_aver2=summary(mod)$coefficients[,4][2],
                  stringsAsFactors = F)

if(i==1){slope=slope0} else {slope=rbind(slope,slope0)}

}

#::::::::::::::::::::::::::::::::::::::::::::::
# plot chisq ~ aver2_j  
#::::::::::::::::::::::::::::::::::::::::::::::
# make a plot ------------------------------------------------------------------
require(vroom)
traits=c("awake","bmi","chron","ever",
        "neur","pulse","quals", "fvc", "height","imp", 
        "reaction","sbp","snoring","hyper")
        
png(paste0("fig/chisq-by-aver2-bin-ukbb-recommend-337k.png"),
      width = 50, height = 30, units = "cm", res=600)
  par(mfrow=c(3,5))

for (i in 1:length(traits)){
    trait=traits[i]
    file=paste0("gwas-norm-337k-out/",trait,".out")
    dat=vroom(file, col_names=T, delim=";")
    # bin a variable by quantile
    cutoff=quantile(dat$aver2, probs = seq(0, 1, 0.005), na.rm=T)
    dat$bin=cut(dat$aver2, breaks=cutoff, labels=1:(length(cutoff)-1))
    # average chisq by bin values
    out=data.frame(chisq_ave=tapply(dat$chisq,INDEX=dat$bin, mean))
    out$bin_val=tapply(dat$aver2,INDEX=dat$bin, mean)

plot(out$bin_val, out$chisq_ave,
         xlab="ave r2", ylab="ave chisq",
         main=trait, las=1,
         cex = 1.5, pch=21,  bg="orange", col="white", lwd=0.5)
 }
dev.off()

# new -----------------------------------------------------------
require(vroom)
traits=c("awake","bmi","chron","ever",
        "neur","pulse","quals", "fvc", "height","imp", 
        "reaction","sbp","snoring","hyper")

png("fig/chisq-aver2-bin-ukbb-recommend-337k.png", res=600, width=50, height=30, units="cm")
par(mfrow=c(3,5), cex.lab=1.2, font.lab=2, cex.main=1.5)

for(i in 1:length(traits)){
  trait=traits[i]
  dat=vroom(paste0("gwas-norm-337k-out/",trait,".out"), col_names=T)
  dat=dat[complete.cases(dat),]

  # linear model
  mod=lm(chisq ~ aver2 + ldsc,data=dat)
  p=summary(mod)$coefficients[,4][2]
  p_sci=formatC(p, format="e", digit=2)

  # bin a variable by quantile
  cutoff=quantile(dat$aver2, probs = seq(0, 1, 0.005), na.rm=T)
  dat$bin=cut(dat$aver2, breaks=cutoff, labels=1:(length(cutoff)-1))
  
  # average chisq by bin values
  out=data.frame(chisq_ave=tapply(dat$chisq,INDEX=dat$bin, mean))
  out$bin_val=tapply(dat$aver2,INDEX=dat$bin, mean)
  px=min(out$bin_val)
  py=max(out$chisq_ave)

  # plot
  plot(out$bin_val, out$chisq_ave,
           xlab="ave r2 bin", ylab="mean chisq",
           main=trait, las=1,
           cex = 1.5, pch=21,  bg="darkgray", col="white", lwd=0.5)
  abline(lm(chisq ~ aver2, data=dat),col="orange", lwd=2)
  if(p<0.01){text(px, py, paste0("p = ", p_sci),
                  adj=c(0,1), col="red", cex=2, font=2)
    } else {text(px, py, paste0("p = ", p_sci), 
          adj=c(0,1), cex=2, font=2)}
  
}
dev.off()

```

## HE

### making grms

```{bash eval=F}

# making grm -------------------------------------------------------------------

#:::
# under gcta
#:::

# all snps
echo "#"'!'"/bin/bash
#SBATCH --partition normal
#SBATCH --mem 60G
#SBATCH -c 10
#SBATCH -t 08:0:0
#SBATCH --constraint \"s04|s05\"

./ldak5.1 --max-threads 10 \
          --calc-kins-direct ../kinship/gcta-all-norm \
          --bfile ../gen/geno-norm-100k \
          --extract ../gen/snps-norm-100k.use \
          --power -1 \
          --ignore-weights YES \
          --single YES
" > sh_script/grm-all-snps-norm

sbatch -A snpher ../sh_script/grm-all-snps-norm > ../job-records/grm-all-snps-norm

# grm by snp blocks: right vs. left
awk '$1<8 {print $2}' geno-norm-100k.bim > left-snps-norm-100k.use 
awk '$1>=8 {print $2}' geno-norm-100k.bim > right-snps-norm-100k.use

for i in left right; do
echo "#"'!'"/bin/bash
#SBATCH --partition normal
#SBATCH --mem 60G
#SBATCH -c 10
#SBATCH -t 20:0:0
#SBATCH --constraint \"s04|s05\"

./ldak5.1 --max-threads 10 \
          --calc-kins-direct ../kinship/gcta-$i-norm \
          --bfile ../gen/geno-norm-100k \
          --extract ../gen/$i-snps-norm-100k.use \
          --power -1 \
          --ignore-weights YES \
          --single YES
" > sh_script/grm-gcta-$i-norm
done

for i in left right; do
sbatch -A snpher ../sh_script/grm-gcta-$i-norm 
done > ../job-records/grm-gcta-by-snps-norm 

#:::
# under ldak-thin
#:::

#-----------
# 1. thin snps
#-----------

for j in {1..22}; do
echo "#"'!'"/bin/bash
#SBATCH --partition normal
#SBATCH --mem 10G
#SBATCH -c 4
#SBATCH -t 4:0:0
#SBATCH --constraint \"s04|s05\"
./ldak5.1 --max-threads 4 \
          --window-prune 0.98 \
          --window-kb 100 \
          --extract ../gen/snps-norm-100k.use \
          --bfile ../gen/geno-norm-100k \
          --thin ../ldak-thin/chr$j-norm \
          --chr $j
" > sh_script/ldak-thin$j-norm
done

# submit script
for j in {1..22}; do
sbatch -A snpher ../sh_script/ldak-thin$j-norm
done > ../job-records/ldak-thin-norm

# check job completion---
file=job-records/ldak-thin-norm
jobs=`awk '{print $4}' $file`
mkdir $file-tmp
for i in $jobs; do
jobinfo $i | awk -F ":" -v i=$i '$1~/Name/ {print i, $2}' >> $file-tmp/name.tmp 
jobinfo $i | awk -F ":" '$1~/State/ {print$2}' >> $file-tmp/state.tmp
jobinfo $i | awk -F ":" '$1~/Cores/ {print$2}' >> $file-tmp/cores.tmp
jobinfo $i | awk -F ":" '$1~/Used walltime/ {print $2 ":" $3 ":" $4}' >> $file-tmp/time.tmp
jobinfo $i | awk -F ":" '$1~/Max Mem/ {split($2,a,/[(]/ ); print a[1]}' >> $file-tmp/mem.tmp
done
paste $file-tmp/name.tmp \
      $file-tmp/state.tmp \
      $file-tmp/cores.tmp \
      $file-tmp/time.tmp \
      $file-tmp/mem.tmp \
      | awk 'BEGIN{print "ID name state cores time mem"}{print $0}' > $file.out
rm -r $file-tmp

# combine snp list
cat ldak-thin/chr{1..22}-norm.in > ldak-thin/ldak-thin-norm.in

#----------------------
# 2. kinship matrix under ldak-thin
#------------------------

echo "#"'!'"/bin/bash
#SBATCH --partition normal
#SBATCH --mem 60G
#SBATCH -c 10
#SBATCH -t 08:0:0
#SBATCH --constraint \"s04|s05\"

./ldak5.1 --max-threads 10 \
          --calc-kins-direct ../kinship/ldak-thin-all-norm \
          --bfile ../gen/geno-norm-100k \
          --extract ../ldak-thin/ldak-thin-norm.in \
          --power -0.25 \
          --ignore-weights YES \
          --single YES
" > sh_script/ldak-thin-grm-all-snps-norm

sbatch -A snpher ../sh_script/ldak-thin-grm-all-snps-norm > ../job-records/ldak-thin-grm-all-snps-norm

# grm by snp blocks: right vs. left

awk '{split($1, a, /[:]/); if (a[1]<8) print $1}' \
 ldak-thin/ldak-thin-norm.in > gen/left-ldak-thin-norm.snps 
awk '{split($1, a, /[:]/); if (a[1]>=8) print $1}' \
 ldak-thin/ldak-thin-norm.in > gen/right-ldak-thin-norm.snps 

for i in left right; do
echo "#"'!'"/bin/bash
#SBATCH --partition normal
#SBATCH --mem 60G
#SBATCH -c 10
#SBATCH -t 08:0:0
#SBATCH --constraint \"s04|s05\"

./ldak5.1 --max-threads 10 \
          --calc-kins-direct ../kinship/ldak-thin-$i-norm \
          --bfile ../gen/geno-norm-100k \
          --extract ../gen/$i-ldak-thin-norm.snps \
          --power -0.25 \
          --ignore-weights YES \
          --single YES
" > sh_script/ldak-thin-grm-$i-norm
done

for i in left right; do
sbatch -A snpher ../sh_script/ldak-thin-grm-$i-norm 
done > ../job-records/grm-ldak-thin-by-snps-norm 

```

### estimation

NEED To check what covariates to adjust for HE
basic.covariates.use or covariates.use?

```{bash eval=F}
# regress grm on covariates-----------------------------------------------------

for grm in gcta-all-norm gcta-left-norm gcta-right-norm ldak-thin-all-norm ldak-thin-left-norm ldak-thin-right-norm; do  
echo "#"'!'"/bin/bash
#SBATCH --constraint \"s04|s05\"
#SBATCH --partition normal
#SBATCH --mem 50G
#SBATCH -c 5
#SBATCH -t 10:0:0
./ldak5.1 --adjust-grm ../kinship/$grm.covar \
          --grm ../kinship/$grm \
          --covar ../phen/covariates.use \
          --max-threads 5
"> sh_script/$grm-adjust.sh
done

# submit jobs
for grm in gcta-all-norm gcta-left-norm gcta-right-norm ldak-thin-all-norm ldak-thin-left-norm ldak-thin-right-norm; do
sbatch -A snpher ../sh_script/$grm-adjust.sh
done > ../job-records/grm-adjust-for-HE

# check job completion----------------------------------------------------------
file=job-records/grm-adjust-for-HE
jobs=`awk '{print $4}' $file`
mkdir $file-tmp
for i in $jobs; do
jobinfo $i | awk -F ":" -v i=$i '$1~/Name/ {print i, $2}' >> $file-tmp/name.tmp 
jobinfo $i | awk -F ":" '$1~/State/ {print$2}' >> $file-tmp/state.tmp
jobinfo $i | awk -F ":" '$1~/Cores/ {print$2}' >> $file-tmp/cores.tmp
jobinfo $i | awk -F ":" '$1~/Used walltime/ {print $2 ":" $3 ":" $4}' >> $file-tmp/time.tmp
jobinfo $i | awk -F ":" '$1~/Max Mem/ {split($2,a,/[(]/ ); print a[1]}' >> $file-tmp/mem.tmp
done
paste $file-tmp/name.tmp \
      $file-tmp/state.tmp \
      $file-tmp/cores.tmp \
      $file-tmp/time.tmp \
      $file-tmp/mem.tmp \
      | awk 'BEGIN{print "ID name state cores time mem"}{print $0}' > $file.out
rm -r $file-tmp

# HE under gcta-----------------------------------------------------------------
for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do
for k in all left right; do
echo "#"'!'"/bin/bash
#SBATCH --constraint \"s04|s05\"
#SBATCH --partition normal
#SBATCH --mem 2G
#SBATCH -c 1
#SBATCH -t 00:30:0

./ldak5.1 --he ../he-norm/$i-he-gcta-$k \
          --pheno ../phen/continuous-traits/$i.raw.pheno \
          --grm ../kinship/gcta-$k-norm.covar \
          --kinship-details NO \
          --check-root NO \
          --covar ../phen/covariates.use \
          --max-threads 1 \
          --memory-save YES
"> sh_script/$i-he-gcta-$k-snps-norm.sh
done
done

# submit files------------------------------------------------------------------
for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do
for k in all left right; do
sbatch -A snpher ../sh_script/$i-he-gcta-$k-snps-norm.sh
done
done > ../job-records/he-gcta

# HE under ldak-thin------------------------------------------------------------
for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do
for k in all left right; do
echo "#"'!'"/bin/bash
#SBATCH --constraint \"s04|s05\"
#SBATCH --partition normal
#SBATCH --mem 2G
#SBATCH -c 1
#SBATCH -t 0:30:0

./ldak5.1 --he ../he-norm/$i-he-ldak-thin-$k \
          --pheno ../phen/continuous-traits/$i.raw.pheno \
          --grm ../kinship/ldak-thin-$k-norm.covar \
          --kinship-details NO \
          --check-root NO \
          --covar ../phen/covariates.use \
          --max-threads 1 \
          --memory-save YES
"> sh_script/$i-he-ldak-thin-$k-norm.sh
done
done

# submit files------------------------------------------------------------------
for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do
for k in all left right; do
sbatch -A snpher ../sh_script/$i-he-ldak-thin-$k-norm.sh
done
done > ../job-records/he-ldak-thin

```

### summary

```{bash eval=F}

#::::::::::::
# under gcta
#::::::::::::

# extract h2 estimates ---------------------------------------------------------
# right
rm summary/he-gcta-norm.right 
for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do
outfile=he-norm/$i-he-gcta-right.he
awk -v i=$i '$1=="Her_All" {print i, $2, $3}' $outfile >> summary/he-gcta-norm.right
done

# left
rm summary/he-gcta-norm.left
for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do
outfile=he-norm/$i-he-gcta-left.he
awk -v i=$i '$1=="Her_All" {print i, $2, $3}' $outfile >> summary/he-gcta-norm.left
done

# all
rm summary/he-gcta-norm.all
for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do
outfile=he-norm/$i-he-gcta-all.he
awk -v i=$i '$1=="Her_All" {print i, $2, $3}' $outfile >> summary/he-gcta-norm.all
done

# inflation test----------------------------------------------------------------
R

full=read.table(paste0("summary/he-gcta-norm.all"), header=F)
left=read.table(paste0("summary/he-gcta-norm.left"), header=F)
right=read.table(paste0("summary/he-gcta-norm.right"), header=F)
names(full)=names(left)=names(right)=c("code","h2","se")
# some analyses did not complete --> match dataframes
dim(full);dim(left);dim(right)
common=intersect(full$code, left$code)
common=intersect(common, right$code)
m1=match(common, right$code)
m2=match(common, full$code)
m3=match(common, left$code)
right=right[m1,]
full=full[m2,]
left=left[m3,]

for(i in 1:dim(full)[1]){
    
    est1=left$h2[i]
    sd1=left$se[i]
    est2=right$h2[i]
    sd2=right$se[i]
    est=full$h2[i]
    sd=full$se[i]
    N=100000
    d1=rnorm(N,est1,sd1)
    d2=rnorm(N,est2,sd2)
    d=rnorm(N,est,sd)
    p=1-mean(d1+d2-d>=0)
    
    out0=data.frame(code=full$code[i],
                    right_est=est2,
                    right_sd=sd2,
                    left_est=est1,
                    left_sd=sd1,
                    all_est=est,
                    all_sd=sd,
                    p_inflation=p)
   if(i==1){out=out0}else{out=rbind(out,out0)}
}
write.table(out, paste0("summary/he-gcta-inflation-norm.txt"),
            col.names=T, row.names=F, quote=F)


#::::::::::::
# under ldak-thin
#::::::::::::

# extract h2 estimates ---------------------------------------------------------
# right
rm summary/he-ldak-thin-norm.right 
for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do
outfile=he-norm/$i-he-ldak-thin-right.he
awk -v i=$i '$1=="Her_All" {print i, $2, $3}' $outfile >> summary/he-ldak-thin-norm.right
done

# left
rm summary/he-ldak-thin-norm.left
for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do
outfile=he-norm/$i-he-ldak-thin-left.he
awk -v i=$i '$1=="Her_All" {print i, $2, $3}' $outfile >> summary/he-ldak-thin-norm.left
done

# all
rm summary/he-ldak-thin-norm.all
for i in {awake,bmi,chron,ever,fvc,height,imp,neur,pulse,quals,reaction,sbp,snoring,hyper}; do
outfile=he-norm/$i-he-gcta-all.he
awk -v i=$i '$1=="Her_All" {print i, $2, $3}' $outfile >> summary/he-ldak-thin-norm.all
done

# inflation test----------------------------------------------------------------
R

full=read.table(paste0("summary/he-ldak-thin-norm.all"), header=F)
left=read.table(paste0("summary/he-ldak-thin-norm.left"), header=F)
right=read.table(paste0("summary/he-ldak-thin-norm.right"), header=F)
names(full)=names(left)=names(right)=c("code","h2","se")
# some analyses did not complete --> match dataframes
dim(full);dim(left);dim(right)
common=intersect(full$code, left$code)
common=intersect(common, right$code)
m1=match(common, right$code)
m2=match(common, full$code)
m3=match(common, left$code)
right=right[m1,]
full=full[m2,]
left=left[m3,]

for(i in 1:dim(full)[1]){
    
    est1=left$h2[i]
    sd1=left$se[i]
    est2=right$h2[i]
    sd2=right$se[i]
    est=full$h2[i]
    sd=full$se[i]
    N=100000
    d1=rnorm(N,est1,sd1)
    d2=rnorm(N,est2,sd2)
    d=rnorm(N,est,sd)
    p=1-mean(d1+d2-d>=0)
    
    out0=data.frame(code=full$code[i],
                    right_est=est2,
                    right_sd=sd2,
                    left_est=est1,
                    left_sd=sd1,
                    all_est=est,
                    all_sd=sd,
                    p_inflation=p)
   if(i==1){out=out0}else{out=rbind(out,out0)}
}
write.table(out, paste0("summary/he-ldak-thin-inflation-norm.txt"),
            col.names=T, row.names=F, quote=F)

```



